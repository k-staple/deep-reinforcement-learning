{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "You are welcome to use this coding environment to train your agent for the project.  Follow the instructions below to get started!\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "Run the next code cell to install a few packages.  This line will take a few minutes to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%aimport agent, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mipython 6.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.15, but you'll have prompt-toolkit 3.0.21 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environments corresponding to both versions of the environment are already saved in the Workspace and can be accessed at the file paths provided below.  \n",
    "\n",
    "Please select one of the two options below for loading the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "from workspace_utils import active_session\n",
    "\n",
    "# select this option to load version 1 (with a single agent) of the environment\n",
    "env = UnityEnvironment(file_name='/data/Reacher_One_Linux_NoVis/Reacher_One_Linux_NoVis.x86_64')\n",
    "\n",
    "# select this option to load version 2 (with 20 agents) of the environment\n",
    "# env = UnityEnvironment(file_name='/data/Reacher_Linux_NoVis/Reacher.x86_64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Size of each action: 4\n",
      "There are 1 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "   1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   5.75471878e+00  -1.00000000e+00\n",
      "   5.55726671e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "  -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,  -4.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,  -0.00000000e+00,  -0.00000000e+00,\n",
       "         -4.37113883e-08,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,  -1.00000000e+01,\n",
       "          0.00000000e+00,   1.00000000e+00,  -0.00000000e+00,\n",
       "         -0.00000000e+00,  -4.37113883e-08,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   5.75471878e+00,\n",
       "         -1.00000000e+00,   5.55726671e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,  -1.68164849e-01]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Note that **in this coding environment, you will not be able to watch the agents while they are training**, and you should set `train_mode=True` to restart the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'env_info = env.reset(train_mode=True)[brain_name]      # reset the environment    \\nstates = env_info.vector_observations                  # get the current state (for each agent)\\nscores = np.zeros(num_agents)                          # initialize the score (for each agent)\\niteration = 0\\nwhile True:\\n    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\\n    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\\n    print(\"\\t\", actions)\\n    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\\n    next_states = env_info.vector_observations         # get next state (for each agent)\\n    rewards = env_info.rewards                         # get reward (for each agent)\\n    if rewards[0] != 0:\\n        print(\"rewards\", rewards)\\n    dones = env_info.local_done                        # see if episode finished\\n    scores += env_info.rewards                         # update the score (for each agent)\\n    states = next_states                               # roll over states to next time step\\n    if np.any(dones):                                  # exit loop if episode finished\\n        print(iteration)\\n        break\\n    iteration += 1\\nprint(\\'Total score (averaged over agents) this episode: {}\\'.format(np.mean(scores)))\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''env_info = env.reset(train_mode=True)[brain_name]      # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "iteration = 0\n",
    "while True:\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    print(\"\\t\", actions)\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    if rewards[0] != 0:\n",
    "        print(\"rewards\", rewards)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        print(iteration)\n",
    "        break\n",
    "    iteration += 1\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  \\nimport queue\\nfrom collections import deque\\n\\nprint_every = 200\\n# seems to be 1000 for the env anyway\\nmax_ts = 2000\\nmax_episodes = 1000\\ncurr_agent = agent.Agent(state_size, action_size)\\n\\nenv_info = env.reset(train_mode=True)[brain_name]      # reset the environment    \\nstate = env_info.vector_observations[0]                  # get the current state (for each agent)\\n# can\\'t use a queue.Queue because \"Insertion will block once this size has been reached, until queue items are consumed\"\\nscores = deque(maxlen=100)                          # initialize the score (for each agent)\\nscores_history = []\\n\\nepisode_won_i = 0\\n\\nwith active_session():\\n    # TODO: maybe set max # of episodes\\n    for i in range(max_episodes):\\n        score = 0\\n        for t in range(max_ts):\\n            action = curr_agent.act(state.astype(\\'float32\\', copy=False))\\n            \\n            # because random numpy actions at the beginning are already numpy\\n            \\n            try:\\n                action = action.to(\"cpu\").detach().numpy()\\n            except:\\n                pass\\n            if t % print_every == 0:\\n                print(\\'\\taction\\', action)\\n            env_info = env.step(action)[brain_name]\\n            reward = env_info.rewards[0]\\n            if reward != 0:\\n                print(\"reward\", reward)\\n            next_state = env_info.vector_observations[0]\\n            done = env_info.local_done[0]\\n            \\n            score = score * curr_agent.Q_DISCOUNT + reward\\n\\n            curr_agent.step(state, action, reward, next_state, done)\\n\\n\\n            if done: \\n                print(\"episode {} at {} ts; done reached\".format(i, t))\\n                break\\n        scores_history.append(score)\\n        scores.append(score)\\n        if i % print_every == 0:\\n            print(\"episode {}; average score past 100 episodes: {}\".format(i, np.mean(scores)))\\n        if np.mean(scores) >= 30:\\n            episode_won_i = i\\n            print(\"Solved in {} episodes\".format(episode_won_i))\\n            curr_agent.save()\\n            break\\n        \\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''  \n",
    "import queue\n",
    "from collections import deque\n",
    "\n",
    "print_every = 200\n",
    "# seems to be 1000 for the env anyway\n",
    "max_ts = 2000\n",
    "max_episodes = 1000\n",
    "curr_agent = agent.Agent(state_size, action_size)\n",
    "\n",
    "env_info = env.reset(train_mode=True)[brain_name]      # reset the environment    \n",
    "state = env_info.vector_observations[0]                  # get the current state (for each agent)\n",
    "# can't use a queue.Queue because \"Insertion will block once this size has been reached, until queue items are consumed\"\n",
    "scores = deque(maxlen=100)                          # initialize the score (for each agent)\n",
    "scores_history = []\n",
    "\n",
    "episode_won_i = 0\n",
    "\n",
    "with active_session():\n",
    "    # TODO: maybe set max # of episodes\n",
    "    for i in range(max_episodes):\n",
    "        score = 0\n",
    "        for t in range(max_ts):\n",
    "            action = curr_agent.act(state.astype('float32', copy=False))\n",
    "            \n",
    "            # because random numpy actions at the beginning are already numpy\n",
    "            \n",
    "            try:\n",
    "                action = action.to(\"cpu\").detach().numpy()\n",
    "            except:\n",
    "                pass\n",
    "            if t % print_every == 0:\n",
    "                print('\\taction', action)\n",
    "            env_info = env.step(action)[brain_name]\n",
    "            reward = env_info.rewards[0]\n",
    "            if reward != 0:\n",
    "                print(\"reward\", reward)\n",
    "            next_state = env_info.vector_observations[0]\n",
    "            done = env_info.local_done[0]\n",
    "            \n",
    "            score = score * curr_agent.Q_DISCOUNT + reward\n",
    "\n",
    "            curr_agent.step(state, action, reward, next_state, done)\n",
    "\n",
    "\n",
    "            if done: \n",
    "                print(\"episode {} at {} ts; done reached\".format(i, t))\n",
    "                break\n",
    "        scores_history.append(score)\n",
    "        scores.append(score)\n",
    "        if i % print_every == 0:\n",
    "            print(\"episode {}; average score past 100 episodes: {}\".format(i, np.mean(scores)))\n",
    "        if np.mean(scores) >= 30:\n",
    "            episode_won_i = i\n",
    "            print(\"Solved in {} episodes\".format(episode_won_i))\n",
    "            curr_agent.save()\n",
    "            break\n",
    "        \n",
    "'''     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\taction [[ 0.52149829  0.17768316  0.63673145 -1.        ]]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.19953901  1.        ]\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.15310174  1.        ]\n",
      "\taction [ 1.          1.         -0.35730794  1.        ]\n",
      "episode 0 at 1000 ts; done reached\n",
      "episode 0; average score past 100 episodes: 0.09999999776482582\n",
      "\taction [ 0.16344191  0.04954946 -0.01665164 -0.02159324]\n",
      "\taction [ 1.          1.         -0.23017302  1.        ]\n",
      "\taction [ 1.          1.         -0.60227263  1.        ]\n",
      "\taction [ 1.          1.         -0.30277315  1.        ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.009999999776482582\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "episode 1 at 1000 ts; done reached\n",
      "\taction [-0.32696345  0.39132172 -0.26360551 -0.10022692]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.         1.        -0.2718561  1.       ]\n",
      "\taction [ 1.         1.        -0.2211674  1.       ]\n",
      "\taction [ 1.          1.         -0.32442749  1.        ]\n",
      "episode 2 at 1000 ts; done reached\n",
      "\taction [-0.91842544 -0.94320655  1.          0.90921181]\n",
      "\taction [-0.38634855  1.          1.          0.11507928]\n",
      "\taction [ 1.          1.         -0.35977212  1.        ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.38442975 -0.29932076]\n",
      "episode 3 at 1000 ts; done reached\n",
      "\taction [-0.4346562   1.         -0.89872479  0.55907577]\n",
      "\taction [ 1.          1.         -0.26190937  1.        ]\n",
      "\taction [ 1.          1.         -0.27711788  1.        ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.32421786  1.        ]\n",
      "episode 4 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.86585867  0.96108687]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.47469392  1.        ]\n",
      "\taction [ 1.          1.         -0.43861976  1.        ]\n",
      "\taction [ 1.          1.         -0.43101048  1.        ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "episode 5 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.95292735  1.        ]\n",
      "\taction [ 1.         1.        -0.2768887  1.       ]\n",
      "\taction [ 1.          1.         -0.36972508  1.        ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.31324103  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "episode 6 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.96713018  1.        ]\n",
      "\taction [ 1.          1.         -0.34984183  1.        ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.57477987  1.        ]\n",
      "\taction [ 1.          1.         -0.31489715  1.        ]\n",
      "episode 7 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.81978625  1.        ]\n",
      "\taction [ 1.          1.         -0.05561661  1.        ]\n",
      "\taction [ 1.          1.         -0.48256415  1.        ]\n",
      "\taction [ 1.          1.         -0.36803392  1.        ]\n",
      "episode 8 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.86156958  1.        ]\n",
      "\taction [ 1.         1.        -0.2413733  1.       ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.35515556  1.        ]\n",
      "\taction [ 1.         1.        -0.2901265  1.       ]\n",
      "episode 9 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.88213599  1.        ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.34322843  1.        ]\n",
      "\taction [ 1.          1.         -0.22296222  1.        ]\n",
      "\taction [ 1.          1.         -0.13934962  1.        ]\n",
      "episode 10 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.81854105  1.        ]\n",
      "\taction [ 1.          1.         -0.29664969  1.        ]\n",
      "\taction [ 1.          1.         -0.40104091  1.        ]\n",
      "\taction [ 1.          1.         -0.34973735  1.        ]\n",
      "episode 11 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.81528401  1.        ]\n",
      "\taction [ 1.          1.         -0.22601835  1.        ]\n",
      "\taction [ 1.          1.         -0.40747806  1.        ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.28468847  1.        ]\n",
      "episode 12 at 1000 ts; done reached\n",
      "\taction [ 1.         1.        -0.8770743  1.       ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.46506095  1.        ]\n",
      "\taction [ 1.          1.         -0.31163308  1.        ]\n",
      "\taction [ 1.          1.         -0.48096952  1.        ]\n",
      "episode 13 at 1000 ts; done reached\n",
      "\taction [ 1.         1.        -0.9800846  1.       ]\n",
      "\taction [ 1.          1.         -0.31837028  1.        ]\n",
      "\taction [ 1.          1.         -0.35336262  1.        ]\n",
      "\taction [ 1.         1.        -0.0968888  1.       ]\n",
      "episode 14 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.91602844  1.        ]\n",
      "\taction [ 1.          1.         -0.29631093  1.        ]\n",
      "\taction [ 1.          1.         -0.38155678  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.20301808  1.        ]\n",
      "episode 15 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.87489676  1.        ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.26214364  1.        ]\n",
      "\taction [ 1.         1.        -0.3764627  1.       ]\n",
      "\taction [ 1.          1.         -0.21557182  1.        ]\n",
      "episode 16 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.87334931  1.        ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.30785185  1.        ]\n",
      "\taction [ 1.          1.         -0.38655326  1.        ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.08135284  1.        ]\n",
      "episode 17 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.96613318  1.        ]\n",
      "\taction [ 1.          1.         -0.32520419  1.        ]\n",
      "\taction [ 1.         1.        -0.4830406  1.       ]\n",
      "\taction [ 1.          1.         -0.31311655  1.        ]\n",
      "episode 18 at 1000 ts; done reached\n",
      "\taction [ 1.          0.99999177 -0.96310699  0.94172055]\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.23332584  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.29456738  1.        ]\n",
      "\taction [ 1.          1.         -0.44400969  1.        ]\n",
      "episode 19 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.82095021  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.36984983  1.        ]\n",
      "\taction [ 1.         1.        -0.2846278  1.       ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.25159663  1.        ]\n",
      "episode 20 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.95943481  1.        ]\n",
      "\taction [ 1.          1.         -0.49358833  1.        ]\n",
      "\taction [ 1.          1.         -0.34954464  1.        ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.43580976  1.        ]\n",
      "episode 21 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.82604843  1.        ]\n",
      "\taction [ 1.          1.         -0.36455712  1.        ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.23511322  1.        ]\n",
      "\taction [ 1.          1.         -0.39239436  1.        ]\n",
      "episode 22 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.80619812  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.38128453  1.        ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.         1.        -0.2386284  1.       ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.44567648  1.        ]\n",
      "episode 23 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.93673605  1.        ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.11135148  1.        ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.47683203  1.        ]\n",
      "\taction [ 1.         1.        -0.3431446  1.       ]\n",
      "episode 24 at 1000 ts; done reached\n",
      "\taction [ 1.         1.        -0.8306278  1.       ]\n",
      "\taction [ 1.         1.        -0.3014231  1.       ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.46187544  1.        ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.029999999329447746\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.25560784  1.        ]\n",
      "episode 25 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.92118961  1.        ]\n",
      "\taction [ 1.          1.         -0.36668432  1.        ]\n",
      "\taction [ 1.          1.         -0.51518691  1.        ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.29468015  1.        ]\n",
      "episode 26 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.83792943  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.48203984  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.         1.        -0.4872964  1.       ]\n",
      "\taction [ 1.         1.        -0.3513774  1.       ]\n",
      "episode 27 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.85183728  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.34249085  1.        ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.43808398  1.        ]\n",
      "\taction [ 1.          1.         -0.45528501  1.        ]\n",
      "episode 28 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.95435029  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.17797919  1.        ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.21174772  1.        ]\n",
      "\taction [ 1.          1.         -0.05879566 -0.25650072]\n",
      "episode 29 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.82896233  1.        ]\n",
      "\taction [ 1.          1.         -0.38152212 -0.51586211]\n",
      "\taction [ 1.         1.        -0.2183298  1.       ]\n",
      "\taction [ 1.          1.         -0.31458172  1.        ]\n",
      "episode 30 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.91433078  1.        ]\n",
      "\taction [ 1.          1.         -0.15976037  1.        ]\n",
      "\taction [ 1.         1.        -0.2804473  1.       ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.18396717  1.        ]\n",
      "episode 31 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.85159266  1.        ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.31579113  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.32804388  1.        ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.30297178  1.        ]\n",
      "episode 32 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.86083978  1.        ]\n",
      "\taction [ 1.          1.         -0.52727479  1.        ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.29740289  1.        ]\n",
      "\taction [ 1.          1.         -0.42773461  1.        ]\n",
      "episode 33 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.95379686  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.46805871  1.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.32700166  1.        ]\n",
      "\taction [ 1.          1.         -0.30038685  1.        ]\n",
      "episode 34 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.86650717  0.99575204]\n",
      "\taction [ 1.          1.         -0.30543339  1.        ]\n",
      "\taction [ 1.          1.         -0.28335136  1.        ]\n",
      "\taction [ 1.          1.         -0.24083167  1.        ]\n",
      "episode 35 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.80658805  0.9662286 ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.         1.        -0.2371102 -0.3278504]\n",
      "\taction [ 1.          1.         -0.45148575  1.        ]\n",
      "\taction [ 1.          1.         -0.44019815  1.        ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "episode 36 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.96946132  1.        ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.43103004  1.        ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.31501013  1.        ]\n",
      "\taction [ 1.          1.         -0.40037712  1.        ]\n",
      "episode 37 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.83782601  1.        ]\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.16115281  1.        ]\n",
      "\taction [ 1.          1.         -0.45373091  1.        ]\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.        1.       -0.096171  1.      ]\n",
      "episode 38 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.91229314  1.        ]\n",
      "\taction [ 1.          1.         -0.17891987  1.        ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.41636005  1.        ]\n",
      "\taction [ 1.          1.         -0.24998263  1.        ]\n",
      "episode 39 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.90900123  1.        ]\n",
      "\taction [ 1.          1.         -0.19001782  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.33732918  1.        ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.36430132  1.        ]\n",
      "episode 40 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.95464617  1.        ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.35128686  1.        ]\n",
      "\taction [ 1.          1.         -0.33850145  1.        ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.28944224  1.        ]\n",
      "episode 41 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.94312358  1.        ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.34728703  1.        ]\n",
      "\taction [ 1.          1.         -0.31849635  1.        ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.18282594  1.        ]\n",
      "episode 42 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.87486929  1.        ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.33350426  1.        ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.44456223  1.        ]\n",
      "\taction [ 1.          1.         -0.37395221 -0.16319802]\n",
      "episode 43 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.84302175  1.        ]\n",
      "\taction [ 1.          1.         -0.45445415  1.        ]\n",
      "\taction [ 1.          1.         -0.24289548  1.        ]\n",
      "\taction [ 1.         1.        -0.4253087  1.       ]\n",
      "episode 44 at 1000 ts; done reached\n",
      "\taction [ 1.         1.        -0.9300611  1.       ]\n",
      "\taction [ 1.          1.         -0.55574983  1.        ]\n",
      "\taction [ 1.          1.         -0.32938096  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.61661106  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "episode 45 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.97006428  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.25276488  1.        ]\n",
      "\taction [ 1.          1.         -0.48464569  1.        ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.28205612  1.        ]\n",
      "episode 46 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.86518455  0.98078746]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.39662686  1.        ]\n",
      "\taction [ 1.          1.         -0.24188328  1.        ]\n",
      "\taction [ 1.          1.         -0.07351698  1.        ]\n",
      "episode 47 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.95834225  0.96985352]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.38789222  1.        ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.019999999552965164\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.        1.       -0.260912  1.      ]\n",
      "\taction [ 1.         1.        -0.4694207  1.       ]\n",
      "episode 48 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.94892365  0.9488824 ]\n",
      "\taction [ 1.          1.         -0.22661202  1.        ]\n",
      "\taction [ 1.          1.         -0.42627865  1.        ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\taction [ 1.          1.         -0.34153339  1.        ]\n",
      "episode 49 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.90126306  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.36700878  1.        ]\n",
      "\taction [ 1.         1.        -0.3120532  1.       ]\n",
      "\taction [ 1.          1.         -0.31392601  1.        ]\n",
      "episode 50 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.94954145  1.        ]\n",
      "\taction [ 1.          1.         -0.40107644  1.        ]\n",
      "\taction [ 1.          1.         -0.22492804  1.        ]\n",
      "\taction [ 1.          1.         -0.39771125  1.        ]\n",
      "episode 51 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.90132612  1.        ]\n",
      "\taction [ 1.          1.         -0.17443173  1.        ]\n",
      "\taction [ 1.          1.         -0.35499462  1.        ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.29199409  1.        ]\n",
      "episode 52 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.97224015  0.93781441]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.15744464  1.        ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.36969784  1.        ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.50310576  1.        ]\n",
      "episode 53 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.79641426  1.        ]\n",
      "\taction [ 1.          1.         -0.33918905  1.        ]\n",
      "\taction [ 1.          1.         -0.34159276  1.        ]\n",
      "\taction [ 1.          1.         -0.28557897  1.        ]\n",
      "episode 54 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.97854877  1.        ]\n",
      "\taction [ 1.          1.         -0.36064178 -0.34363276]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.36291325  1.        ]\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.35762024  1.        ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "episode 55 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.82083821  1.        ]\n",
      "\taction [ 1.          1.         -0.41246527  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.38045326  1.        ]\n",
      "\taction [ 1.          1.         -0.40216938  1.        ]\n",
      "episode 56 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.82219648  1.        ]\n",
      "\taction [ 1.          1.         -0.18517715  0.0306055 ]\n",
      "\taction [ 1.          1.         -0.36500573  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.50861394  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "episode 57 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.86121732  1.        ]\n",
      "\taction [ 1.          1.         -0.21993384  1.        ]\n",
      "\taction [ 1.          1.         -0.42257619  1.        ]\n",
      "\taction [ 1.          1.         -0.37610352  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "episode 58 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.87584269  0.97781211]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.41450626  1.        ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.30868408  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.30180922  1.        ]\n",
      "episode 59 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.85586482  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.37040806 -0.29436374]\n",
      "reward 0.029999999329447746\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.31524104  1.        ]\n",
      "\taction [ 1.          1.         -0.22190088  1.        ]\n",
      "episode 60 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.90897757  1.        ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.41526416  1.        ]\n",
      "\taction [ 1.         1.        -0.2725651  1.       ]\n",
      "\taction [ 1.          1.         -0.54480606  1.        ]\n",
      "episode 61 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.91211963  1.        ]\n",
      "\taction [ 1.          1.         -0.51012152  1.        ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.31741902  1.        ]\n",
      "\taction [ 1.          1.         -0.29975966  1.        ]\n",
      "episode 62 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.85582471  1.        ]\n",
      "\taction [ 1.         1.        -0.3783254  1.       ]\n",
      "\taction [ 1.         1.        -0.4624109  1.       ]\n",
      "\taction [ 1.          1.         -0.40291917  1.        ]\n",
      "episode 63 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.98404676  1.        ]\n",
      "\taction [ 1.          1.         -0.40520906  1.        ]\n",
      "\taction [ 1.          1.         -0.27176908  0.33473364]\n",
      "\taction [ 1.          1.         -0.51300603  1.        ]\n",
      "episode 64 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.94512898  1.        ]\n",
      "\taction [ 1.          1.         -0.29663181  1.        ]\n",
      "\taction [ 1.          1.         -0.53200841  1.        ]\n",
      "\taction [ 1.          1.         -0.09372245  1.        ]\n",
      "episode 65 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.98098654  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.20827337  1.        ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.         1.        -0.2043197  1.       ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.029999999329447746\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.42282605  1.        ]\n",
      "episode 66 at 1000 ts; done reached\n",
      "\taction [ 1.         1.        -0.8238256  1.       ]\n",
      "\taction [ 1.          1.         -0.44663042  1.        ]\n",
      "\taction [ 1.          1.         -0.39033213  0.11535767]\n",
      "\taction [ 1.          1.         -0.27983084  1.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 67 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.89916283  0.99825066]\n",
      "\taction [ 1.          1.         -0.31733903  1.        ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.43300569  1.        ]\n",
      "\taction [ 1.          1.         -0.41002968  1.        ]\n",
      "episode 68 at 1000 ts; done reached\n",
      "\taction [ 1.         1.        -0.9794172  1.       ]\n",
      "\taction [ 1.          1.         -0.22344978  1.        ]\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.32102624  1.        ]\n",
      "\taction [ 1.          1.         -0.45999733  1.        ]\n",
      "episode 69 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.92448783  0.9989109 ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.38018933  1.        ]\n",
      "\taction [ 1.          1.         -0.36824065  1.        ]\n",
      "\taction [ 1.          1.         -0.30037358  1.        ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "episode 70 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.90931749  1.        ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.47382367  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.         1.        -0.2632969  1.       ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.21486227  1.        ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "episode 71 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.96780503  1.        ]\n",
      "\taction [ 1.          1.         -0.45528814  1.        ]\n",
      "\taction [ 1.          1.         -0.25969136  1.        ]\n",
      "\taction [ 1.          1.         -0.31568199  1.        ]\n",
      "episode 72 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.92935562  1.        ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.43972653  1.        ]\n",
      "\taction [ 1.         1.        -0.2155209  1.       ]\n",
      "\taction [ 1.          1.         -0.30897221  1.        ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "episode 73 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.83589178  1.        ]\n",
      "\taction [ 1.          1.         -0.43541774  1.        ]\n",
      "\taction [ 1.          1.         -0.27095541  1.        ]\n",
      "\taction [ 1.          1.         -0.37538531  1.        ]\n",
      "episode 74 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.81447589  1.        ]\n",
      "\taction [ 1.          1.         -0.28982508  1.        ]\n",
      "\taction [ 1.          1.         -0.23260701  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.27364314  1.        ]\n",
      "episode 75 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.82825553  1.        ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.26690379  1.        ]\n",
      "\taction [ 1.          1.         -0.44878009  1.        ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.51333773  1.        ]\n",
      "episode 76 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.97525787  1.        ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.29478681  0.0531922 ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.28746784  0.05662677]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.18802141  1.        ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "episode 77 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.86033964  1.        ]\n",
      "\taction [ 1.          1.         -0.41319561 -0.27992517]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.44506109  1.        ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.16329932  1.        ]\n",
      "episode 78 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.98288471  0.83784372]\n",
      "\taction [ 1.          1.         -0.38473782  0.48680323]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.18003142 -0.27204859]\n",
      "\taction [ 1.         1.        -0.4550955  1.       ]\n",
      "episode 79 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.92254966  1.        ]\n",
      "\taction [ 1.          1.         -0.26613149  1.        ]\n",
      "\taction [ 1.          1.         -0.26575661  1.        ]\n",
      "\taction [ 1.          1.         -0.36482778 -0.25340575]\n",
      "episode 80 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.80359823  1.        ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.         1.        -0.3425152  1.       ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.35740158  0.30449381]\n",
      "\taction [ 1.          1.         -0.38956112  1.        ]\n",
      "episode 81 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.98956907  0.98700982]\n",
      "\taction [ 1.          1.         -0.36336452  1.        ]\n",
      "\taction [ 1.          1.         -0.25179204  1.        ]\n",
      "\taction [ 1.          1.         -0.49191961  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "episode 82 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.90220475  0.95295876]\n",
      "\taction [ 1.         1.        -0.3238396  1.       ]\n",
      "\taction [ 1.          1.         -0.24121328  1.        ]\n",
      "\taction [ 1.          1.         -0.40528977  0.35182339]\n",
      "episode 83 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.83563811  1.        ]\n",
      "\taction [ 1.          1.         -0.41017509 -0.28320852]\n",
      "\taction [ 1.          1.         -0.38158843  0.87906855]\n",
      "\taction [ 1.          1.         -0.31147811 -0.41910467]\n",
      "episode 84 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.99011207  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.29903889  1.        ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.39954907  1.        ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.29476383  0.2440331 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 85 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.82661766  1.        ]\n",
      "\taction [ 1.          1.         -0.58423847  1.        ]\n",
      "\taction [ 1.          1.         -0.34118921  1.        ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.25611582 -0.21474391]\n",
      "episode 86 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.82267499  0.93954295]\n",
      "\taction [ 1.          1.         -0.14710362  1.        ]\n",
      "\taction [ 1.          1.         -0.33213264  1.        ]\n",
      "\taction [ 1.          1.         -0.42862558  1.        ]\n",
      "episode 87 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.88562715  1.        ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.28955391 -0.34783679]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.34060639  1.        ]\n",
      "\taction [ 1.          1.         -0.27647677  1.        ]\n",
      "episode 88 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.91317964  0.84197712]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.37077531  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.34070399  1.        ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.15736032  0.65705413]\n",
      "episode 89 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.83928055  1.        ]\n",
      "\taction [ 1.          1.         -0.39617956  0.57543123]\n",
      "\taction [ 1.          1.         -0.39719036  1.        ]\n",
      "\taction [ 1.        1.       -0.299458  1.      ]\n",
      "episode 90 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.92983973  1.        ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.31589845 -0.16853422]\n",
      "\taction [ 1.         1.        -0.0864532  1.       ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.42283028 -0.13758303]\n",
      "episode 91 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.83688122  0.93529594]\n",
      "\taction [ 1.         1.        -0.3461104  1.       ]\n",
      "\taction [ 1.          1.         -0.31259653  1.        ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.45147911  1.        ]\n",
      "episode 92 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.95751208  1.        ]\n",
      "\taction [ 1.          1.         -0.40825561  1.        ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.21771434  1.        ]\n",
      "\taction [ 1.          1.         -0.08263919 -0.42756262]\n",
      "episode 93 at 1000 ts; done reached\n",
      "\taction [ 1.         1.        -0.8719818  1.       ]\n",
      "\taction [ 1.          1.         -0.305464   -0.45340243]\n",
      "\taction [ 1.          1.         -0.22920075  1.        ]\n",
      "\taction [ 1.          1.         -0.41859946 -0.19809775]\n",
      "episode 94 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.86618561  0.82672971]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.37638256  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.24307872  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.35197258 -0.04503429]\n",
      "episode 95 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.89506227  1.        ]\n",
      "\taction [ 1.          1.         -0.39961916  1.        ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.24540129 -0.26458088]\n",
      "\taction [ 1.          1.         -0.32692325  1.        ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "episode 96 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.98398119  0.77949148]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.23047768  1.        ]\n",
      "\taction [ 1.          1.         -0.25498486  1.        ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.43023449 -0.44304103]\n",
      "episode 97 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.85257435  0.87277049]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.44013786  1.        ]\n",
      "\taction [ 1.          1.         -0.30730811  1.        ]\n",
      "\taction [ 1.          1.         -0.23767723 -0.28323066]\n",
      "episode 98 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.80375075  1.        ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.        1.       -0.481534  1.      ]\n",
      "\taction [ 1.         1.        -0.4053818  1.       ]\n",
      "\taction [ 1.          1.         -0.36474097  0.83872789]\n",
      "episode 99 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.93412483  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.42129111  1.        ]\n",
      "\taction [ 1.          1.         -0.48753428  0.4378455 ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.029999999329447746\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\taction [ 1.          1.         -0.26090071 -0.38728955]\n",
      "episode 100 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.92801642  0.73389763]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.        1.       -0.309834  1.      ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.27529749  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.26815811  1.        ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.019999999552965164\n",
      "episode 101 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.79890156  0.93731481]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.19770631  1.        ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.009999999776482582\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.09966426  1.        ]\n",
      "\taction [ 1.          1.         -0.17938222  1.        ]\n",
      "episode 102 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.99344206  1.        ]\n",
      "\taction [ 1.          1.         -0.41978854  1.        ]\n",
      "\taction [ 1.          1.         -0.40477663 -0.10845109]\n",
      "\taction [ 1.          1.         -0.40638164  1.        ]\n",
      "episode 103 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.96325171  1.        ]\n",
      "\taction [ 1.          1.         -0.29900736  0.75110132]\n",
      "reward 0.019999999552965164\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.25949436 -0.21869282]\n",
      "\taction [ 1.          1.         -0.45525894 -0.12116399]\n",
      "episode 104 at 1000 ts; done reached\n",
      "\taction [ 1.         1.        -0.8449356  1.       ]\n",
      "\taction [ 1.         1.        -0.4130623  1.       ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.25454655  1.        ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.43262634 -0.10808719]\n",
      "episode 105 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.90112418  1.        ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.30959466  1.        ]\n",
      "\taction [ 1.         1.        -0.3811565  1.       ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.39257112  1.        ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "episode 106 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.85334206  0.93456542]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.13248129 -0.28097928]\n",
      "\taction [ 1.          1.         -0.24045834 -0.01901034]\n",
      "reward 0.019999999552965164\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.20285764  1.        ]\n",
      "episode 107 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.87933099  1.        ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.23381451  1.        ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.45768383  1.        ]\n",
      "\taction [ 1.          1.         -0.40313536 -0.25535339]\n",
      "episode 108 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.83866751  1.        ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.35341692 -0.48834422]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.47052994  1.        ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.24950339  1.        ]\n",
      "episode 109 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.87052417  1.        ]\n",
      "\taction [ 1.          1.         -0.12023798  1.        ]\n",
      "\taction [ 1.          1.         -0.31926444 -0.3436875 ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.47247997 -0.24775688]\n",
      "episode 110 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.94499695  0.75115091]\n",
      "reward 0.009999999776482582\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.33901331  1.        ]\n",
      "\taction [ 1.         1.        -0.3072173  1.       ]\n",
      "\taction [ 1.          1.         -0.54481542  1.        ]\n",
      "episode 111 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.86341357  1.        ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.15239935  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.21494804 -0.51648486]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.51232779  1.        ]\n",
      "episode 112 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.87336481  1.        ]\n",
      "\taction [ 1.          1.         -0.38093609  1.        ]\n",
      "\taction [ 1.          1.         -0.60765588  0.12390782]\n",
      "\taction [ 1.          1.         -0.46809486  1.        ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "episode 113 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.99853939  1.        ]\n",
      "\taction [ 1.          1.         -0.29684907 -0.29291931]\n",
      "reward 0.029999999329447746\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.22894076 -0.30092379]\n",
      "\taction [ 1.          1.         -0.23627894 -0.40511227]\n",
      "episode 114 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.90514284  0.74735445]\n",
      "\taction [ 1.          1.         -0.28105256 -0.19334406]\n",
      "\taction [ 1.          1.         -0.24538046 -0.29773951]\n",
      "\taction [ 1.          1.         -0.32029185 -0.446235  ]\n",
      "episode 115 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.81622237  1.        ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.36866027 -0.40718895]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.29529217 -0.32360438]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.29751936 -0.39234939]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "episode 116 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.82709426  0.91137516]\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.49348173 -0.21023667]\n",
      "reward 0.009999999776482582\n",
      "reward 0.009999999776482582\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.42598182  0.67787182]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.31096968 -0.21763241]\n",
      "episode 117 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.97780544  0.12833731]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.21582384 -0.15718341]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.34232906 -0.34994686]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.30077198 -0.33071181]\n",
      "episode 118 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.92054886  1.        ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.28208229 -0.16703594]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.33964241 -0.34042704]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.21931835 -0.31496686]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "episode 119 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.97736984  0.06229993]\n",
      "\taction [ 1.          1.         -0.22530496 -0.25956979]\n",
      "\taction [ 1.          1.         -0.33722761 -0.44668409]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.3134189  -0.32892254]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "episode 120 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.99399745  1.        ]\n",
      "\taction [ 1.          1.         -0.21600431 -0.38394815]\n",
      "\taction [ 1.          1.         -0.49279198 -0.41541708]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.25691125 -0.36248764]\n",
      "episode 121 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.97193891  0.74354309]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.26138681 -0.3016029 ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.029999999329447746\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.27332711 -0.39052582]\n",
      "\taction [ 1.          1.         -0.33303201 -0.26199314]\n",
      "episode 122 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.82992232  0.99037576]\n",
      "\taction [ 1.          1.         -0.29171661 -0.39427969]\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.32924575 -0.32190642]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.34792554 -0.33778659]\n",
      "episode 123 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.81617016  1.        ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.32496893 -0.57204735]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.56625938 -0.37688994]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.34860015 -0.23053464]\n",
      "episode 124 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.93104827 -0.17218037]\n",
      "\taction [ 1.          1.         -0.48590559 -0.42535296]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.35434094 -0.29323307]\n",
      "\taction [ 1.          1.         -0.52286673 -0.25081158]\n",
      "episode 125 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.94060707  0.98169345]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.22050044 -0.43712908]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.44092613 -0.36199257]\n",
      "\taction [ 1.          1.         -0.28593808 -0.30141705]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 126 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.80453372  0.55386204]\n",
      "\taction [ 1.          1.         -0.24966104 -0.33157057]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.31374487 -0.23219875]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.21635981 -0.46851254]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "episode 127 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.93842018  0.6126675 ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.30805334 -0.36739218]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.2694056  -0.39228478]\n",
      "\taction [ 1.          1.         -0.03514799 -0.1952785 ]\n",
      "episode 128 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.81789225  1.        ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.029999999329447746\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.          1.         -0.20768325]\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.          1.         -0.39703593]\n",
      "\taction [ 1.          1.         -0.3352986  -0.39553297]\n",
      "episode 129 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.404401    0.43609497]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.31298527 -0.30281547]\n",
      "\taction [ 1.          1.          1.         -0.37291241]\n",
      "\taction [ 1.          1.          1.         -0.42753407]\n",
      "episode 130 at 1000 ts; done reached\n",
      "\taction [ 1.         1.        -0.6160602  1.       ]\n",
      "\taction [ 1.          1.         -0.29974768 -0.38169211]\n",
      "\taction [ 1.          1.         -0.30377567 -0.09567927]\n",
      "\taction [ 1.          1.          1.         -0.46424076]\n",
      "episode 131 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.37203896  0.59637582]\n",
      "\taction [ 1.          1.          1.         -0.47156236]\n",
      "\taction [ 1.          1.         -0.36701891 -0.37589723]\n",
      "\taction [ 1.          1.          1.         -0.39232999]\n",
      "episode 132 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.86041969  1.        ]\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.         1.         1.        -0.5729841]\n",
      "\taction [ 1.          1.          1.         -0.42940524]\n",
      "\taction [ 1.          1.         -0.39253122 -0.42351255]\n",
      "episode 133 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.43849424  0.3454338 ]\n",
      "\taction [ 1.          1.          1.         -0.19592814]\n",
      "\taction [ 1.          1.         -0.45721433 -0.22488452]\n",
      "\taction [ 1.          1.          1.         -0.35990173]\n",
      "episode 134 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.79544157  0.53555083]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.31206214 -0.28386471]\n",
      "\taction [ 1.          1.         -0.53953338 -0.4403879 ]\n",
      "\taction [ 1.          1.         -0.20696107 -0.28552979]\n",
      "episode 135 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.57314581  0.85632104]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.          1.         -0.17043489]\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.15589547 -0.18731825]\n",
      "\taction [ 1.          1.          1.         -0.34106842]\n",
      "episode 136 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.76546866  1.        ]\n",
      "\taction [ 1.          1.         -0.2850405  -0.33548552]\n",
      "\taction [ 1.          1.         -0.5138886  -0.34772658]\n",
      "\taction [ 1.          1.          1.         -0.53289557]\n",
      "episode 137 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.37590921  0.3187229 ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.019999999552965164\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.         1.         1.        -0.2968857]\n",
      "\taction [ 1.          1.          1.         -0.41953301]\n",
      "\taction [ 1.          1.          1.         -0.39056742]\n",
      "episode 138 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.73100251  1.        ]\n",
      "\taction [ 1.          1.          1.         -0.20179726]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.36154911 -0.45681867]\n",
      "\taction [ 1.          1.         -0.46787274 -0.28073254]\n",
      "episode 139 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.89217705  1.        ]\n",
      "\taction [ 1.          1.         -0.38599354 -0.38576788]\n",
      "\taction [ 1.          1.         -0.32182321 -0.28704864]\n",
      "\taction [ 1.          1.         -0.46402645 -0.41803524]\n",
      "episode 140 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.52146888  0.46618539]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.          1.         -0.60195684]\n",
      "\taction [ 1.          1.          1.         -0.18404713]\n",
      "\taction [ 1.          1.         -0.23133183 -0.45951882]\n",
      "episode 141 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.8896324   0.73742598]\n",
      "\taction [ 1.          1.         -0.07631537 -0.48894763]\n",
      "\taction [ 1.          1.         -0.38125345 -0.40790772]\n",
      "\taction [ 1.          1.          1.         -0.28980488]\n",
      "episode 142 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.38027722  0.44465685]\n",
      "\taction [ 1.          1.         -0.35033303 -0.39177802]\n",
      "\taction [ 1.          1.          1.         -0.42798272]\n",
      "\taction [ 1.          1.          1.         -0.31055301]\n",
      "episode 143 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.45413843  0.29957709]\n",
      "\taction [ 1.          1.          1.         -0.42199582]\n",
      "\taction [ 1.          1.         -0.42105204 -0.23954383]\n",
      "\taction [ 1.          1.         -0.43119892 -0.26845154]\n",
      "episode 144 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.498712    0.44869259]\n",
      "\taction [ 1.          1.         -0.24220151 -0.27556565]\n",
      "\taction [ 1.          1.         -0.54749256 -0.36956456]\n",
      "\taction [ 1.          1.          1.         -0.27849343]\n",
      "episode 145 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.69756895  1.        ]\n",
      "\taction [ 1.          1.          1.         -0.13557407]\n",
      "\taction [ 1.         1.         1.        -0.3819479]\n",
      "\taction [ 1.         1.         1.        -0.2505745]\n",
      "episode 146 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.86815935  0.63436276]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.          1.         -0.43278173]\n",
      "\taction [ 1.          1.         -0.1755189  -0.24961562]\n",
      "\taction [ 1.          1.         -0.42639503 -0.13549446]\n",
      "episode 147 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.79019582  0.62509769]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.          1.         -0.36560428]\n",
      "\taction [ 1.          1.         -0.32472754 -0.32362017]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\taction [ 1.          1.         -0.23913744 -0.37067845]\n",
      "episode 148 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.81187326  1.        ]\n",
      "\taction [ 1.          1.         -0.23810104 -0.21120282]\n",
      "\taction [ 1.          1.         -0.18973459 -0.3493897 ]\n",
      "\taction [ 1.          1.         -0.36929342 -0.33261544]\n",
      "episode 149 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.83877075  0.88497519]\n",
      "\taction [ 1.          1.         -0.12711847 -0.39328691]\n",
      "\taction [ 1.          1.         -0.43326333 -0.41233736]\n",
      "\taction [ 1.          1.         -0.22151378 -0.29899842]\n",
      "episode 150 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.85085779  0.94676912]\n",
      "reward 0.009999999776482582\n",
      "reward 0.019999999552965164\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.          1.         -0.24060991]\n",
      "\taction [ 1.          1.         -0.32792604 -0.31048152]\n",
      "\taction [ 1.          1.         -0.34913769 -0.36990741]\n",
      "episode 151 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.33127293  0.37241817]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.          1.         -0.19520855]\n",
      "\taction [ 1.          1.         -0.48825353 -0.33978742]\n",
      "\taction [ 1.          1.          1.         -0.36401078]\n",
      "episode 152 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.78860742  1.        ]\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.          1.         -0.62165612]\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.32035449 -0.23878248]\n",
      "\taction [ 1.          1.          1.         -0.22895867]\n",
      "episode 153 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.50786     0.29419985]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.35209227 -0.14754738]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.2080981  -0.41072831]\n",
      "\taction [ 1.          1.         -0.31903267 -0.26484782]\n",
      "episode 154 at 1000 ts; done reached\n",
      "\taction [ 0.99932665  1.         -0.66583037  1.        ]\n",
      "\taction [ 1.          1.         -0.13875026 -0.39083445]\n",
      "\taction [ 1.          1.          1.         -0.26144657]\n",
      "\taction [ 1.          1.         -0.28983009 -0.4134098 ]\n",
      "episode 155 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.87937552  0.99057561]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.          1.         -0.26546314]\n",
      "\taction [ 1.          1.         -0.28716084 -0.13381663]\n",
      "\taction [ 1.          1.         -0.35444218 -0.40159515]\n",
      "episode 156 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.32484138  0.44704828]\n",
      "\taction [ 1.          1.         -0.33917955 -0.38586718]\n",
      "reward 0.029999999329447746\n",
      "reward 0.029999999329447746\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.36925417 -0.46090287]\n",
      "\taction [ 1.          1.         -0.29270229 -0.45881698]\n",
      "episode 157 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.62360483  1.        ]\n",
      "\taction [ 1.          1.          1.         -0.35995013]\n",
      "\taction [ 1.          1.         -0.2587347  -0.23830871]\n",
      "\taction [ 1.          1.         -0.1366753  -0.41242075]\n",
      "episode 158 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.62197256  1.        ]\n",
      "\taction [ 1.          1.          1.         -0.46940073]\n",
      "\taction [ 1.          1.          1.         -0.32581839]\n",
      "\taction [ 1.          1.          1.         -0.32864517]\n",
      "episode 159 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.46922654  0.69218409]\n",
      "reward 0.029999999329447746\n",
      "reward 0.029999999329447746\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.46116722 -0.29747462]\n",
      "\taction [ 1.          1.          1.         -0.20526563]\n",
      "\taction [ 1.          1.         -0.19960602 -0.28383467]\n",
      "episode 160 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.71513045  0.54652184]\n",
      "\taction [ 1.          1.         -0.32400995 -0.47397158]\n",
      "\taction [ 1.          1.          1.         -0.37586585]\n",
      "\taction [ 1.          1.         -0.31345153 -0.26082954]\n",
      "episode 161 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.71111804  0.49839786]\n",
      "\taction [ 1.          1.         -0.23834881 -0.22512591]\n",
      "\taction [ 1.          1.         -0.52675182 -0.31651524]\n",
      "\taction [ 1.         1.         1.        -0.2101068]\n",
      "episode 162 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.31125805  0.27026334]\n",
      "\taction [ 1.          1.         -0.43609217 -0.17962542]\n",
      "\taction [ 1.          1.          0.27559048 -0.3366895 ]\n",
      "\taction [ 1.          1.          1.         -0.49727467]\n",
      "episode 163 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.65682638  1.        ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.14357375 -0.41367659]\n",
      "\taction [ 1.          1.          1.         -0.33816582]\n",
      "\taction [ 1.         1.         1.        -0.2345781]\n",
      "episode 164 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.47667012  0.44410402]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.42279571 -0.26485312]\n",
      "\taction [ 1.          1.         -0.27045363 -0.38463411]\n",
      "\taction [ 1.          1.          1.         -0.65789425]\n",
      "episode 165 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.50460887  0.44160199]\n",
      "\taction [ 1.          1.         -0.42938179 -0.3773801 ]\n",
      "\taction [ 1.          1.         -0.37328926 -0.43662331]\n",
      "\taction [ 1.          1.         -0.49109128 -0.36449608]\n",
      "episode 166 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.70715266  1.        ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.          1.         -0.57857585]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.45647603 -0.23604028]\n",
      "\taction [ 1.         1.         1.        -0.3646057]\n",
      "episode 167 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.74633467  1.        ]\n",
      "\taction [ 1.          1.         -0.29557344 -0.43890041]\n",
      "\taction [ 1.          1.          1.         -0.40329799]\n",
      "\taction [ 1.          1.          1.         -0.20116423]\n",
      "episode 168 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.75230289  1.        ]\n",
      "\taction [ 1.         1.         1.        -0.2007475]\n",
      "\taction [ 1.          1.          1.         -0.17929482]\n",
      "\taction [ 1.          1.         -0.40803671 -0.48078817]\n",
      "episode 169 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.47991005  0.57890755]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.          1.         -0.38489059]\n",
      "\taction [ 1.         1.         1.        -0.4873246]\n",
      "\taction [ 1.          1.         -0.37785563 -0.43787748]\n",
      "episode 170 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.84751016  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.          1.         -0.36348826]\n",
      "\taction [ 1.          1.         -0.34022567 -0.44470054]\n",
      "\taction [ 1.          1.         -0.45306432 -0.49055842]\n",
      "episode 171 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.63012248  0.42534721]\n",
      "\taction [ 1.          1.          1.         -0.11387045]\n",
      "\taction [ 1.          1.          1.         -0.40355667]\n",
      "\taction [ 1.          1.          1.         -0.39359552]\n",
      "episode 172 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.77511233  0.83703303]\n",
      "\taction [ 1.          1.         -0.28185627 -0.17710581]\n",
      "\taction [ 1.          1.          1.         -0.23828648]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\taction [ 1.         1.         1.        -0.3450177]\n",
      "episode 173 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.46941313  1.        ]\n",
      "\taction [ 1.          1.         -0.38829395 -0.36946121]\n",
      "\taction [ 1.          1.          1.         -0.34958318]\n",
      "\taction [ 1.          1.          1.         -0.41548568]\n",
      "episode 174 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.46764675  0.38295338]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.          1.         -0.20250285]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.6645422  -0.41917014]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.029999999329447746\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.          1.         -0.32295245]\n",
      "episode 175 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.84304315  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.         1.         1.        -0.3647207]\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.36806092 -0.21107224]\n",
      "\taction [ 1.         1.         1.        -0.3808164]\n",
      "episode 176 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.63527745  1.        ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.          1.         -0.48628277]\n",
      "reward 0.019999999552965164\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.22875215 -0.29758221]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.         1.         1.        -0.2662155]\n",
      "episode 177 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.88337344  0.97015387]\n",
      "reward 0.009999999776482582\n",
      "reward 0.029999999329447746\n",
      "reward 0.019999999552965164\n",
      "reward 0.009999999776482582\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.20636456 -0.35474753]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.29536763 -0.38213819]\n",
      "\taction [ 1.          1.          1.         -0.47514927]\n",
      "episode 178 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.82925832  1.        ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.49023834 -0.12605892]\n",
      "\taction [ 1.          1.          1.         -0.42341891]\n",
      "\taction [ 1.          1.          1.         -0.29023877]\n",
      "episode 179 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.57292843  0.96386135]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.31576434 -0.47358757]\n",
      "\taction [ 1.          1.         -0.3939141  -0.26684138]\n",
      "\taction [ 1.          1.          1.         -0.46839052]\n",
      "episode 180 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.80366784  0.64031821]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.          1.         -0.56848288]\n",
      "\taction [ 1.          1.         -0.15671074 -0.39003322]\n",
      "\taction [ 1.          1.         -0.32740971 -0.29727527]\n",
      "episode 181 at 1000 ts; done reached\n",
      "\taction [ 0.99983126  1.         -0.41837341  0.30939537]\n",
      "\taction [ 1.          1.          1.         -0.27067655]\n",
      "\taction [ 1.          1.          1.         -0.42944947]\n",
      "\taction [ 1.          1.         -0.56369847 -0.44717818]\n",
      "episode 182 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.85884058  1.        ]\n",
      "\taction [ 1.          1.         -0.41606441 -0.31630424]\n",
      "\taction [ 1.          1.         -0.29347086 -0.35235289]\n",
      "\taction [ 1.          1.          1.         -0.20343547]\n",
      "episode 183 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.66020125  1.        ]\n",
      "\taction [ 1.          1.          1.         -0.45636946]\n",
      "\taction [ 1.          1.         -0.41503373 -0.37265325]\n",
      "\taction [ 1.          1.         -0.31104153 -0.33067626]\n",
      "episode 184 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.43897423  0.43860286]\n",
      "\taction [ 1.          1.         -0.08160515 -0.32597145]\n",
      "\taction [ 1.          1.         -0.30777675 -0.25846699]\n",
      "\taction [ 1.          1.         -0.20726989 -0.48800236]\n",
      "episode 185 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.48325345  0.41470528]\n",
      "reward 0.029999999329447746\n",
      "reward 0.029999999329447746\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.22371835 -0.22747111]\n",
      "\taction [ 1.          1.         -0.34726539 -0.26804483]\n",
      "\taction [ 1.          1.         -0.30126095 -0.43449786]\n",
      "episode 186 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.67312717  0.98176849]\n",
      "\taction [ 1.          1.         -0.33887106 -0.32828707]\n",
      "\taction [ 1.          1.         -0.16573621 -0.31458175]\n",
      "\taction [ 1.          1.          1.         -0.55392271]\n",
      "episode 187 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.80402571  1.        ]\n",
      "\taction [ 1.          1.          1.          0.00547017]\n",
      "\taction [ 1.          1.         -0.39262059 -0.44431129]\n",
      "\taction [ 1.          1.          1.         -0.56053907]\n",
      "episode 188 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.74538296  1.        ]\n",
      "\taction [ 1.          1.          1.         -0.47789368]\n",
      "\taction [ 1.          1.         -0.67990619 -0.22082515]\n",
      "\taction [ 1.          1.          1.         -0.41611308]\n",
      "episode 189 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.40617567  0.37435278]\n",
      "\taction [ 1.          1.          1.         -0.57613564]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.         1.         1.        -0.2858499]\n",
      "\taction [ 1.          1.          1.         -0.30946818]\n",
      "episode 190 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.82166332  1.        ]\n",
      "\taction [ 1.          1.          1.         -0.29048014]\n",
      "\taction [ 1.          1.          1.         -0.32463565]\n",
      "\taction [ 1.          1.         -0.1591254  -0.22358273]\n",
      "episode 191 at 1000 ts; done reached\n",
      "\taction [ 1.         1.        -0.8117516  1.       ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.          1.         -0.31020656]\n",
      "\taction [ 1.          1.         -0.36436939 -0.45019728]\n",
      "\taction [ 1.          1.         -0.45361573 -0.46848121]\n",
      "episode 192 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.88672751  1.        ]\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.          1.         -0.16736531]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.31122208 -0.27495745]\n",
      "\taction [ 1.          1.          0.17676008 -0.30400413]\n",
      "episode 193 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.80820268  1.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\taction [ 1.          1.         -0.22679019 -0.4013752 ]\n",
      "\taction [ 1.          1.         -0.34314397 -0.41689369]\n",
      "\taction [ 1.          1.          1.         -0.41903472]\n",
      "episode 194 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.35875964  0.51666051]\n",
      "\taction [ 1.          1.          1.         -0.23044814]\n",
      "\taction [ 1.          1.         -0.37415943 -0.51174444]\n",
      "\taction [ 1.          1.         -0.25939557 -0.28970546]\n",
      "episode 195 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.4214859   0.88410944]\n",
      "\taction [ 1.          1.         -0.08851323 -0.28196949]\n",
      "\taction [ 1.          1.         -0.29745263 -0.39475858]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.029999999329447746\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.32919863 -0.2743113 ]\n",
      "episode 196 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.39159968  0.85935235]\n",
      "reward 0.019999999552965164\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.3239961  -0.04787065]\n",
      "\taction [ 1.         1.         1.        -0.3593486]\n",
      "\taction [ 1.          1.         -0.46614793 -0.44447732]\n",
      "episode 197 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.83650267  1.        ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.029999999329447746\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.22757752 -0.32365301]\n",
      "\taction [ 1.          1.         -0.21621245 -0.31623331]\n",
      "\taction [ 1.          1.         -0.17022195 -0.42367801]\n",
      "episode 198 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.36663586  0.40011913]\n",
      "\taction [ 1.          1.          0.97617787 -0.45869279]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.3349022  -0.31274146]\n",
      "\taction [ 1.          1.         -0.28305706 -0.3951211 ]\n",
      "episode 199 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.84549695  0.96809411]\n",
      "\taction [ 1.          1.         -0.44528025 -0.17578773]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.2706877  -0.27847818]\n",
      "\taction [ 1.          1.          1.         -0.38266271]\n",
      "episode 200 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.70562798  1.        ]\n",
      "\taction [ 1.          1.         -0.36351377 -0.17107995]\n",
      "\taction [ 1.          1.         -0.2846882  -0.43437719]\n",
      "\taction [ 1.          1.         -0.16065969 -0.5408749 ]\n",
      "episode 201 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.73804504  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.45160404 -0.4503524 ]\n",
      "\taction [ 1.          1.         -0.39354724 -0.30962661]\n",
      "\taction [ 1.          1.          1.         -0.40041935]\n",
      "episode 202 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.3506979   0.38328108]\n",
      "\taction [ 1.          1.         -0.39423323 -0.45693848]\n",
      "\taction [ 1.          1.          1.         -0.26461676]\n",
      "\taction [ 1.          1.          1.         -0.35047528]\n",
      "episode 203 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.41417682  0.88971043]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.41621214 -0.19787712]\n",
      "\taction [ 1.          1.          1.         -0.33554786]\n",
      "\taction [ 1.          1.          1.         -0.47669727]\n",
      "episode 204 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.77317923  1.        ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.          1.         -0.41760811]\n",
      "\taction [ 1.          1.          0.38758278 -0.36656865]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.21948589 -0.34780264]\n",
      "episode 205 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.43793252  0.31223169]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.37709072 -0.23347951]\n",
      "\taction [ 1.          1.          1.         -0.19355413]\n",
      "\taction [ 1.          1.         -0.50111735 -0.3138361 ]\n",
      "episode 206 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.70130128  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.44427919 -0.27891752]\n",
      "\taction [ 1.          1.          1.         -0.32556587]\n",
      "reward 0.009999999776482582\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.31289342 -0.26978892]\n",
      "episode 207 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.82577914  0.86959672]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.29323417 -0.24631724]\n",
      "\taction [ 1.          1.         -0.121824   -0.39336532]\n",
      "\taction [ 1.          1.          1.         -0.48732626]\n",
      "episode 208 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.79270411  1.        ]\n",
      "\taction [ 1.          1.         -0.28538215 -0.49602112]\n",
      "\taction [ 1.          1.         -0.25936267 -0.24548081]\n",
      "\taction [ 1.          1.          0.26816005 -0.16989054]\n",
      "episode 209 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.82335186  1.        ]\n",
      "\taction [ 1.          1.         -0.18766323 -0.48161414]\n",
      "\taction [ 1.          1.         -0.46806264 -0.50994331]\n",
      "\taction [ 1.          1.          1.         -0.27005038]\n",
      "episode 210 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.76855916  1.        ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.40851673 -0.13736133]\n",
      "\taction [ 1.          1.         -0.33907828 -0.44691047]\n",
      "\taction [ 1.         1.         1.        -0.2842584]\n",
      "episode 211 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.80768305  1.        ]\n",
      "\taction [ 1.          1.          1.         -0.40694851]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.          1.         -0.50245529]\n",
      "\taction [ 1.          1.         -0.37019488 -0.29665518]\n",
      "episode 212 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.70683569  0.55052876]\n",
      "\taction [ 1.          1.         -0.45533296 -0.15926628]\n",
      "\taction [ 1.          1.         -0.30743468 -0.40507582]\n",
      "\taction [ 1.          1.          1.         -0.34649259]\n",
      "episode 213 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.26828846  0.78185654]\n",
      "\taction [ 1.          1.         -0.22580427 -0.24571796]\n",
      "\taction [ 1.          1.         -0.19229881 -0.18516003]\n",
      "\taction [ 1.          1.         -0.35914394 -0.26898021]\n",
      "episode 214 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.74572581  0.54843909]\n",
      "\taction [ 1.          1.         -0.27893245 -0.16376653]\n",
      "\taction [ 1.          1.         -0.40357184 -0.38427711]\n",
      "\taction [ 1.          1.         -0.17154016 -0.27758774]\n",
      "episode 215 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.52615643  0.43325856]\n",
      "\taction [ 1.          1.          1.         -0.18530339]\n",
      "\taction [ 1.          1.          1.         -0.40372336]\n",
      "\taction [ 1.          1.         -0.17300317 -0.5216763 ]\n",
      "episode 216 at 1000 ts; done reached\n",
      "\taction [ 1.         1.        -0.4909769  0.4018842]\n",
      "\taction [ 1.          1.         -0.42662123 -0.45899162]\n",
      "\taction [ 1.          1.          1.         -0.26962364]\n",
      "\taction [ 1.          1.         -0.15342966 -0.33020377]\n",
      "episode 217 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.62393713  1.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\taction [ 1.          1.         -0.54402077 -0.27334917]\n",
      "\taction [ 1.          1.         -0.15205967 -0.44392496]\n",
      "\taction [ 1.          1.         -0.33215848 -0.1861665 ]\n",
      "episode 218 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.59574068  1.        ]\n",
      "\taction [ 1.          1.         -0.09136258 -0.56845117]\n",
      "\taction [ 1.          1.          1.         -0.30800414]\n",
      "\taction [ 1.          1.         -0.34916505 -0.44897187]\n",
      "episode 219 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.44962177  0.30542541]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.41106436 -0.22945403]\n",
      "\taction [ 1.          1.          1.         -0.39752513]\n",
      "\taction [ 1.          1.          1.         -0.18951158]\n",
      "episode 220 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.45168084  0.56546366]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.          1.         -0.41872916]\n",
      "\taction [ 1.          1.         -0.26390344 -0.38494337]\n",
      "\taction [ 1.          1.          1.         -0.43819964]\n",
      "episode 221 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.58016431  0.34550002]\n",
      "\taction [ 1.          1.         -0.20538931 -0.22748493]\n",
      "\taction [ 1.          1.         -0.41245186 -0.33455953]\n",
      "\taction [ 1.          1.         -0.36247176 -0.25253838]\n",
      "episode 222 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.75048572  1.        ]\n",
      "\taction [ 1.          1.         -0.35939196 -0.4613221 ]\n",
      "\taction [ 1.          1.         -0.28847554 -0.37145463]\n",
      "\taction [ 1.          1.         -0.42122567 -0.24442416]\n",
      "episode 223 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.77189338  0.7269665 ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.37917012 -0.43276954]\n",
      "\taction [ 1.          1.          1.         -0.41050339]\n",
      "\taction [ 1.          1.         -0.29271185 -0.09330725]\n",
      "episode 224 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.52153808  0.33415627]\n",
      "\taction [ 1.          1.         -0.46510464 -0.28619799]\n",
      "\taction [ 1.          1.         -0.48954552 -0.33091104]\n",
      "\taction [ 1.          1.          1.         -0.46783787]\n",
      "episode 225 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.50820208  0.93107069]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.60045707 -0.33818972]\n",
      "\taction [ 1.          1.         -0.43156394 -0.36430043]\n",
      "\taction [ 1.          1.          1.         -0.24232125]\n",
      "episode 226 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.53594726  0.39001834]\n",
      "reward 0.029999999329447746\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.04919311 -0.52275151]\n",
      "\taction [ 1.          1.         -0.33330944 -0.26306641]\n",
      "\taction [ 1.          1.         -0.39626768 -0.2764644 ]\n",
      "episode 227 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.51396501  0.28455335]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.2313136  -0.15485162]\n",
      "\taction [ 1.         1.         1.        -0.2188773]\n",
      "\taction [ 1.          1.         -0.22721176 -0.34208506]\n",
      "episode 228 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.34082869  0.40696537]\n",
      "\taction [ 1.          1.         -0.52099234 -0.3633582 ]\n",
      "\taction [ 1.          1.         -0.26802349 -0.26983336]\n",
      "\taction [ 1.          1.         -0.02765291 -0.24066819]\n",
      "episode 229 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.81093502  0.57518727]\n",
      "\taction [ 1.          1.          1.         -0.09111784]\n",
      "\taction [ 1.          1.          1.         -0.35174912]\n",
      "\taction [ 1.          1.         -0.54493219 -0.35159841]\n",
      "episode 230 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.91486275  1.        ]\n",
      "\taction [ 1.        1.        1.       -0.185142]\n",
      "\taction [ 1.          1.         -0.42901275 -0.43627226]\n",
      "\taction [ 1.          1.         -0.11992335 -0.32952276]\n",
      "episode 231 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.80937237  0.95060003]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.47996876 -0.43283713]\n",
      "reward 0.019999999552965164\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.          1.         -0.52190781]\n",
      "\taction [ 1.          1.          1.         -0.33360711]\n",
      "episode 232 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.88875312  1.        ]\n",
      "\taction [ 1.          1.         -0.33579606 -0.17828315]\n",
      "\taction [ 1.          1.         -0.32166341 -0.4095138 ]\n",
      "\taction [ 1.          1.         -0.39410111 -0.16818208]\n",
      "episode 233 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.78408676  0.74708611]\n",
      "\taction [ 1.          1.         -0.40360948 -0.24142012]\n",
      "\taction [ 1.          1.         -0.35443634 -0.24210016]\n",
      "\taction [ 1.          1.         -0.38787207 -0.42243871]\n",
      "episode 234 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.90747702  0.68279052]\n",
      "\taction [ 1.          1.         -0.42902267 -0.24632819]\n",
      "\taction [ 1.          1.          1.         -0.29667246]\n",
      "\taction [ 1.          1.         -0.37578669 -0.33145159]\n",
      "episode 235 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.71961224  1.        ]\n",
      "\taction [ 1.          1.          1.         -0.23541035]\n",
      "\taction [ 1.          1.          1.         -0.19469227]\n",
      "\taction [ 1.         1.         1.        -0.2705135]\n",
      "episode 236 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.4775112   0.31396437]\n",
      "\taction [ 1.          1.         -0.27271214 -0.39070338]\n",
      "\taction [ 1.          1.         -0.10756824 -0.24001981]\n",
      "\taction [ 1.          1.         -0.29227129 -0.5426296 ]\n",
      "episode 237 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.80586231  0.85465097]\n",
      "\taction [ 1.          1.          1.         -0.12576827]\n",
      "\taction [ 1.          1.          1.         -0.35998368]\n",
      "\taction [ 1.         1.         1.        -0.1410771]\n",
      "episode 238 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.89867777  0.71294856]\n",
      "\taction [ 1.          1.          1.         -0.29025429]\n",
      "\taction [ 1.          1.         -0.40068418 -0.23307095]\n",
      "\taction [ 1.          1.         -0.29581118 -0.48292717]\n",
      "episode 239 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.57517368  1.        ]\n",
      "\taction [ 1.          1.         -0.51658767 -0.41079298]\n",
      "\taction [ 1.          1.         -0.30851713 -0.36413291]\n",
      "\taction [ 1.          1.         -0.49591896 -0.33994299]\n",
      "episode 240 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.92303139  1.        ]\n",
      "\taction [ 1.          1.         -0.25102383 -0.15912433]\n",
      "\taction [ 1.          1.         -0.38639289 -0.22319862]\n",
      "\taction [ 1.          1.         -0.41459    -0.43365607]\n",
      "episode 241 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.93804365  1.        ]\n",
      "\taction [ 1.          1.         -0.33915246 -0.35208192]\n",
      "\taction [ 1.          1.         -0.31457946 -0.31872347]\n",
      "\taction [ 1.          1.          1.         -0.28260913]\n",
      "episode 242 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.42502916  0.38167441]\n",
      "reward 0.019999999552965164\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.07728537 -0.21095647]\n",
      "\taction [ 1.       1.       1.      -0.49265]\n",
      "\taction [ 1.          1.         -0.0219202  -0.23224525]\n",
      "episode 243 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.39966807  0.26337859]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.24020323 -0.46096873]\n",
      "\taction [ 1.          1.         -0.30549547 -0.24891731]\n",
      "\taction [ 1.          1.         -0.29283634 -0.44648787]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 244 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.45116156  0.77753639]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.3430858  -0.46745875]\n",
      "\taction [ 1.          1.         -0.35166657 -0.40156561]\n",
      "\taction [ 1.          1.          1.         -0.50561148]\n",
      "episode 245 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.53149742  0.44871196]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.019999999552965164\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.40265378 -0.2436289 ]\n",
      "\taction [ 1.          1.          1.         -0.41422048]\n",
      "\taction [ 1.          1.          1.         -0.26299158]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "episode 246 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.80759126  0.99611419]\n",
      "\taction [ 1.          1.         -0.25016615 -0.32122248]\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.36557558 -0.34428805]\n",
      "\taction [ 1.          1.         -0.50359726 -0.2747944 ]\n",
      "episode 247 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.49827862  0.57207829]\n",
      "reward 0.009999999776482582\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.1628139  -0.22450003]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.          1.         -0.45321706]\n",
      "\taction [ 1.          1.          1.         -0.25368109]\n",
      "episode 248 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.47072217  0.62437046]\n",
      "\taction [ 1.          1.         -0.36845371 -0.50440919]\n",
      "\taction [ 1.        1.        1.       -0.329662]\n",
      "\taction [ 1.          1.          1.         -0.31109801]\n",
      "episode 249 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.52300763  0.33015504]\n",
      "\taction [ 1.          1.          1.         -0.32780752]\n",
      "\taction [ 1.          1.          1.         -0.45322707]\n",
      "\taction [ 1.          1.          1.         -0.28760058]\n",
      "episode 250 at 1000 ts; done reached\n",
      "\taction [ 1.         1.        -0.6630078  1.       ]\n",
      "\taction [ 1.          1.          1.         -0.37960926]\n",
      "\taction [ 1.          1.         -0.40177929 -0.29269823]\n",
      "\taction [ 1.          1.         -0.22527282 -0.0982168 ]\n",
      "episode 251 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.28727132  0.50932336]\n",
      "\taction [ 1.          1.          1.         -0.40680999]\n",
      "\taction [ 1.          1.         -0.41945469 -0.3290005 ]\n",
      "\taction [ 1.          1.         -0.35770148 -0.48239842]\n",
      "episode 252 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.78223282  1.        ]\n",
      "\taction [ 1.          1.         -0.53451973 -0.31226707]\n",
      "\taction [ 1.          1.         -0.42621696 -0.27076471]\n",
      "\taction [ 1.          1.         -0.40572762 -0.44853652]\n",
      "episode 253 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.76313835  1.        ]\n",
      "\taction [ 1.          1.          1.         -0.32139832]\n",
      "\taction [ 1.          1.          1.         -0.43846479]\n",
      "\taction [ 1.          1.         -0.25211588 -0.30700937]\n",
      "episode 254 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.40429178  0.76371646]\n",
      "\taction [ 1.          1.          1.         -0.28280386]\n",
      "\taction [ 1.          1.         -0.26280057 -0.42184582]\n",
      "\taction [ 1.         1.         1.        -0.1523554]\n",
      "episode 255 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.79482341  1.        ]\n",
      "\taction [ 1.          1.          1.         -0.43309575]\n",
      "\taction [ 1.          1.         -0.53443122 -0.32192495]\n",
      "\taction [ 1.          1.         -0.03824839 -0.37685829]\n",
      "episode 256 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.65664917  0.50807458]\n",
      "reward 0.019999999552965164\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.          1.         -0.14696237]\n",
      "\taction [ 1.          1.         -0.28069326 -0.17249508]\n",
      "\taction [ 1.          1.         -0.28665054 -0.21603265]\n",
      "episode 257 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.57890373  0.93572789]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.          1.         -0.28966972]\n",
      "\taction [ 1.          1.         -0.31709307 -0.2972939 ]\n",
      "\taction [ 1.          1.         -0.43390176 -0.26113081]\n",
      "episode 258 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.69781733  0.56774908]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.          1.         -0.62559509]\n",
      "\taction [ 1.          1.         -0.23717166 -0.37669742]\n",
      "\taction [ 1.          1.          1.         -0.15435211]\n",
      "episode 259 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.41198248  0.4217442 ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.41067719 -0.43135202]\n",
      "\taction [ 1.          1.          1.         -0.41966611]\n",
      "\taction [ 1.          1.         -0.44851357 -0.42801979]\n",
      "episode 260 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.46011633  0.47468296]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.          1.         -0.29767811]\n",
      "\taction [ 1.          1.         -0.33382666 -0.30444765]\n",
      "\taction [ 1.        1.        1.       -0.217472]\n",
      "episode 261 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.79631215  0.72039735]\n",
      "\taction [ 1.         1.         1.        -0.2753104]\n",
      "\taction [ 1.          1.          0.29475954 -0.43669358]\n",
      "\taction [ 1.          1.          1.         -0.46010807]\n",
      "episode 262 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.81307727  0.98966986]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.28613117 -0.10598753]\n",
      "\taction [ 1.          1.          1.         -0.23853327]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.45633194 -0.07906596]\n",
      "episode 263 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.392088    0.97157693]\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.2207303  -0.36729553]\n",
      "\taction [ 1.          1.         -0.47075239 -0.44140631]\n",
      "\taction [ 1.          1.         -0.27590269 -0.38062006]\n",
      "episode 264 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.89919412  0.81898642]\n",
      "\taction [ 1.          1.         -0.28132591 -0.41135043]\n",
      "\taction [ 1.          1.          1.         -0.41891575]\n",
      "\taction [ 1.          1.         -0.44201586 -0.3726764 ]\n",
      "episode 265 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.31502748  0.85827506]\n",
      "\taction [ 1.          1.          1.         -0.45779824]\n",
      "\taction [ 1.          1.         -0.44990668 -0.37596488]\n",
      "\taction [ 1.          1.          1.         -0.39438927]\n",
      "episode 266 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.74364662  1.        ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.          0.43370008 -0.48122075]\n",
      "\taction [ 1.          1.          0.21182506 -0.48515803]\n",
      "\taction [ 1.          1.          1.         -0.16919011]\n",
      "episode 267 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.84411848  1.        ]\n",
      "\taction [ 1.          1.          1.         -0.44549671]\n",
      "\taction [ 1.          1.         -0.31898817 -0.34415632]\n",
      "\taction [ 1.          1.         -0.45913967 -0.34587026]\n",
      "episode 268 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.59076345  0.98516321]\n",
      "reward 0.029999999329447746\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.          1.         -0.45330071]\n",
      "reward 0.019999999552965164\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.          1.         -0.42817703]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\taction [ 1.          1.         -0.45723739 -0.54636288]\n",
      "episode 269 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.71329868  0.39734322]\n",
      "\taction [ 1.          1.          1.         -0.32749975]\n",
      "\taction [ 1.          1.         -0.39811552 -0.31485608]\n",
      "\taction [ 1.          1.         -0.46783885 -0.18446851]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "episode 270 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.49468026  0.29299927]\n",
      "\taction [ 1.          1.         -0.02559873 -0.40457079]\n",
      "\taction [ 1.          1.         -0.27164215 -0.32635379]\n",
      "\taction [ 1.          1.         -0.48507658 -0.38111776]\n",
      "episode 271 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.77052057  0.73719025]\n",
      "reward 0.029999999329447746\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.          1.         -0.34945744]\n",
      "\taction [ 1.          1.         -0.30442667 -0.22966535]\n",
      "\taction [ 1.          1.         -0.4189381  -0.25894535]\n",
      "episode 272 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.82755446  0.66949987]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.          1.         -0.31308779]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.          1.         -0.38968918]\n",
      "reward 0.019999999552965164\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.40745279 -0.43974775]\n",
      "episode 273 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.82231945  0.48299217]\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.42188457 -0.21716072]\n",
      "\taction [ 1.          1.         -0.31364214 -0.33742464]\n",
      "\taction [ 1.          1.         -0.23242331 -0.32387158]\n",
      "episode 274 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.54849797  0.45785254]\n",
      "\taction [ 1.          1.          1.         -0.44733599]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.43221852 -0.45180294]\n",
      "\taction [ 1.          1.         -0.17708242 -0.37367025]\n",
      "episode 275 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.34029552  0.4111172 ]\n",
      "\taction [ 1.          1.         -0.24736109 -0.23903151]\n",
      "\taction [ 1.          1.         -0.4452593  -0.31376901]\n",
      "\taction [ 1.          1.         -0.30498919 -0.39821452]\n",
      "episode 276 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.81494612  0.50932372]\n",
      "\taction [ 1.          1.         -0.26673836 -0.30632156]\n",
      "\taction [ 1.          1.         -0.53156298 -0.40636957]\n",
      "\taction [ 1.          1.         -0.33708298 -0.40260354]\n",
      "episode 277 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.60074967  1.        ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.33313838 -0.18094645]\n",
      "\taction [ 1.          1.         -0.12905692 -0.39362299]\n",
      "\taction [ 1.          1.          1.         -0.34672093]\n",
      "episode 278 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.95069307  0.99122101]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.          1.         -0.38834256]\n",
      "\taction [ 1.         1.         1.        -0.2950435]\n",
      "\taction [ 1.          1.         -0.43780664 -0.25229219]\n",
      "episode 279 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.52575266  1.        ]\n",
      "\taction [ 1.          1.         -0.43796745 -0.25419039]\n",
      "\taction [ 1.          1.         -0.39012975 -0.43710038]\n",
      "\taction [ 1.          1.         -0.25413063 -0.23845534]\n",
      "episode 280 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.96209008  0.78855497]\n",
      "\taction [ 1.          1.         -0.33364165 -0.24750158]\n",
      "\taction [ 1.         1.         1.        -0.2680572]\n",
      "\taction [ 1.          1.         -0.43749574 -0.35280025]\n",
      "episode 281 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.75616843  0.55028802]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.20043813 -0.07501005]\n",
      "\taction [ 1.          1.         -0.31705141 -0.35727158]\n",
      "\taction [ 1.          1.         -0.1777247  -0.17826244]\n",
      "episode 282 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.81456333  0.74305195]\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.2614511  -0.36430791]\n",
      "\taction [ 1.          1.         -0.40990102 -0.55569702]\n",
      "\taction [ 1.          1.         -0.45996594 -0.30745614]\n",
      "episode 283 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.78846627  1.        ]\n",
      "\taction [ 1.          1.          1.         -0.33604255]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.         1.         1.        -0.3452158]\n",
      "\taction [ 1.          1.         -0.41848719 -0.19055888]\n",
      "episode 284 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.96577525  0.95511889]\n",
      "\taction [ 1.          1.         -0.5291267  -0.38283834]\n",
      "\taction [ 1.          1.         -0.43315199 -0.31046528]\n",
      "\taction [ 1.          1.          0.92807007 -0.34746698]\n",
      "episode 285 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.54480171  0.33611521]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.          1.         -0.39122042]\n",
      "\taction [ 1.          1.         -0.33554286 -0.38332531]\n",
      "\taction [ 1.          1.         -0.38716629 -0.25346956]\n",
      "episode 286 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.4187648   0.44095942]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.          1.         -0.37236461]\n",
      "\taction [ 1.          1.         -0.44517848 -0.305103  ]\n",
      "\taction [ 1.          1.         -0.42908967 -0.47846919]\n",
      "episode 287 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.90325224  0.98182142]\n",
      "\taction [ 1.          1.         -0.30977571 -0.1804698 ]\n",
      "\taction [ 1.          1.         -0.3632842  -0.32661432]\n",
      "\taction [ 1.          1.         -0.21258716 -0.35435429]\n",
      "episode 288 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.33360252  0.44510302]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.         1.         1.        -0.4990195]\n",
      "\taction [ 1.          1.          1.         -0.30227429]\n",
      "\taction [ 1.          1.         -0.42058995 -0.34124124]\n",
      "episode 289 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.36282024  0.8455649 ]\n",
      "\taction [ 1.          1.          1.         -0.36121148]\n",
      "\taction [ 1.          1.          1.         -0.15229762]\n",
      "reward 0.019999999552965164\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.01961056 -0.45338714]\n",
      "episode 290 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.50643575  0.98549306]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.019999999552965164\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\taction [ 1.          1.         -0.26744109 -0.51855469]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.          1.         -0.33163053]\n",
      "\taction [ 1.          1.         -0.22664821 -0.34837759]\n",
      "episode 291 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.67835718  1.        ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.         1.         1.        -0.2271347]\n",
      "\taction [ 1.          1.         -0.1132362  -0.48485547]\n",
      "\taction [ 1.          1.          1.         -0.46269104]\n",
      "episode 292 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.71809769  1.        ]\n",
      "\taction [ 1.          1.          1.         -0.22193161]\n",
      "\taction [ 1.          1.         -0.34088486 -0.41671261]\n",
      "\taction [ 1.          1.         -0.2899974  -0.50536776]\n",
      "episode 293 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.86499721  1.        ]\n",
      "\taction [ 1.          1.          1.         -0.40255323]\n",
      "\taction [ 1.          1.         -0.36839491 -0.49019834]\n",
      "\taction [ 1.          1.         -0.26713827 -0.33089298]\n",
      "episode 294 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.39145947  0.72327971]\n",
      "\taction [ 1.          1.         -0.30587497 -0.22656509]\n",
      "\taction [ 1.          1.         -0.28599623 -0.45714843]\n",
      "\taction [ 1.          1.         -0.34212881 -0.34593028]\n",
      "episode 295 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.81759554  1.        ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.21742553 -0.26991749]\n",
      "\taction [ 1.          1.          1.         -0.26318508]\n",
      "\taction [ 1.          1.          1.         -0.42586952]\n",
      "episode 296 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.62411499  0.38217658]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.          1.         -0.41829991]\n",
      "\taction [ 1.          1.         -0.19504297 -0.36004186]\n",
      "\taction [ 1.          1.          1.         -0.39379293]\n",
      "episode 297 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.68454939  0.60558838]\n",
      "reward 0.009999999776482582\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.          1.         -0.30827653]\n",
      "\taction [ 1.          1.          1.         -0.36993939]\n",
      "\taction [ 1.          1.          1.         -0.46638012]\n",
      "episode 298 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.35004196  0.33458224]\n",
      "\taction [ 1.          1.         -0.28972438 -0.40417647]\n",
      "\taction [ 1.          1.          1.         -0.50217366]\n",
      "\taction [ 1.          1.         -0.5002625  -0.33363503]\n",
      "episode 299 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.74862278  1.        ]\n",
      "\taction [ 1.          1.         -0.38917181 -0.27241737]\n",
      "\taction [ 1.          1.         -0.49498883 -0.2143808 ]\n",
      "\taction [ 1.          1.         -0.35525697 -0.35633746]\n",
      "episode 300 at 1000 ts; done reached\n",
      "episode 300; average score past 100 episodes: 0.08059999819844961\n",
      "\taction [ 1.          1.         -0.76706427  1.        ]\n",
      "\taction [ 1.          1.         -0.39975849 -0.23666242]\n",
      "\taction [ 1.          1.         -0.31930292 -0.45961156]\n",
      "\taction [ 1.          1.         -0.40819499 -0.27316132]\n",
      "episode 301 at 1000 ts; done reached\n",
      "\taction [ 1.         1.        -0.8058759  1.       ]\n",
      "\taction [ 1.          1.         -0.44520167 -0.28133625]\n",
      "\taction [ 1.          1.         -0.23047401 -0.23571089]\n",
      "\taction [ 1.          1.          1.         -0.42470807]\n",
      "episode 302 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.85323226  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.32361737 -0.51285273]\n",
      "reward 0.019999999552965164\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.14392574 -0.33069727]\n",
      "\taction [ 1.          1.         -0.374937   -0.47251755]\n",
      "episode 303 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.79235584  0.96173364]\n",
      "\taction [ 1.          1.         -0.25471148 -0.42118102]\n",
      "\taction [ 1.          1.          1.         -0.19444422]\n",
      "\taction [ 1.          1.          0.07958435 -0.2865988 ]\n",
      "episode 304 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.68458784  1.        ]\n",
      "\taction [ 1.          1.          1.         -0.45940885]\n",
      "\taction [ 1.          1.         -0.37840718 -0.30231541]\n",
      "\taction [ 1.          1.         -0.15771291 -0.36289951]\n",
      "episode 305 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.40067017  0.69681054]\n",
      "\taction [ 1.          1.          1.         -0.46969542]\n",
      "\taction [ 1.          1.          1.         -0.38205305]\n",
      "\taction [ 1.          1.          1.         -0.28550428]\n",
      "episode 306 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.95785755  0.94340813]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.          1.         -0.13933608]\n",
      "reward 0.029999999329447746\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.28524947 -0.36233407]\n",
      "\taction [ 1.          1.          1.         -0.32372233]\n",
      "episode 307 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.94289434  0.9801535 ]\n",
      "\taction [ 1.          1.          1.         -0.39322692]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.          1.         -0.31776926]\n",
      "\taction [ 1.          1.         -0.44810918 -0.30718207]\n",
      "reward 0.029999999329447746\n",
      "reward 0.009999999776482582\n",
      "episode 308 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.67181414  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.48192996 -0.31005472]\n",
      "\taction [ 1.          1.         -0.49046671 -0.2981469 ]\n",
      "\taction [ 1.          1.          1.         -0.39558378]\n",
      "episode 309 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.77824843  0.6194765 ]\n",
      "\taction [ 1.          1.         -0.41568539 -0.45142129]\n",
      "\taction [ 1.          1.         -0.10775729 -0.18156871]\n",
      "\taction [ 1.          1.          1.         -0.30414221]\n",
      "episode 310 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.77676588  1.        ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.029999999329447746\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.19395572 -0.36324352]\n",
      "\taction [ 1.          1.          1.         -0.60465974]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\taction [ 1.          1.         -0.2938593  -0.24610393]\n",
      "episode 311 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.44617131  0.39826077]\n",
      "\taction [ 1.          1.         -0.48137671 -0.29768741]\n",
      "\taction [ 1.        1.        1.       -0.205561]\n",
      "\taction [ 1.          1.         -0.33830017 -0.49980107]\n",
      "episode 312 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.93402052  1.        ]\n",
      "\taction [ 1.          1.          1.         -0.26945978]\n",
      "\taction [ 1.          1.          1.         -0.21422873]\n",
      "\taction [ 1.          1.          1.         -0.28967482]\n",
      "episode 313 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.76665068  1.        ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.41227627 -0.56768107]\n",
      "\taction [ 1.          1.         -0.38877887 -0.30969003]\n",
      "\taction [ 1.          1.          1.         -0.13900346]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "episode 314 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.4606111   0.33327851]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.          0.12882333 -0.37797621]\n",
      "\taction [ 1.         1.        -0.2803517 -0.2481313]\n",
      "\taction [ 1.          1.          1.         -0.38473934]\n",
      "episode 315 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.40703186  0.51885611]\n",
      "\taction [ 1.         1.         1.        -0.2084368]\n",
      "\taction [ 1.          1.          1.         -0.53885633]\n",
      "\taction [ 1.          1.         -0.34715781 -0.35452577]\n",
      "episode 316 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.3914566   0.53089684]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.21090348  1.        ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.44441855 -0.39676932]\n",
      "\taction [ 1.          1.         -0.31802812 -0.51207638]\n",
      "episode 317 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.82206029  1.        ]\n",
      "\taction [ 1.          1.         -0.22867778 -0.42912844]\n",
      "\taction [ 1.          1.          1.         -0.23783787]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.33667248 -0.35230672]\n",
      "episode 318 at 1000 ts; done reached\n",
      "\taction [ 1.         1.        -0.7715283  1.       ]\n",
      "\taction [ 1.          1.         -0.1573483  -0.49389002]\n",
      "\taction [ 1.          1.          1.         -0.35268536]\n",
      "\taction [ 1.          1.          1.         -0.33962345]\n",
      "episode 319 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.60449952  0.99334657]\n",
      "\taction [ 1.          1.          1.         -0.21528839]\n",
      "\taction [ 1.          1.          1.         -0.16796674]\n",
      "\taction [ 1.          1.         -0.24381973 -0.33675921]\n",
      "episode 320 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.38138458  0.43739015]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.46411517 -0.14504373]\n",
      "\taction [ 1.          1.          1.         -0.31910804]\n",
      "\taction [ 1.          1.         -0.48492146 -0.26748282]\n",
      "episode 321 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.74093944  1.        ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.44660655 -0.23066199]\n",
      "\taction [ 1.          1.          1.         -0.38756543]\n",
      "\taction [ 1.         1.         1.        -0.4622193]\n",
      "episode 322 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.56605804  0.36886147]\n",
      "reward 0.029999999329447746\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.         1.         1.        -0.4248125]\n",
      "\taction [ 1.          1.          1.         -0.26869777]\n",
      "\taction [ 1.          1.         -0.16214614 -0.34275261]\n",
      "episode 323 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.51950634  0.38619274]\n",
      "\taction [ 1.          1.         -0.36761615 -0.1654588 ]\n",
      "\taction [ 1.          1.         -0.3244029  -0.29892552]\n",
      "\taction [ 1.          1.          1.         -0.35394871]\n",
      "episode 324 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.50732821  0.33702683]\n",
      "\taction [ 1.          1.         -0.57558823 -0.41587397]\n",
      "\taction [ 1.          1.          1.         -0.29553378]\n",
      "\taction [ 1.          1.         -0.31091478 -0.18803819]\n",
      "episode 325 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.95189726  1.        ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.43135855 -0.49392247]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.          1.         -0.31911752]\n",
      "\taction [ 1.          1.         -0.15623748 -0.34289938]\n",
      "episode 326 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.38619184  0.61425966]\n",
      "\taction [ 1.          1.         -0.18747662 -0.29744199]\n",
      "\taction [ 1.          1.         -0.20320176 -0.40899256]\n",
      "\taction [ 1.          1.         -0.24864286 -0.19057679]\n",
      "episode 327 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.78660738  1.        ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.41969708 -0.39919496]\n",
      "\taction [ 1.          1.         -0.54416841 -0.44127458]\n",
      "\taction [ 1.          1.          1.         -0.21266697]\n",
      "episode 328 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.91200894  0.97545564]\n",
      "\taction [ 1.          1.          1.         -0.43992966]\n",
      "\taction [ 1.          1.          1.         -0.30667311]\n",
      "\taction [ 1.          1.         -0.31994414 -0.14516076]\n",
      "episode 329 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.77390379  0.81586784]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.029999999329447746\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.31116316 -0.36065254]\n",
      "\taction [ 1.          1.         -0.62003779 -0.31815362]\n",
      "\taction [ 1.          1.         -0.33037513 -0.21676654]\n",
      "episode 330 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.84169644  1.        ]\n",
      "\taction [ 1.          1.         -0.28038943 -0.38424075]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.39802763 -0.43194574]\n",
      "\taction [ 1.          1.         -0.45193347 -0.01870381]\n",
      "episode 331 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.46333835  0.83858025]\n",
      "\taction [ 1.          1.          1.         -0.25790206]\n",
      "\taction [ 1.          1.          1.         -0.40689635]\n",
      "\taction [ 1.          1.         -0.36996135 -0.28277621]\n",
      "episode 332 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.65710127  1.        ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.          1.         -0.31731105]\n",
      "\taction [ 1.          1.          1.         -0.53178209]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.         1.         1.        -0.4560543]\n",
      "episode 333 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.65136951  1.        ]\n",
      "\taction [ 1.          1.         -0.50011384 -0.42396599]\n",
      "\taction [ 1.          1.          1.         -0.40660188]\n",
      "\taction [ 1.          1.         -0.2028369  -0.55787259]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 334 at 1000 ts; done reached\n",
      "\taction [ 0.99942195  1.         -0.75665736  0.56716329]\n",
      "\taction [ 1.          1.         -0.21405992 -0.28321129]\n",
      "\taction [ 1.          1.          0.5688445  -0.35227013]\n",
      "\taction [ 1.          1.         -0.30043417 -0.42499027]\n",
      "episode 335 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.38820824  0.40459245]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.27558151 -0.60642248]\n",
      "\taction [ 1.          1.         -0.49031305 -0.30224207]\n",
      "\taction [ 1.          1.          1.         -0.32168385]\n",
      "episode 336 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.96440828  0.77659249]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.         1.         1.        -0.2437447]\n",
      "\taction [ 1.          1.         -0.21673173 -0.37911543]\n",
      "\taction [ 1.          1.          1.         -0.25255287]\n",
      "episode 337 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.5138284   0.27963626]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.41140261 -0.4778091 ]\n",
      "\taction [ 1.         1.         1.        -0.4337962]\n",
      "\taction [ 1.          1.          1.         -0.31877297]\n",
      "episode 338 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.53445786  0.33920535]\n",
      "\taction [ 1.          1.         -0.26597399 -0.26951686]\n",
      "\taction [ 1.          1.         -0.25048789 -0.3032988 ]\n",
      "\taction [ 1.        1.        1.       -0.103336]\n",
      "episode 339 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.42701587  0.75854152]\n",
      "\taction [ 1.          1.          1.         -0.45499092]\n",
      "\taction [ 1.          1.         -0.32234648 -0.40335163]\n",
      "\taction [ 1.          1.          1.         -0.39076015]\n",
      "episode 340 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.40590918  0.68564314]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.         1.         1.        -0.4704248]\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.29902589 -0.36623603]\n",
      "\taction [ 1.          1.         -0.32475156 -0.39234066]\n",
      "episode 341 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.88930136  1.        ]\n",
      "\taction [ 1.          1.         -0.14459889 -0.48889285]\n",
      "\taction [ 1.          1.         -0.45658609 -0.28888369]\n",
      "\taction [ 1.          1.          1.         -0.39968264]\n",
      "episode 342 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.35974437  0.67446661]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.30800608 -0.2903811 ]\n",
      "\taction [ 1.          1.          1.         -0.39985704]\n",
      "\taction [ 1.          1.          1.         -0.26175055]\n",
      "episode 343 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.69382399  1.        ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.          1.         -0.40442386]\n",
      "\taction [ 1.         1.         1.        -0.5770486]\n",
      "\taction [ 1.         1.         1.        -0.4189288]\n",
      "episode 344 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.41197914  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.26730108 -0.32626075]\n",
      "\taction [ 1.          1.          1.         -0.33907846]\n",
      "\taction [ 1.          1.          1.         -0.12016201]\n",
      "episode 345 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.60477918  1.        ]\n",
      "\taction [ 1.          1.         -0.31613663 -0.50413114]\n",
      "\taction [ 1.          1.         -0.42180169 -0.11135808]\n",
      "\taction [ 1.          1.         -0.29312733 -0.33824006]\n",
      "episode 346 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.38324127  0.70632768]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.46197221 -0.42350286]\n",
      "\taction [ 1.          1.          1.         -0.34504521]\n",
      "\taction [ 1.          1.         -0.20764588 -0.35381001]\n",
      "episode 347 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.34722307  0.70971185]\n",
      "\taction [ 1.          1.          1.         -0.16961561]\n",
      "\taction [ 1.          1.         -0.45656702 -0.21860644]\n",
      "\taction [ 1.          1.         -0.30388838 -0.42130125]\n",
      "episode 348 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.69478035  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.009999999776482582\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.          1.         -0.41302612]\n",
      "\taction [ 1.          1.          1.         -0.45372906]\n",
      "reward 0.019999999552965164\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.38286939 -0.30817807]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "episode 349 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.81711227  1.        ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.          1.         -0.64710379]\n",
      "\taction [ 1.          1.          1.         -0.25668731]\n",
      "\taction [ 1.          1.         -0.32929373 -0.24726483]\n",
      "episode 350 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.56557792  0.45768833]\n",
      "\taction [ 1.          1.         -0.10978778 -0.40861323]\n",
      "\taction [ 1.          1.          1.         -0.14335871]\n",
      "\taction [ 1.          1.         -0.21144685 -0.31031618]\n",
      "episode 351 at 1000 ts; done reached\n",
      "\taction [ 0.99707717  1.         -0.7522108   0.54251206]\n",
      "\taction [ 1.          1.         -0.33562586 -0.35231885]\n",
      "\taction [ 1.          1.         -0.51053673 -0.40425828]\n",
      "\taction [ 1.          1.          0.09775664 -0.23459275]\n",
      "episode 352 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.47153488  0.39273292]\n",
      "\taction [ 1.          1.         -0.52429718 -0.33468199]\n",
      "\taction [ 1.          1.         -0.25139043 -0.32284948]\n",
      "\taction [ 1.          1.         -0.35379779 -0.43140033]\n",
      "episode 353 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.47805959  0.75609463]\n",
      "\taction [ 1.          1.         -0.30898163 -0.19157015]\n",
      "\taction [ 1.          1.         -0.51645494 -0.23854513]\n",
      "\taction [ 1.          1.          1.         -0.29138741]\n",
      "episode 354 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.70178491  1.        ]\n",
      "\taction [ 1.         1.         1.        -0.4178935]\n",
      "\taction [ 1.          1.         -0.38682041 -0.36585334]\n",
      "\taction [ 1.          1.         -0.21465123 -0.15342264]\n",
      "episode 355 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.58297729  1.        ]\n",
      "\taction [ 1.          1.         -0.39192003 -0.22159763]\n",
      "\taction [ 1.          1.         -0.24969177 -0.32481283]\n",
      "\taction [ 1.          1.          1.         -0.33667019]\n",
      "episode 356 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.83266377  1.        ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.26038912 -0.29169101]\n",
      "\taction [ 1.          1.          1.         -0.42868334]\n",
      "\taction [ 1.          1.         -0.46904621 -0.32611415]\n",
      "episode 357 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.78612202  1.        ]\n",
      "\taction [ 1.          1.          1.         -0.35151875]\n",
      "\taction [ 1.          1.          1.         -0.28898373]\n",
      "\taction [ 1.         1.         1.        -0.1768603]\n",
      "episode 358 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.96130967  0.9438622 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\taction [ 1.          1.         -0.30216646 -0.2425908 ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.029999999329447746\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.          1.         -0.19851384]\n",
      "\taction [ 1.          1.         -0.38356027 -0.46535748]\n",
      "episode 359 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.57221591  0.29762182]\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.         1.         1.        -0.2630727]\n",
      "\taction [ 1.          1.          1.         -0.28798646]\n",
      "\taction [ 1.          1.         -0.20070849 -0.37916946]\n",
      "episode 360 at 1000 ts; done reached\n",
      "\taction [ 1.          0.99881023 -0.30769461  0.79426837]\n",
      "\taction [ 1.          1.         -0.52569473 -0.24990873]\n",
      "\taction [ 1.          1.         -0.3226673  -0.33367029]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.32216495 -0.21821807]\n",
      "episode 361 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.81086123  1.        ]\n",
      "\taction [ 1.          1.          1.         -0.36968952]\n",
      "\taction [ 1.          1.         -0.38258421 -0.10426986]\n",
      "\taction [ 1.          1.          1.         -0.35624751]\n",
      "episode 362 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.42008066  0.57655418]\n",
      "\taction [ 1.          1.         -0.48665658 -0.24323966]\n",
      "\taction [ 1.          1.         -0.14570783 -0.15299711]\n",
      "\taction [ 1.          1.          1.         -0.27340552]\n",
      "episode 363 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.79792792  1.        ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.29471382 -0.2984663 ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.36518455 -0.31230041]\n",
      "\taction [ 1.          1.         -0.38414225 -0.31941506]\n",
      "episode 364 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.76937973  1.        ]\n",
      "\taction [ 1.          1.         -0.27368635 -0.50339592]\n",
      "\taction [ 1.          1.          1.         -0.48321205]\n",
      "\taction [ 1.          1.          1.         -0.38469678]\n",
      "episode 365 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.58987021  0.38022506]\n",
      "\taction [ 1.          1.         -0.35959107 -0.26340893]\n",
      "\taction [ 1.          1.         -0.19077033 -0.24565199]\n",
      "\taction [ 1.          1.          1.         -0.33304068]\n",
      "episode 366 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.79047674  1.        ]\n",
      "\taction [ 1.          1.         -0.30643594 -0.35970312]\n",
      "\taction [ 1.          1.         -0.43704009 -0.28282598]\n",
      "\taction [ 1.          1.         -0.39717653 -0.14814447]\n",
      "episode 367 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.86603343  0.58558732]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.5222156  -0.33776554]\n",
      "\taction [ 1.          1.         -0.39353842 -0.32318062]\n",
      "\taction [ 1.          1.         -0.14684203 -0.50209242]\n",
      "episode 368 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.35782522  0.30429408]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.56785256 -0.35986838]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.          1.         -0.42148072]\n",
      "\taction [ 1.          1.          0.13155471 -0.28806812]\n",
      "episode 369 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.33177561  0.52771932]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.26941028 -0.2110211 ]\n",
      "\taction [ 1.          1.          1.         -0.25978914]\n",
      "\taction [ 1.          1.         -0.52594894 -0.22848824]\n",
      "episode 370 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.73236442  0.73795587]\n",
      "\taction [ 1.          1.         -0.18293703 -0.34553251]\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.          1.         -0.43071595]\n",
      "\taction [ 1.          1.          1.         -0.25883639]\n",
      "episode 371 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.64520526  0.45561913]\n",
      "\taction [ 1.          1.         -0.45607612 -0.23259218]\n",
      "\taction [ 1.          1.          1.         -0.22938037]\n",
      "\taction [ 1.          1.         -0.36199504 -0.40963045]\n",
      "episode 372 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.42913395  0.44066533]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.          1.         -0.46518645]\n",
      "\taction [ 1.          1.         -0.37202638 -0.25288299]\n",
      "\taction [ 1.          1.         -0.41206437 -0.3455503 ]\n",
      "episode 373 at 1000 ts; done reached\n",
      "\taction [ 0.99959719  1.         -0.49815875  0.36932218]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.3715865  -0.42697847]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.13534357 -0.4482182 ]\n",
      "\taction [ 1.          1.          1.         -0.48277679]\n",
      "episode 374 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.60346818  0.40424487]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.          1.         -0.40208834]\n",
      "\taction [ 1.          1.          1.         -0.08695855]\n",
      "\taction [ 1.          1.          1.         -0.37315246]\n",
      "episode 375 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.50854748  0.32638404]\n",
      "\taction [ 1.          1.         -0.36536571 -0.42784199]\n",
      "\taction [ 1.          1.         -0.20477897 -0.33284625]\n",
      "\taction [ 1.          1.         -0.35711187 -0.39531934]\n",
      "episode 376 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.36775953  0.35322669]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.18660492 -0.36871907]\n",
      "\taction [ 1.          1.          0.14825042 -0.3023468 ]\n",
      "\taction [ 1.          1.          1.         -0.31220496]\n",
      "episode 377 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.95147371  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.36522862 -0.22261506]\n",
      "\taction [ 1.          1.         -0.49716452 -0.20909289]\n",
      "\taction [ 1.          1.         -0.36805585 -0.35043693]\n",
      "episode 378 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.7817319   0.95055908]\n",
      "\taction [ 1.          1.         -0.31972754 -0.29134727]\n",
      "\taction [ 1.          1.          1.         -0.40928099]\n",
      "\taction [ 1.          1.          1.         -0.26952782]\n",
      "episode 379 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.81846482  1.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.14151858 -0.4333351 ]\n",
      "\taction [ 1.          1.         -0.34592286 -0.33990031]\n",
      "\taction [ 1.          1.          1.         -0.34793937]\n",
      "episode 380 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.69368327  1.        ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.         -0.14064702 -0.50715905]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.46628034 -0.38867268]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.20164748 -0.3292188 ]\n",
      "episode 381 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.70715022  1.        ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.          1.         -0.10822524]\n",
      "\taction [ 1.          1.         -0.28549349 -0.24652961]\n",
      "\taction [ 1.          1.         -0.13096121 -0.23029929]\n",
      "episode 382 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.89203101  1.        ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.          1.         -0.37142739]\n",
      "\taction [ 1.          1.         -0.36116299 -0.30753398]\n",
      "\taction [ 1.          1.         -0.50481266 -0.21349274]\n",
      "episode 383 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.61165679  1.        ]\n",
      "\taction [ 1.          1.         -0.17661449 -0.1660673 ]\n",
      "\taction [ 1.          1.          1.         -0.25860596]\n",
      "\taction [ 1.          1.          1.         -0.20801383]\n",
      "episode 384 at 1000 ts; done reached\n",
      "\taction [ 1.         1.        -0.5586372  1.       ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.         -0.5403024  -0.34771755]\n",
      "\taction [ 1.          1.         -0.41388598 -0.38396573]\n",
      "\taction [ 1.          1.          1.         -0.22132736]\n",
      "episode 385 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.78939718  1.        ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.         -0.37706184 -0.35068929]\n",
      "\taction [ 1.          1.         -0.22283566 -0.21289116]\n",
      "\taction [ 1.        1.        1.       -0.403249]\n",
      "episode 386 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.41901538  0.40588146]\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.          1.         -0.45408177]\n",
      "\taction [ 1.         1.         1.        -0.3962574]\n",
      "\taction [ 1.          1.         -0.41368243 -0.34690076]\n",
      "episode 387 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.83545691  1.        ]\n",
      "\taction [ 1.          1.          1.         -0.32943264]\n",
      "\taction [ 1.          1.          1.         -0.31338799]\n",
      "\taction [ 1.          1.         -0.21033154 -0.42382127]\n",
      "episode 388 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.84554499  1.        ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.         1.         1.        -0.2884478]\n",
      "\taction [ 1.          1.          1.         -0.19939069]\n",
      "\taction [ 1.          1.         -0.16186491 -0.16713695]\n",
      "episode 389 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.3745029   0.95097291]\n",
      "reward 0.019999999552965164\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.         1.         1.        -0.2956863]\n",
      "\taction [ 1.          1.         -0.35308421 -0.50506103]\n",
      "\taction [ 1.          1.         -0.26703858 -0.40370825]\n",
      "episode 390 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.345687    0.69758219]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.          1.         -0.25576302]\n",
      "\taction [ 1.          1.          1.         -0.22839034]\n",
      "\taction [ 1.          1.         -0.24967127 -0.36356115]\n",
      "episode 391 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.50326604  0.33368006]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.          1.         -0.48275828 -0.30804309]\n",
      "\taction [ 1.          1.         -0.24894333 -0.34988883]\n",
      "\taction [ 1.          1.          1.         -0.33984661]\n",
      "episode 392 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.65258282  1.        ]\n",
      "\taction [ 1.          1.         -0.23533647 -0.32822338]\n",
      "\taction [ 1.          1.         -0.38200465 -0.12046719]\n",
      "\taction [ 1.          1.          1.         -0.44873682]\n",
      "episode 393 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.90473109  1.        ]\n",
      "\taction [ 1.          1.         -0.29045564 -0.41205531]\n",
      "\taction [ 1.          1.          1.         -0.38941959]\n",
      "\taction [ 1.          1.         -0.31333807 -0.30556616]\n",
      "episode 394 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.50006211  0.30302739]\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.          1.         -0.46995568]\n",
      "\taction [ 1.          1.          1.         -0.30276486]\n",
      "\taction [ 1.          1.          1.         -0.40771043]\n",
      "episode 395 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.71740663  1.        ]\n",
      "\taction [ 1.          1.          1.         -0.33765152]\n",
      "\taction [ 1.          1.          1.         -0.30993089]\n",
      "\taction [ 1.          1.         -0.28144491 -0.37082908]\n",
      "episode 396 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.36631048  0.37526667]\n",
      "\taction [ 1.         1.         1.        -0.2404346]\n",
      "\taction [ 1.          1.         -0.41220397 -0.28139916]\n",
      "\taction [ 1.          1.          1.         -0.40556565]\n",
      "episode 397 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.52770293  0.39901039]\n",
      "\taction [ 1.          1.         -0.17845325 -0.19631308]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.019999999552965164\n",
      "\taction [ 1.          1.          1.         -0.40195665]\n",
      "reward 0.029999999329447746\n",
      "\taction [ 1.          1.          1.         -0.19321176]\n",
      "episode 398 at 1000 ts; done reached\n",
      "\taction [ 1.          1.         -0.31992999  0.84574759]\n",
      "\taction [ 1.          1.         -0.25078246 -0.19430298]\n",
      "\taction [ 1.          1.         -0.17566338 -0.37090734]\n",
      "\taction [ 1.          1.         -0.27541086 -0.24833395]\n",
      "episode 399 at 1000 ts; done reached\n",
      "[0.09999999776482582, 0.1599999964237213, 0.25999999418854713, 0.12999999709427357, 0.08999999798834324, 0.2799999937415123, 0.3299999926239252, 0.20999999530613422, 0.0, 1.029999976977706, 0.1599999964237213, 0.0, 0.13999999687075615, 0.08999999798834324, 0.0, 0.14999999664723873, 0.2199999950826168, 0.2299999948590994, 0.0, 0.3499999921768904, 0.3999999910593033, 0.9999999776482582, 0.13999999687075615, 0.20999999530613422, 0.9899999778717756, 0.20999999530613422, 0.18999999575316906, 0.25999999418854713, 0.2299999948590994, 0.2899999935179949, 0.0, 0.05999999865889549, 0.36999999172985554, 0.24999999441206455, 0.41999999061226845, 0.0, 0.1599999964237213, 0.2799999937415123, 0.029999999329447746, 0.06999999843537807, 0.4999999888241291, 0.2799999937415123, 0.2799999937415123, 0.5199999883770943, 0.0, 0.549999987706542, 0.6899999845772982, 0.7299999836832285, 0.47999998927116394, 0.25999999418854713, 0.08999999798834324, 0.0, 0.06999999843537807, 1.0599999763071537, 0.0, 0.5199999883770943, 0.3499999921768904, 0.2899999935179949, 0.08999999798834324, 0.3199999928474426, 0.1599999964237213, 0.05999999865889549, 0.08999999798834324, 0.0, 0.0, 0.0, 0.9299999792128801, 0.0, 0.2799999937415123, 0.029999999329447746, 0.3399999924004078, 0.5899999868124723, 0.0, 0.2899999935179949, 0.0, 0.14999999664723873, 0.30999999307096004, 0.5399999879300594, 0.5799999870359898, 0.07999999821186066, 0.0, 0.3799999915063381, 0.1699999962002039, 0.0, 0.0, 0.29999999329447746, 0.2799999937415123, 0.0, 0.41999999061226845, 0.5399999879300594, 0.0, 0.8199999816715717, 0.13999999687075615, 0.19999999552965164, 0.0, 0.4499999899417162, 0.36999999172985554, 0.7599999830126762, 0.20999999530613422, 0.1599999964237213, 0.9699999783188105, 0.6299999859184027, 0.6499999854713678, 0.0, 0.029999999329447746, 0.19999999552965164, 0.24999999441206455, 0.4999999888241291, 0.3299999926239252, 0.8799999803304672, 0.05999999865889549, 0.019999999552965164, 0.3199999928474426, 0.1699999962002039, 0.2299999948590994, 0.0, 0.8399999812245369, 0.9899999778717756, 0.8499999810010195, 1.1599999740719795, 0.3199999928474426, 0.2699999939650297, 0.3799999915063381, 0.5699999872595072, 0.669999985024333, 0.13999999687075615, 0.8299999814480543, 1.0799999758601189, 0.20999999530613422, 0.2899999935179949, 0.09999999776482582, 0.0, 0.0, 0.029999999329447746, 0.0, 0.2299999948590994, 0.1599999964237213, 0.0, 0.1599999964237213, 0.08999999798834324, 0.0, 0.06999999843537807, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1099999975413084, 0.3199999928474426, 0.0, 0.0, 0.13999999687075615, 0.1699999962002039, 0.07999999821186066, 0.17999999597668648, 0.0, 0.04999999888241291, 0.12999999709427357, 0.0, 0.0, 0.14999999664723873, 0.0, 0.0, 0.0, 0.05999999865889549, 0.2799999937415123, 0.0, 0.11999999731779099, 0.0, 0.0, 0.20999999530613422, 0.1099999975413084, 0.0, 0.0, 0.0, 1.0599999763071537, 0.2899999935179949, 0.25999999418854713, 0.36999999172985554, 0.3399999924004078, 0.08999999798834324, 0.11999999731779099, 0.0, 0.0, 0.0, 0.0, 0.1699999962002039, 0.0, 0.0, 0.0, 0.05999999865889549, 0.0, 0.2799999937415123, 0.14999999664723873, 0.0, 0.0, 0.13999999687075615, 0.03999999910593033, 0.1599999964237213, 0.17999999597668648, 0.08999999798834324, 0.0, 0.17999999597668648, 0.0, 0.09999999776482582, 0.18999999575316906, 0.2799999937415123, 0.17999999597668648, 0.29999999329447746, 0.0, 0.0, 0.06999999843537807, 0.06999999843537807, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06999999843537807, 0.18999999575316906, 0.0, 0.0, 0.08999999798834324, 0.0, 0.1699999962002039, 0.04999999888241291, 0.19999999552965164, 0.0, 0.0, 0.0, 0.2199999950826168, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03999999910593033, 0.14999999664723873, 0.07999999821186066, 0.1699999962002039, 0.05999999865889549, 0.1699999962002039, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03999999910593033, 0.12999999709427357, 0.08999999798834324, 0.1699999962002039, 0.1099999975413084, 0.0, 0.1099999975413084, 0.12999999709427357, 0.0, 0.0, 0.2699999939650297, 0.0, 0.08999999798834324, 0.08999999798834324, 0.0, 0.5699999872595072, 0.6399999856948853, 0.009999999776482582, 0.29999999329447746, 0.0, 0.0, 0.04999999888241291, 0.09999999776482582, 0.0, 0.0, 0.17999999597668648, 0.06999999843537807, 0.35999999195337296, 0.0, 0.09999999776482582, 0.07999999821186066, 0.0, 0.06999999843537807, 0.04999999888241291, 0.4899999890476465, 0.04999999888241291, 0.0, 0.0, 0.0, 0.2699999939650297, 0.36999999172985554, 0.03999999910593033, 0.0, 0.0, 0.0, 0.0, 0.1699999962002039, 0.0, 0.0, 0.0, 0.3799999915063381, 0.5899999868124723, 0.25999999418854713, 0.0, 1.0399999767541885, 0.0, 0.0, 0.20999999530613422, 0.04999999888241291, 0.0, 0.20999999530613422, 0.12999999709427357, 0.0, 0.0, 0.13999999687075615, 0.14999999664723873, 0.05999999865889549, 0.0, 0.0, 0.42999999038875103, 0.0, 0.2699999939650297, 0.0, 0.1099999975413084, 0.07999999821186066, 0.0, 0.3199999928474426, 0.0, 0.0, 0.11999999731779099, 0.07999999821186066, 0.1599999964237213, 0.0, 0.0, 0.2199999950826168, 0.0, 0.2199999950826168, 0.2299999948590994, 0.11999999731779099, 0.0, 0.20999999530613422, 0.0, 0.25999999418854713, 0.3399999924004078, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.019999999552965164, 0.0, 0.24999999441206455, 0.06999999843537807, 0.669999985024333, 0.0, 0.0, 0.5399999879300594, 0.0, 0.0, 0.0, 0.09999999776482582, 0.36999999172985554, 0.07999999821186066, 0.029999999329447746, 0.0, 0.08999999798834324, 0.19999999552965164, 0.549999987706542, 0.0, 0.09999999776482582, 0.06999999843537807, 0.0, 0.11999999731779099, 0.2899999935179949, 0.07999999821186066, 0.06999999843537807, 0.0, 0.13999999687075615, 0.23999999463558197, 0.06999999843537807, 0.0, 0.40999999083578587, 0.04999999888241291, 0.19999999552965164, 0.09999999776482582, 0.0, 0.0, 0.06999999843537807, 0.0, 0.0, 0.36999999172985554, 0.0]\n"
     ]
    }
   ],
   "source": [
    "import queue\n",
    "from collections import deque\n",
    "\n",
    "print_every = 300\n",
    "# seems to be 1000 for the env anyway\n",
    "max_ts = 2000\n",
    "max_episodes = 400\n",
    "curr_agent = agent.Agent(state_size, action_size)\n",
    "\n",
    "\n",
    "# can't use a queue.Queue because \"Insertion will block once this size has been reached, until queue items are consumed\"\n",
    "scores = deque(maxlen=100)                          # initialize the score (for each agent)\n",
    "scores_history = []\n",
    "\n",
    "\n",
    "# env expecting the list?\n",
    "# action not in the form env was expecting?\n",
    "\n",
    "# dropout too high?\n",
    "# why are all the negatives in a certain col? - dropout, not high enough experience? smthg wrong w adding experience?\n",
    "# changed dropout to 0, min_to_sample lower -> all same #s \n",
    "#     -> based on random, stay similar thru episodes that aren't learning!!\n",
    "\n",
    "episode_won_i = 0\n",
    "\n",
    "with active_session():\n",
    "    for i in range(max_episodes):\n",
    "        # initialize for the start of the episode\n",
    "        env_info = env.reset(train_mode=True)[brain_name]      # reset the environment    \n",
    "        state = env_info.vector_observations[0]                  # get the current state (for each agent)\n",
    "        # resets the noise class variable\n",
    "        curr_agent.reset()\n",
    "        score = 0\n",
    "        \n",
    "        for t in range(max_ts):\n",
    "            action = curr_agent.act(state.astype('float32', copy=False))\n",
    "            \n",
    "            if t % print_every == 0:\n",
    "                print('\\taction', action)\n",
    "                \n",
    "            env_info = env.step(action)[brain_name]\n",
    "            reward = env_info.rewards[0]\n",
    "            if reward != 0:\n",
    "                print(\"reward\", reward)\n",
    "            next_state = env_info.vector_observations[0]\n",
    "            done = env_info.local_done[0]\n",
    "            \n",
    "            #score = score * curr_agent.Q_DISCOUNT + reward[0]\n",
    "            #score = score * curr_agent.Q_DISCOUNT + reward\n",
    "            score = score + reward\n",
    "\n",
    "            curr_agent.step(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "\n",
    "            # done is a vector\n",
    "            if done: \n",
    "            #if done[0]: \n",
    "                print(\"episode {} at {} ts; done reached\".format(i, t))\n",
    "                break\n",
    "        scores_history.append(score)\n",
    "        scores.append(score)\n",
    "        if i % print_every == 0:\n",
    "            print(\"episode {}; average score past 100 episodes: {}\".format(i, np.mean(scores)))\n",
    "        if np.mean(scores) >= 30:\n",
    "            episode_won_i = i\n",
    "            print(\"Solved in {} episodes\".format(episode_won_i))\n",
    "            curr_agent.save()\n",
    "            break\n",
    "            \n",
    "    print(scores_history)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff09a05fe48>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff09d9620b8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot of rewards\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(1,len(scores_history) +1 ), scores_history)\n",
    "\n",
    "#plt.plot(range(1,len(scores) +1 ), scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'agent' from '/home/workspace/agent.py'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  A few **important notes**:\n",
    "- When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```\n",
    "- To structure your work, you're welcome to work directly in this Jupyter notebook, or you might like to start over with a new file!  You can see the list of files in the workspace by clicking on **_Jupyter_** in the top left corner of the notebook.\n",
    "- In this coding environment, you will not be able to watch the agents while they are training.  However, **_after training the agents_**, you can download the saved model weights to watch the agents on your own machine! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
