{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "You are welcome to use this coding environment to train your agent for the project.  Follow the instructions below to get started!\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "Run the next code cell to install a few packages.  This line will take a few minutes to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%aimport agent, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mipython 6.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.15, but you'll have prompt-toolkit 3.0.21 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environments corresponding to both versions of the environment are already saved in the Workspace and can be accessed at the file paths provided below.  \n",
    "\n",
    "Please select one of the two options below for loading the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "from workspace_utils import active_session\n",
    "\n",
    "# select this option to load version 1 (with a single agent) of the environment\n",
    "env = UnityEnvironment(file_name='/data/Reacher_One_Linux_NoVis/Reacher_One_Linux_NoVis.x86_64')\n",
    "\n",
    "# select this option to load version 2 (with 20 agents) of the environment\n",
    "# env = UnityEnvironment(file_name='/data/Reacher_Linux_NoVis/Reacher.x86_64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Size of each action: 4\n",
      "There are 1 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "   1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   5.75471878e+00  -1.00000000e+00\n",
      "   5.55726671e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "  -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,  -4.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,  -0.00000000e+00,  -0.00000000e+00,\n",
       "         -4.37113883e-08,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,  -1.00000000e+01,\n",
       "          0.00000000e+00,   1.00000000e+00,  -0.00000000e+00,\n",
       "         -0.00000000e+00,  -4.37113883e-08,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   5.75471878e+00,\n",
       "         -1.00000000e+00,   5.55726671e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,  -1.68164849e-01]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Note that **in this coding environment, you will not be able to watch the agents while they are training**, and you should set `train_mode=True` to restart the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'env_info = env.reset(train_mode=True)[brain_name]      # reset the environment    \\nstates = env_info.vector_observations                  # get the current state (for each agent)\\nscores = np.zeros(num_agents)                          # initialize the score (for each agent)\\niteration = 0\\nwhile True:\\n    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\\n    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\\n    print(\"\\t\", actions)\\n    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\\n    next_states = env_info.vector_observations         # get next state (for each agent)\\n    rewards = env_info.rewards                         # get reward (for each agent)\\n    if rewards[0] != 0:\\n        print(\"rewards\", rewards)\\n    dones = env_info.local_done                        # see if episode finished\\n    scores += env_info.rewards                         # update the score (for each agent)\\n    states = next_states                               # roll over states to next time step\\n    if np.any(dones):                                  # exit loop if episode finished\\n        print(iteration)\\n        break\\n    iteration += 1\\nprint(\\'Total score (averaged over agents) this episode: {}\\'.format(np.mean(scores)))\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''env_info = env.reset(train_mode=True)[brain_name]      # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "iteration = 0\n",
    "while True:\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    print(\"\\t\", actions)\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    if rewards[0] != 0:\n",
    "        print(\"rewards\", rewards)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        print(iteration)\n",
    "        break\n",
    "    iteration += 1\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  \\nimport queue\\nfrom collections import deque\\n\\nprint_every = 200\\n# seems to be 1000 for the env anyway\\nmax_ts = 2000\\nmax_episodes = 1000\\ncurr_agent = agent.Agent(state_size, action_size)\\n\\nenv_info = env.reset(train_mode=True)[brain_name]      # reset the environment    \\nstate = env_info.vector_observations[0]                  # get the current state (for each agent)\\n# can\\'t use a queue.Queue because \"Insertion will block once this size has been reached, until queue items are consumed\"\\nscores = deque(maxlen=100)                          # initialize the score (for each agent)\\nscores_history = []\\n\\nepisode_won_i = 0\\n\\nwith active_session():\\n    # TODO: maybe set max # of episodes\\n    for i in range(max_episodes):\\n        score = 0\\n        for t in range(max_ts):\\n            action = curr_agent.act(state.astype(\\'float32\\', copy=False))\\n            \\n            # because random numpy actions at the beginning are already numpy\\n            \\n            try:\\n                action = action.to(\"cpu\").detach().numpy()\\n            except:\\n                pass\\n            if t % print_every == 0:\\n                print(\\'\\taction\\', action)\\n            env_info = env.step(action)[brain_name]\\n            reward = env_info.rewards[0]\\n            if reward != 0:\\n                print(\"reward\", reward)\\n            next_state = env_info.vector_observations[0]\\n            done = env_info.local_done[0]\\n            \\n            score = score * curr_agent.Q_DISCOUNT + reward\\n\\n            curr_agent.step(state, action, reward, next_state, done)\\n\\n\\n            if done: \\n                print(\"episode {} at {} ts; done reached\".format(i, t))\\n                break\\n        scores_history.append(score)\\n        scores.append(score)\\n        if i % print_every == 0:\\n            print(\"episode {}; average score past 100 episodes: {}\".format(i, np.mean(scores)))\\n        if np.mean(scores) >= 30:\\n            episode_won_i = i\\n            print(\"Solved in {} episodes\".format(episode_won_i))\\n            curr_agent.save()\\n            break\\n        \\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''  \n",
    "import queue\n",
    "from collections import deque\n",
    "\n",
    "print_every = 200\n",
    "# seems to be 1000 for the env anyway\n",
    "max_ts = 2000\n",
    "max_episodes = 1000\n",
    "curr_agent = agent.Agent(state_size, action_size)\n",
    "\n",
    "env_info = env.reset(train_mode=True)[brain_name]      # reset the environment    \n",
    "state = env_info.vector_observations[0]                  # get the current state (for each agent)\n",
    "# can't use a queue.Queue because \"Insertion will block once this size has been reached, until queue items are consumed\"\n",
    "scores = deque(maxlen=100)                          # initialize the score (for each agent)\n",
    "scores_history = []\n",
    "\n",
    "episode_won_i = 0\n",
    "\n",
    "with active_session():\n",
    "    # TODO: maybe set max # of episodes\n",
    "    for i in range(max_episodes):\n",
    "        score = 0\n",
    "        for t in range(max_ts):\n",
    "            action = curr_agent.act(state.astype('float32', copy=False))\n",
    "            \n",
    "            # because random numpy actions at the beginning are already numpy\n",
    "            \n",
    "            try:\n",
    "                action = action.to(\"cpu\").detach().numpy()\n",
    "            except:\n",
    "                pass\n",
    "            if t % print_every == 0:\n",
    "                print('\\taction', action)\n",
    "            env_info = env.step(action)[brain_name]\n",
    "            reward = env_info.rewards[0]\n",
    "            if reward != 0:\n",
    "                print(\"reward\", reward)\n",
    "            next_state = env_info.vector_observations[0]\n",
    "            done = env_info.local_done[0]\n",
    "            \n",
    "            score = score * curr_agent.Q_DISCOUNT + reward\n",
    "\n",
    "            curr_agent.step(state, action, reward, next_state, done)\n",
    "\n",
    "\n",
    "            if done: \n",
    "                print(\"episode {} at {} ts; done reached\".format(i, t))\n",
    "                break\n",
    "        scores_history.append(score)\n",
    "        scores.append(score)\n",
    "        if i % print_every == 0:\n",
    "            print(\"episode {}; average score past 100 episodes: {}\".format(i, np.mean(scores)))\n",
    "        if np.mean(scores) >= 30:\n",
    "            episode_won_i = i\n",
    "            print(\"Solved in {} episodes\".format(episode_won_i))\n",
    "            curr_agent.save()\n",
    "            break\n",
    "        \n",
    "'''     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\taction [ 0.01396207  0.06307286  0.09043477  0.1127754 ]\n",
      "\taction [-0.32899454  1.         -0.19964397 -0.24771798]\n",
      "\taction [-0.10395262  1.         -0.16794744  1.        ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "\taction [-0.22072846  1.          0.48670959 -0.33961049]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "episode 0 at 1000 ts; done reached\n",
      "episode 0; average score past 100 episodes: 0.19999999552965164\n",
      "\taction [-0.88078493  1.          1.          0.83279395]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [-0.39198765  1.          1.          1.        ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [-0.35052234  1.          1.         -0.398707  ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [-0.13392462  1.          1.         -0.44162911]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.009999999776482582\n",
      "reward 0.029999999329447746\n",
      "episode 1 at 1000 ts; done reached\n",
      "\taction [-0.97799253  1.          1.         -0.87142044]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [-0.35087287  1.          1.         -0.18374343]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [-0.28008398  1.          1.         -0.45897707]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [-0.44462836  1.          1.         -0.5201506 ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "episode 2 at 1000 ts; done reached\n",
      "\taction [-0.93865877  1.          1.         -0.97995239]\n",
      "reward 0.009999999776482582\n",
      "reward 0.019999999552965164\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [-0.33479375  1.          1.         -0.34031814]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.019999999552965164\n",
      "\taction [-0.41177484  1.          1.         -0.42692068]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [-0.26571822  1.          1.         -0.47532183]\n",
      "episode 3 at 1000 ts; done reached\n",
      "\taction [-0.98710531  1.          1.         -0.86337578]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [-0.32934111  1.          1.         -0.29282686]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [-0.4438549   1.          1.         -0.40478382]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [-0.44889876  1.          1.         -0.35741612]\n",
      "episode 4 at 1000 ts; done reached\n",
      "\taction [-0.94853675  1.          1.         -0.8699559 ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [-0.61661524  1.          1.         -0.21233316]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [-0.15985997  1.          1.         -0.34816822]\n",
      "\taction [-0.36013702  1.          1.         -0.24105535]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "episode 5 at 1000 ts; done reached\n",
      "\taction [ 1.          1.          1.         -0.94437701]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [-0.50409955  1.          1.         -0.3956238 ]\n",
      "\taction [-0.34871006  1.          1.         -0.45569044]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [-0.25943854  1.          1.         -0.13120617]\n",
      "episode 6 at 1000 ts; done reached\n",
      "\taction [-0.82599121  1.          1.         -0.94449174]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [-0.22802092  1.          1.         -0.43946579]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.  1.  1.  1.]\n",
      "\taction [ 1.          1.          1.         -0.33646768]\n",
      "episode 7 at 1000 ts; done reached\n",
      "\taction [ 1.          1.          1.         -0.89779609]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [ 1.  1.  1.  1.]\n",
      "\taction [ 1.          1.          1.         -0.20949505]\n",
      "\taction [-0.31963164  1.          1.         -0.21381128]\n",
      "episode 8 at 1000 ts; done reached\n",
      "\taction [-0.97556895  1.          1.         -0.99772298]\n",
      "\taction [-0.49681613  1.          1.         -0.37229615]\n",
      "\taction [-0.45391759  1.          1.         -0.36003315]\n",
      "\taction [-0.37002021  1.          1.         -0.47195402]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "episode 9 at 1000 ts; done reached\n",
      "\taction [-0.94188517  1.          1.         -0.98365664]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [-0.55673379  1.          1.         -0.14792208]\n",
      "\taction [-0.42934525  1.          1.         -0.22293507]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [-0.34373206  1.          1.         -0.34159422]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "episode 10 at 1000 ts; done reached\n",
      "\taction [-0.88234419  1.          1.         -0.99515933]\n",
      "\taction [-0.14764459  1.          1.         -0.49359664]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.          1.         -0.41492879]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.          1.         -0.44294453]\n",
      "episode 11 at 1000 ts; done reached\n",
      "\taction [ 1.          1.          1.         -0.97978199]\n",
      "\taction [ 1.          1.          1.         -0.30408761]\n",
      "\taction [ 1.         1.         1.        -0.2332094]\n",
      "\taction [ 1.          1.          1.         -0.36417058]\n",
      "episode 12 at 1000 ts; done reached\n",
      "\taction [ 1.          1.          1.         -0.95527643]\n",
      "\taction [ 1.          1.          1.         -0.24253388]\n",
      "\taction [ 1.          1.          1.         -0.37638846]\n",
      "\taction [ 1.          1.          1.         -0.37742379]\n",
      "episode 13 at 1000 ts; done reached\n",
      "\taction [ 1.          1.          1.         -0.84258944]\n",
      "\taction [ 1.          1.          1.         -0.19316317]\n",
      "\taction [ 1.          1.          1.         -0.26470476]\n",
      "\taction [ 1.          1.          1.         -0.38744712]\n",
      "episode 14 at 1000 ts; done reached\n",
      "\taction [ 1.          1.          1.         -0.98244542]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.          1.         -0.51572388]\n",
      "\taction [ 1.          1.          1.         -0.14718536]\n",
      "\taction [ 1.         1.         1.        -0.1397575]\n",
      "episode 15 at 1000 ts; done reached\n",
      "\taction [ 1.          1.          1.         -0.98609936]\n",
      "\taction [ 1.          1.          1.         -0.23836054]\n",
      "\taction [ 1.          1.          1.         -0.33415657]\n",
      "\taction [ 1.          1.          1.         -0.37783882]\n",
      "episode 16 at 1000 ts; done reached\n",
      "\taction [ 1.          1.          1.         -0.86700994]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [ 1.          1.          1.         -0.30667654]\n",
      "\taction [ 1.          1.          1.         -0.27587309]\n",
      "\taction [-0.30748779  1.          1.         -0.21823585]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "episode 17 at 1000 ts; done reached\n",
      "\taction [-0.84041429  1.          1.         -0.86543471]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "\taction [-0.34481731  1.          1.         -0.48960015]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [-0.24930514  1.          1.         -0.37017632]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [-0.40397203  1.          1.         -0.38215366]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "episode 18 at 1000 ts; done reached\n",
      "\taction [-0.95475531  1.          1.         -0.91107929]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [-0.35281369  1.          1.         -0.17072172]\n",
      "\taction [-0.36137453  1.          1.         -0.34520385]\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [-0.47436854  1.          1.         -0.1939715 ]\n",
      "episode 19 at 1000 ts; done reached\n",
      "\taction [-0.94700146  1.          1.         -0.93038642]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [-0.48866376  1.          1.         -0.1954862 ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [-0.32266545  1.          1.         -0.41060942]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [-0.29048967  1.          1.         -0.41356382]\n",
      "episode 20 at 1000 ts; done reached\n",
      "\taction [-0.89109194  1.          1.         -0.89539832]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [-0.40516686  1.          1.         -0.44143245]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [-0.28652024  1.          1.         -0.2333059 ]\n",
      "\taction [-0.22537588  1.          1.         -0.41784883]\n",
      "episode 21 at 1000 ts; done reached\n",
      "\taction [-0.97308666  1.          1.         -0.88091272]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [-0.31316546  1.          1.         -0.31773701]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [-0.51873863  1.          1.         -0.3801012 ]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [-0.24390869  1.          1.         -0.43138149]\n",
      "episode 22 at 1000 ts; done reached\n",
      "\taction [-0.89592326  1.          1.         -0.82125849]\n",
      "\taction [-0.24041955  1.          1.         -0.33166766]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [-0.46376336  1.          1.         -0.20333757]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\taction [-0.3189857   1.          1.         -0.46384257]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "episode 23 at 1000 ts; done reached\n",
      "\taction [-0.97034353  1.          1.         -0.92773193]\n",
      "\taction [-0.40436304  1.          1.         -0.43008164]\n",
      "reward 0.019999999552965164\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [-0.28112468  1.          1.         -0.24963924]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "\taction [-0.27568328  1.          1.         -0.22324754]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "episode 24 at 1000 ts; done reached\n",
      "\taction [-0.95625544  1.          1.         -0.87490231]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [-0.37207428  1.          1.         -0.2293534 ]\n",
      "\taction [-0.22063448  1.          1.         -0.53354293]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [-0.26759112  1.          1.         -0.29965842]\n",
      "episode 25 at 1000 ts; done reached\n",
      "\taction [-0.86705667  1.          1.         -0.81962055]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [-0.46710697  1.          1.         -0.45422083]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [-0.30798492  1.          1.         -0.36992082]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [-0.28545067  1.          1.         -0.2121155 ]\n",
      "episode 26 at 1000 ts; done reached\n",
      "\taction [-0.90799379  1.          1.         -0.88348657]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [-0.39950338  1.          1.         -0.54612714]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [-0.10012951  1.          1.         -0.40273318]\n",
      "\taction [-0.37652981  1.          1.         -0.35163245]\n",
      "episode 27 at 1000 ts; done reached\n",
      "\taction [-0.84943652  1.          1.         -0.9466958 ]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [-0.54195708  1.          1.         -0.39962941]\n",
      "\taction [-0.33362144  1.          1.         -0.28001079]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [-0.17244731  1.          1.         -0.42760256]\n",
      "episode 28 at 1000 ts; done reached\n",
      "\taction [-0.81556296  1.          1.         -0.97704738]\n",
      "\taction [-0.4901894   1.          1.         -0.31686854]\n",
      "\taction [-0.18166733  1.          1.         -0.30324334]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [-0.32499424  1.          1.         -0.17863515]\n",
      "episode 29 at 1000 ts; done reached\n",
      "\taction [-0.80224723  1.          1.         -0.84047604]\n",
      "\taction [-0.43860698  1.          1.         -0.43549708]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [-0.50815952  1.          1.         -0.37560901]\n",
      "reward 0.019999999552965164\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [-0.23908789  1.          1.         -0.29383045]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "episode 30 at 1000 ts; done reached\n",
      "\taction [-0.9831422   1.          1.         -0.95400959]\n",
      "\taction [-0.46132103  1.          1.         -0.17731605]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [-0.18814595  1.          1.         -0.29017061]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [-0.3554298   1.          1.         -0.39272985]\n",
      "episode 31 at 1000 ts; done reached\n",
      "\taction [-0.90974689  1.          1.         -0.83182752]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [-0.28705302  1.          1.         -0.39716047]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [-0.25091639  1.          1.         -0.31429878]\n",
      "\taction [-0.26534113  1.          1.         -0.25073755]\n",
      "episode 32 at 1000 ts; done reached\n",
      "\taction [-0.86259526  1.          1.         -0.80957997]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [-0.42679226  1.          1.         -0.15984084]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [-0.26316771  1.          1.         -0.24692346]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [-0.42439076  1.          1.         -0.3686749 ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "episode 33 at 1000 ts; done reached\n",
      "\taction [-0.99382079  1.          1.         -0.84832412]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [-0.42568231  1.          1.         -0.45814747]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [-0.06957445  1.          1.         -0.32541519]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [-0.12047474  1.          1.         -0.24623431]\n",
      "episode 34 at 1000 ts; done reached\n",
      "\taction [-0.82544607  1.          1.         -0.87238699]\n",
      "\taction [-0.19062348  1.          1.         -0.33151665]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [-0.26345038  1.          1.         -0.39943138]\n",
      "\taction [-0.39848265  1.          1.         -0.20365049]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "episode 35 at 1000 ts; done reached\n",
      "\taction [-0.92692673  1.          1.         -0.95058137]\n",
      "\taction [-0.41017127  1.          1.         -0.48328912]\n",
      "reward 0.019999999552965164\n",
      "\taction [-0.37901872  1.          1.         -0.60501087]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "reward 0.029999999329447746\n",
      "reward 0.029999999329447746\n",
      "\taction [-0.14241987  1.          1.         -0.44506279]\n",
      "episode 36 at 1000 ts; done reached\n",
      "\taction [-0.8787657   1.          1.         -0.81142789]\n",
      "reward 0.019999999552965164\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [-0.35938004  1.          1.         -0.54689264]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [-0.41002727  1.          1.         -0.33206931]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [-0.26152492  1.          1.         -0.38306451]\n",
      "episode 37 at 1000 ts; done reached\n",
      "\taction [-0.96365631  1.          1.         -0.89552784]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [-0.34523585  1.          1.         -0.21703583]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [-0.38408828  1.          1.         -0.11790707]\n",
      "\taction [-0.46948725  1.          1.         -0.33190358]\n",
      "reward 0.009999999776482582\n",
      "reward 0.009999999776482582\n",
      "reward 0.019999999552965164\n",
      "episode 38 at 1000 ts; done reached\n",
      "\taction [-0.80248797  1.          1.         -0.93173647]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [-0.34259805  1.          1.         -0.5172599 ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [-0.41939458 -0.41044119 -0.42690119 -0.43524992]\n",
      "\taction [-0.51785886 -0.32290888 -0.45347714 -0.17218752]\n",
      "episode 39 at 1000 ts; done reached\n",
      "\taction [-0.95146704 -0.93106627 -0.89203095 -0.95371848]\n",
      "\taction [-0.2671006  -0.15085104 -0.40343761 -0.09760676]\n",
      "\taction [-0.39727861 -0.28931746 -0.2459832  -0.37033853]\n",
      "\taction [-0.29486021 -0.67261839 -0.49979919 -0.40986049]\n",
      "episode 40 at 1000 ts; done reached\n",
      "\taction [-0.82617313 -0.99188316 -0.98716831 -0.82235754]\n",
      "\taction [-0.49185899 -0.31390527 -0.06823954 -0.42905301]\n",
      "\taction [-0.35124004 -0.28205296 -0.33882207 -0.4552359 ]\n",
      "\taction [-0.3117114  -0.29288241 -0.39851817 -0.2420622 ]\n",
      "episode 41 at 1000 ts; done reached\n",
      "\taction [-0.82256228 -0.91794121 -0.93578392 -0.80448985]\n",
      "\taction [-0.39052495 -0.24150085 -0.23659833 -0.28164789]\n",
      "\taction [-0.34781119 -0.28283268 -0.28849116 -0.25044698]\n",
      "\taction [-0.15887967 -0.22105391 -0.35016796 -0.25876141]\n",
      "episode 42 at 1000 ts; done reached\n",
      "\taction [-0.93668234 -0.89359462 -0.81758499 -0.96830165]\n",
      "\taction [-0.24581718 -0.34039843 -0.33259833 -0.22370307]\n",
      "\taction [-0.24367456 -0.29775351 -0.34546247 -0.2922689 ]\n",
      "\taction [-0.3725546  -0.52338517 -0.39183617 -0.20821606]\n",
      "episode 43 at 1000 ts; done reached\n",
      "\taction [-0.90844333 -0.81403846 -0.87920022 -0.98425519]\n",
      "\taction [-0.40280399 -0.47680417 -0.22731479 -0.32622272]\n",
      "\taction [-0.40410396 -0.24985856 -0.2982325  -0.30790305]\n",
      "\taction [-0.41913939 -0.37273547 -0.39416867 -0.22936545]\n",
      "episode 44 at 1000 ts; done reached\n",
      "\taction [-0.91493553 -0.8743515  -0.95456952 -0.98167652]\n",
      "\taction [-0.26987219 -0.19888553 -0.39746651 -0.13594559]\n",
      "\taction [-0.39523262 -0.34353554 -0.33730489 -0.42891923]\n",
      "\taction [-0.37396321 -0.40035132 -0.44834995 -0.24285649]\n",
      "episode 45 at 1000 ts; done reached\n",
      "\taction [-0.87726414 -0.95403981 -0.84331322 -0.99871033]\n",
      "\taction [-0.38696513 -0.51653719 -0.33367261 -0.35052681]\n",
      "\taction [-0.10273844 -0.24952763 -0.28077078 -0.43980017]\n",
      "\taction [-0.28743905 -0.21096477 -0.41476461 -0.50822532]\n",
      "episode 46 at 1000 ts; done reached\n",
      "\taction [-0.966344   -0.99860978 -0.91897947 -0.9933461 ]\n",
      "\taction [-0.5006482  -0.43891221 -0.3148393  -0.23699409]\n",
      "\taction [-0.48351613 -0.22898385 -0.17547323 -0.10496064]\n",
      "\taction [-0.37022769 -0.42742455 -0.31504631 -0.33084613]\n",
      "episode 47 at 1000 ts; done reached\n",
      "\taction [-0.95174825 -0.84242082 -0.80921119 -0.99483806]\n",
      "\taction [-0.3106564  -0.26816034 -0.05548542 -0.26715103]\n",
      "\taction [-0.33567959 -0.26621279 -0.29403999 -0.24247777]\n",
      "\taction [-0.28368652 -0.2455928  -0.24305695 -0.22165763]\n",
      "episode 48 at 1000 ts; done reached\n",
      "\taction [-0.99010313 -0.90514791 -0.9255349  -0.99175495]\n",
      "\taction [-0.32726571 -0.39624697 -0.48940003 -0.51317787]\n",
      "\taction [-0.36051038 -0.45642    -0.26498652 -0.23472695]\n",
      "\taction [-0.25006682 -0.13759032 -0.1499913  -0.36221865]\n",
      "episode 49 at 1000 ts; done reached\n",
      "\taction [-0.95402944 -0.85961747 -0.93658561 -0.92969626]\n",
      "\taction [-0.44404775 -0.20663573 -0.41612265 -0.40243763]\n",
      "\taction [-0.32022351 -0.38061115 -0.41208076 -0.42688218]\n",
      "\taction [-0.46034002 -0.44066241 -0.28126466 -0.46529728]\n",
      "episode 50 at 1000 ts; done reached\n",
      "\taction [-0.99337202 -0.82863444 -0.84189326 -0.84351939]\n",
      "\taction [-0.34209743 -0.53253222 -0.39289382 -0.47887114]\n",
      "\taction [-0.34848967 -0.22382906 -0.48339155 -0.37057474]\n",
      "\taction [-0.22681183 -0.29817289 -0.35355037 -0.21641336]\n",
      "episode 51 at 1000 ts; done reached\n",
      "\taction [-0.98768234 -0.83695704 -0.80504042 -0.92368662]\n",
      "\taction [-0.2555289  -0.25468931 -0.36188823 -0.58393639]\n",
      "\taction [-0.3837609  -0.27849215 -0.28314587 -0.44785538]\n",
      "\taction [-0.26272199 -0.22291547 -0.42764798 -0.20623383]\n",
      "episode 52 at 1000 ts; done reached\n",
      "\taction [-0.93958634 -0.9166643  -0.91315526 -0.93975198]\n",
      "\taction [-0.29593787 -0.37957641 -0.36107117 -0.27580678]\n",
      "\taction [-0.34915522 -0.25081098 -0.17163876 -0.2326244 ]\n",
      "\taction [-0.26082316 -0.48801959 -0.24168725 -0.34548515]\n",
      "episode 53 at 1000 ts; done reached\n",
      "\taction [-0.998133   -0.96793288 -0.93373436 -0.80552   ]\n",
      "\taction [-0.13459304 -0.37293366 -0.38637012 -0.41294837]\n",
      "\taction [-0.49991223 -0.35165033 -0.43814096 -0.15425609]\n",
      "\taction [-0.18540606 -0.17220958 -0.46820936 -0.30541402]\n",
      "episode 54 at 1000 ts; done reached\n",
      "\taction [-0.85240829 -0.90059853 -0.96683031 -0.93530387]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\taction [-0.24412587 -0.36106548 -0.28875864 -0.25428158]\n",
      "\taction [-0.42752585 -0.301781   -0.43040171 -0.36993742]\n",
      "\taction [-0.4802255  -0.45556042 -0.30728942 -0.33210236]\n",
      "episode 55 at 1000 ts; done reached\n",
      "\taction [-0.88769525 -0.863796   -0.97307462 -0.98103923]\n",
      "\taction [-0.40512887 -0.37493715 -0.55064148 -0.46619755]\n",
      "\taction [-0.22593774 -0.49158064 -0.33622631 -0.3763383 ]\n",
      "\taction [-0.4436287  -0.33196145 -0.39610082 -0.23390287]\n",
      "episode 56 at 1000 ts; done reached\n",
      "\taction [-0.88545811 -0.8081193  -0.92854124 -0.8181324 ]\n",
      "\taction [-0.49850512 -0.10397314 -0.31107873 -0.54746616]\n",
      "\taction [-0.4051975  -0.38841668 -0.32607543 -0.38029727]\n",
      "\taction [-0.43997607 -0.31572649 -0.47838852 -0.28684103]\n",
      "episode 57 at 1000 ts; done reached\n",
      "\taction [-0.85961711 -0.93725008 -0.91119939 -0.80631435]\n",
      "\taction [-0.240197   -0.4341231  -0.45478678 -0.36882839]\n",
      "\taction [-0.39233571 -0.16450913 -0.32596451 -0.44839931]\n",
      "\taction [-0.43031192 -0.27543139 -0.36061904 -0.18336385]\n",
      "episode 58 at 1000 ts; done reached\n",
      "\taction [-0.92047119 -0.93058896 -0.90746039 -0.90366304]\n",
      "\taction [-0.20710869 -0.31981033 -0.42894086 -0.19917135]\n",
      "\taction [-0.38649982 -0.26526618 -0.5378083  -0.21205252]\n",
      "\taction [-0.47886923 -0.26327148 -0.32088628 -0.41207272]\n",
      "episode 59 at 1000 ts; done reached\n",
      "\taction [-0.990861   -0.82759398 -0.90497744 -0.85146087]\n",
      "\taction [-0.2966952  -0.42767695 -0.20790052 -0.35320172]\n",
      "\taction [-0.20393939 -0.42998588 -0.238539   -0.42736319]\n",
      "\taction [-0.31003851 -0.43307731 -0.1684949  -0.44864795]\n",
      "episode 60 at 1000 ts; done reached\n",
      "\taction [-0.82214028 -0.90524262 -0.87963891 -0.93625367]\n",
      "\taction [-0.21330363 -0.29582331 -0.2599335  -0.33247617]\n",
      "\taction [-0.22715874 -0.51511282 -0.25717533 -0.17829646]\n",
      "\taction [-0.24068226 -0.3948026  -0.45370159 -0.19570169]\n",
      "episode 61 at 1000 ts; done reached\n",
      "\taction [-0.82727253 -0.84169489 -0.877105   -0.85699707]\n",
      "\taction [-0.11280266 -0.12895566 -0.23348722 -0.28003398]\n",
      "\taction [-0.39554781 -0.47802034 -0.61607242 -0.26508552]\n",
      "\taction [-0.41529277 -0.20208347 -0.48139009 -0.2807312 ]\n",
      "episode 62 at 1000 ts; done reached\n",
      "\taction [-0.82066828 -0.88665003 -0.86511469 -0.84186029]\n",
      "\taction [-0.46671474 -0.22580291 -0.34962142 -0.41258869]\n",
      "\taction [-0.27041793 -0.31477791 -0.26465866 -0.38576508]\n",
      "\taction [-0.38029861 -0.25815919 -0.26078525 -0.24067718]\n",
      "episode 63 at 1000 ts; done reached\n",
      "\taction [-0.83309853 -0.92116654 -0.93004948 -0.95280874]\n",
      "\taction [-0.13198602 -0.39811534 -0.44936439 -0.22199701]\n",
      "\taction [-0.23684523 -0.20158044 -0.52651191 -0.32310808]\n",
      "\taction [-0.35463268 -0.20804489 -0.39898762 -0.35292894]\n",
      "episode 64 at 1000 ts; done reached\n",
      "\taction [-0.97768718 -0.99121547 -0.93047887 -0.868186  ]\n",
      "\taction [-0.31487998 -0.2814295  -0.59170818 -0.23124699]\n",
      "\taction [-0.28187904 -0.22113204 -0.30753464 -0.39348847]\n",
      "\taction [-0.3750836  -0.23912902 -0.2108309  -0.22870573]\n",
      "episode 65 at 1000 ts; done reached\n",
      "\taction [-0.83272809 -0.93105102 -0.8109709  -0.8131693 ]\n",
      "\taction [-0.33069235 -0.44229051 -0.22543827 -0.22438721]\n",
      "\taction [-0.48444736 -0.24724573 -0.26195043 -0.04355625]\n",
      "\taction [-0.3642191  -0.42464986 -0.18272375 -0.28797731]\n",
      "episode 66 at 1000 ts; done reached\n",
      "\taction [-0.92108667 -0.99652189 -0.96412432 -0.90847778]\n",
      "\taction [-0.42402849 -0.25931916 -0.18549767 -0.38396308]\n",
      "\taction [-0.18505774 -0.28019482 -0.56205302 -0.33463931]\n",
      "\taction [-0.29517365 -0.14156181 -0.47128227 -0.36821648]\n",
      "episode 67 at 1000 ts; done reached\n",
      "\taction [-0.85445279 -0.91792965 -0.90941954 -0.8147136 ]\n",
      "\taction [-0.47698584 -0.31196025 -0.20278811 -0.31226626]\n",
      "\taction [-0.46982381 -0.35671586 -0.23968999 -0.44352549]\n",
      "\taction [-0.29249626 -0.17460468 -0.42099306 -0.16242798]\n",
      "episode 68 at 1000 ts; done reached\n",
      "\taction [-0.82557774 -0.91272533 -0.88005978 -0.82113469]\n",
      "\taction [-0.19972198 -0.40448084 -0.34667537 -0.23334748]\n",
      "\taction [-0.35872653 -0.19529665 -0.31924444 -0.34857112]\n",
      "\taction [-0.32211447 -0.56053555 -0.3318049  -0.33855781]\n",
      "episode 69 at 1000 ts; done reached\n",
      "\taction [-0.9753713  -0.94164485 -0.89901751 -0.82754707]\n",
      "\taction [-0.37399784 -0.25653017 -0.30229431 -0.46030751]\n",
      "\taction [-0.49617216 -0.41346583 -0.19738212 -0.29543531]\n",
      "\taction [-0.3517971  -0.46165401 -0.26743376 -0.10905556]\n",
      "episode 70 at 1000 ts; done reached\n",
      "\taction [-0.82535493 -0.8999815  -0.82303703 -0.94401944]\n",
      "\taction [-0.52551174 -0.59734625 -0.40863907 -0.3818385 ]\n",
      "\taction [-0.33019155 -0.25335485 -0.31767833 -0.15325053]\n",
      "\taction [-0.34261337 -0.39314705 -0.19922651 -0.21531643]\n",
      "episode 71 at 1000 ts; done reached\n",
      "\taction [-0.84887427 -0.99584937 -0.9385426  -0.90116149]\n",
      "\taction [-0.46377924 -0.47854149 -0.21092553 -0.33346331]\n",
      "\taction [-0.47048295 -0.2188281  -0.30820164 -0.30586538]\n",
      "\taction [-0.51300055 -0.28700164 -0.28621361 -0.38332465]\n",
      "episode 72 at 1000 ts; done reached\n",
      "\taction [-0.98661864 -0.96761191 -0.89813143 -0.91295731]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [-0.29327956 -0.41373613 -0.37439352 -0.35087061]\n",
      "\taction [-0.28377751 -0.22959025 -0.18354231 -0.35596436]\n",
      "\taction [-0.45752507 -0.31106085 -0.13458519 -0.49160931]\n",
      "episode 73 at 1000 ts; done reached\n",
      "\taction [-0.82629466 -0.85049075 -0.90508628 -0.95489138]\n",
      "\taction [-0.30696186 -0.15509908 -0.51207727 -0.51704788]\n",
      "\taction [-0.27502686 -0.2130712  -0.40296534 -0.32203835]\n",
      "\taction [-0.37540179 -0.21195808 -0.40702564 -0.38031796]\n",
      "episode 74 at 1000 ts; done reached\n",
      "\taction [-0.9183858  -0.9415251  -0.88830197 -0.99150389]\n",
      "\taction [-0.39484769 -0.3472392  -0.32087719 -0.33739182]\n",
      "\taction [-0.44922006 -0.37803891 -0.37756279 -0.32637495]\n",
      "\taction [-0.53590316 -0.40391374 -0.38881278 -0.38354942]\n",
      "episode 75 at 1000 ts; done reached\n",
      "\taction [-0.9978295  -0.86666214 -0.90797281 -0.86679083]\n",
      "\taction [-0.36088213 -0.24188991 -0.34534913 -0.1779007 ]\n",
      "\taction [-0.19950405 -0.5234828  -0.38673502 -0.33432251]\n",
      "\taction [-0.36631441 -0.24496011 -0.2715241  -0.29300323]\n",
      "episode 76 at 1000 ts; done reached\n",
      "\taction [-0.87805557 -0.91162384 -0.91116005 -0.87269372]\n",
      "\taction [-0.36341295 -0.36781129 -0.34226528 -0.2153789 ]\n",
      "\taction [-0.20546459 -0.32966173 -0.39455289 -0.27079552]\n",
      "\taction [-0.41581583 -0.27490395 -0.39943847 -0.04394352]\n",
      "episode 77 at 1000 ts; done reached\n",
      "\taction [-0.92810524 -0.90112078 -0.91713119 -0.80189222]\n",
      "\taction [-0.365042   -0.15069991 -0.35795206 -0.47328946]\n",
      "\taction [-0.39984086 -0.50326467 -0.42098033 -0.4900009 ]\n",
      "\taction [-0.47338203 -0.34759662 -0.37396732 -0.45904294]\n",
      "episode 78 at 1000 ts; done reached\n",
      "\taction [-0.967417   -0.81826729 -0.89629376 -0.80196589]\n",
      "\taction [-0.34176889 -0.47601953 -0.30107996 -0.53852296]\n",
      "\taction [-0.47076526 -0.44559357 -0.27001047 -0.31391886]\n",
      "\taction [-0.39491674 -0.38162085 -0.29643852 -0.49296552]\n",
      "episode 79 at 1000 ts; done reached\n",
      "\taction [-0.88187903 -0.94597596 -0.86364174 -0.94760841]\n",
      "\taction [-0.37314627 -0.47311947 -0.45030868 -0.21988426]\n",
      "\taction [-0.34921187 -0.48325485 -0.43143544 -0.32719934]\n",
      "\taction [-0.42019418 -0.41367707 -0.45100841 -0.25035203]\n",
      "episode 80 at 1000 ts; done reached\n",
      "\taction [-0.90357673 -0.93435979 -0.97442043 -0.93764776]\n",
      "\taction [-0.16992904 -0.38755473 -0.3508364  -0.16310383]\n",
      "\taction [-0.44560614 -0.41843536 -0.20509204 -0.34672228]\n",
      "\taction [-0.13511074 -0.46877736 -0.29944193 -0.30559754]\n",
      "episode 81 at 1000 ts; done reached\n",
      "\taction [-0.83437568 -0.88646895 -0.89388871 -0.87826383]\n",
      "\taction [-0.35868216 -0.2444896  -0.29170105 -0.25403222]\n",
      "\taction [-0.34716091 -0.33929983 -0.43522018 -0.59854913]\n",
      "\taction [-0.35274437 -0.47432435 -0.35434929 -0.29782313]\n",
      "episode 82 at 1000 ts; done reached\n",
      "\taction [-0.8661375  -0.81807715 -0.97453094 -0.87597901]\n",
      "\taction [-0.40439877 -0.29620916 -0.32715815 -0.43070787]\n",
      "\taction [-0.4832558  -0.23295107 -0.25036183 -0.26912978]\n",
      "\taction [-0.2299915  -0.51094311 -0.27869558 -0.48032758]\n",
      "episode 83 at 1000 ts; done reached\n",
      "\taction [-0.81225556 -0.87063408 -0.94745904 -0.97994971]\n",
      "\taction [-0.29429096 -0.21846533 -0.21322258 -0.28447089]\n",
      "\taction [-0.32397389 -0.11626779 -0.4508478  -0.37526026]\n",
      "\taction [-0.30027437 -0.38071901 -0.20184857 -0.11412774]\n",
      "episode 84 at 1000 ts; done reached\n",
      "\taction [-0.87705773 -0.95384949 -0.92983788 -0.96924078]\n",
      "\taction [-0.55544978 -0.30664477 -0.42041996 -0.15737352]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\taction [-0.51697588 -0.53468704 -0.45920965 -0.54489011]\n",
      "\taction [-0.34941736 -0.54861355 -0.17978631 -0.36886021]\n",
      "episode 85 at 1000 ts; done reached\n",
      "\taction [-0.96556967 -0.87776542 -0.98998535 -0.88910979]\n",
      "\taction [-0.34710026 -0.28078893 -0.20360821 -0.1416695 ]\n",
      "\taction [-0.40455937 -0.27063423 -0.31121501 -0.49714729]\n",
      "\taction [-0.25611019 -0.20915395 -0.42322519 -0.43254983]\n",
      "episode 86 at 1000 ts; done reached\n",
      "\taction [-0.90531641 -0.81399363 -0.90867019 -0.85600966]\n",
      "\taction [-0.19301762 -0.14497909 -0.29658458 -0.34092167]\n",
      "\taction [-0.40428057 -0.36419258 -0.50224036 -0.32839221]\n",
      "\taction [-0.42227247 -0.18795045 -0.15216997 -0.19000316]\n",
      "episode 87 at 1000 ts; done reached\n",
      "\taction [-0.81960082 -0.95063961 -0.87416774 -0.99202681]\n",
      "reward 0.029999999329447746\n",
      "reward 0.029999999329447746\n",
      "\taction [-0.28658283 -0.31468958 -0.27577415 -0.25726432]\n",
      "\taction [-0.32175413 -0.21149951 -0.29552746 -0.17962801]\n",
      "\taction [-0.21373256 -0.53205484 -0.12822369 -0.34773844]\n",
      "episode 88 at 1000 ts; done reached\n",
      "\taction [-0.86972821 -0.92628664 -0.86277139 -0.86971486]\n",
      "\taction [-0.50153643 -0.21641852 -0.28353786 -0.37169954]\n",
      "\taction [-0.28915018 -0.62917393 -0.31807271 -0.44056487]\n",
      "\taction [-0.30022293 -0.3355982  -0.47550535 -0.39144892]\n",
      "episode 89 at 1000 ts; done reached\n",
      "\taction [-0.80864644 -0.85548335 -0.95589942 -0.87376177]\n",
      "\taction [-0.26721713 -0.42250586 -0.47453943 -0.43809271]\n",
      "\taction [-0.49275818 -0.32162777 -0.34940198 -0.30538434]\n",
      "\taction [-0.29672492 -0.3677257  -0.44289249 -0.49543256]\n",
      "episode 90 at 1000 ts; done reached\n",
      "\taction [-0.94838405 -0.92523426 -0.86832869 -0.84087193]\n",
      "\taction [-0.43676195 -0.38003197 -0.46496615 -0.32731122]\n",
      "\taction [-0.33387372 -0.32172608 -0.28898573 -0.38353664]\n",
      "\taction [-0.47867373 -0.22040179 -0.50827688 -0.44602263]\n",
      "episode 91 at 1000 ts; done reached\n",
      "\taction [-0.88340205 -0.90910447 -0.80416429 -0.97982872]\n",
      "\taction [-0.48791769 -0.38133487 -0.30329123 -0.23242307]\n",
      "\taction [-0.39197508 -0.46860936 -0.4615165  -0.30823815]\n",
      "\taction [-0.33218175 -0.54581314 -0.45949158 -0.252554  ]\n",
      "episode 92 at 1000 ts; done reached\n",
      "\taction [-0.97103959 -0.8740024  -0.96726847 -0.98961216]\n",
      "\taction [-0.31608665 -0.50047326 -0.32767022 -0.1577421 ]\n",
      "\taction [-0.25736746 -0.14783096 -0.3086631  -0.30993113]\n",
      "\taction [-0.3892923  -0.3092978  -0.449058   -0.29181772]\n",
      "episode 93 at 1000 ts; done reached\n",
      "\taction [-0.92718118 -0.86199212 -0.83344692 -0.81632793]\n",
      "\taction [-0.28927898 -0.3002376  -0.37209344 -0.43031546]\n",
      "\taction [-0.33017319 -0.3151418  -0.53575748 -0.20091796]\n",
      "\taction [-0.19291188 -0.14481844 -0.33425012 -0.28176978]\n",
      "episode 94 at 1000 ts; done reached\n",
      "\taction [-0.92772007 -0.84957099 -0.99209219 -0.84567863]\n",
      "\taction [-0.47048509 -0.35045144 -0.36196357 -0.31116456]\n",
      "\taction [-0.23840745 -0.56809318 -0.24435839 -0.51595289]\n",
      "\taction [-0.42695293 -0.20375429 -0.38779604 -0.29127017]\n",
      "episode 95 at 1000 ts; done reached\n",
      "\taction [-0.81681138 -0.8931855  -0.81853724 -0.89401251]\n",
      "\taction [-0.51020366 -0.28606683 -0.24322028 -0.15632887]\n",
      "\taction [-0.24709357 -0.22529666 -0.32274213 -0.25067213]\n",
      "\taction [-0.37262693 -0.09865163 -0.30929756 -0.32393119]\n",
      "episode 96 at 1000 ts; done reached\n",
      "\taction [-0.99798656 -0.90328401 -0.90491539 -0.97141176]\n",
      "\taction [-0.10639233 -0.34902552 -0.19964537 -0.30059689]\n",
      "\taction [-0.26649082 -0.53056794 -0.23021559 -0.05863203]\n",
      "\taction [-0.5271486  -0.37323436 -0.51125681 -0.53443855]\n",
      "episode 97 at 1000 ts; done reached\n",
      "\taction [-0.97724789 -0.86488491 -0.9695819  -0.81259102]\n",
      "\taction [-0.27802631 -0.15947692 -0.3771683  -0.35253441]\n",
      "\taction [-0.41846743 -0.33293489 -0.34935859 -0.13249505]\n",
      "\taction [-0.23741715 -0.28671876 -0.32161084 -0.33851835]\n",
      "episode 98 at 1000 ts; done reached\n",
      "\taction [-0.95319742 -0.94276607 -0.8790735  -0.83641464]\n",
      "\taction [-0.19819255 -0.26758999 -0.35516477 -0.47413975]\n",
      "\taction [-0.24074836 -0.25214741 -0.37570524 -0.28791678]\n",
      "\taction [-0.51173425 -0.10485391 -0.36084774 -0.30193236]\n",
      "episode 99 at 1000 ts; done reached\n",
      "\taction [-0.88350767 -0.81238276 -0.99826872 -0.81525028]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [-0.44349375 -0.45098054 -0.21767177 -0.24080215]\n",
      "\taction [-0.23117414 -0.21013364 -0.47249225 -0.34865281]\n",
      "\taction [-0.33308086 -0.326702   -0.29924956 -0.32769257]\n",
      "episode 100 at 1000 ts; done reached\n",
      "\taction [-0.99675244 -0.81929517 -0.91406894 -0.99396586]\n",
      "\taction [-0.35982305 -0.49620298 -0.47066328 -0.25394103]\n",
      "\taction [-0.49557579 -0.46548632 -0.22122703 -0.35883579]\n",
      "\taction [-0.25431934 -0.1997187  -0.41464314 -0.36498949]\n",
      "episode 101 at 1000 ts; done reached\n",
      "\taction [-0.87262809 -0.86409795 -0.86095488 -0.93854386]\n",
      "\taction [-0.20976986 -0.16807982 -0.40389803 -0.33836645]\n",
      "\taction [-0.41484684 -0.47382218 -0.27732885 -0.28344494]\n",
      "\taction [-0.2265379  -0.28116181 -0.0654447  -0.38396505]\n",
      "episode 102 at 1000 ts; done reached\n",
      "\taction [-0.96842313 -0.99622965 -0.87100738 -0.85802931]\n",
      "\taction [-0.0939635  -0.21679683 -0.26980403 -0.44982755]\n",
      "\taction [-0.39190811 -0.37777424 -0.31784618 -0.1330557 ]\n",
      "\taction [-0.19999567 -0.43573818 -0.08475472 -0.57548171]\n",
      "episode 103 at 1000 ts; done reached\n",
      "\taction [-0.97788471 -0.99682587 -0.98814821 -0.83716655]\n",
      "\taction [-0.34845644 -0.20069371 -0.24267361 -0.40502042]\n",
      "\taction [-0.41016275 -0.48686844 -0.24918714 -0.22204931]\n",
      "\taction [-0.30647898 -0.35536847 -0.24288119 -0.45462018]\n",
      "episode 104 at 1000 ts; done reached\n",
      "\taction [-0.98531222 -0.92502242 -0.96415609 -0.96354687]\n",
      "\taction [-0.45168868 -0.34634367 -0.29910362 -0.28212205]\n",
      "\taction [-0.23536727 -0.15094356 -0.14563644 -0.41658434]\n",
      "\taction [-0.40790007 -0.4002879  -0.37623471 -0.43381575]\n",
      "episode 105 at 1000 ts; done reached\n",
      "\taction [-0.94841766 -0.98015302 -0.96791244 -0.90671521]\n",
      "\taction [-0.38352469 -0.15913048 -0.54719174 -0.25759962]\n",
      "\taction [-0.21029019 -0.18562485 -0.290746   -0.37732482]\n",
      "\taction [-0.32826358 -0.30864874 -0.29194301 -0.52287644]\n",
      "episode 106 at 1000 ts; done reached\n",
      "\taction [-0.98467356 -0.8529954  -0.90132815 -0.90660894]\n",
      "\taction [-0.31223038 -0.31239644 -0.40529028 -0.10339385]\n",
      "\taction [-0.34276941 -0.33903441 -0.23229522 -0.39013934]\n",
      "\taction [-0.30621016 -0.30494338 -0.39242977 -0.19559756]\n",
      "episode 107 at 1000 ts; done reached\n",
      "\taction [-0.8603667  -0.93947917 -0.87592554 -0.8978132 ]\n",
      "\taction [-0.55400598 -0.37045458 -0.21525551 -0.16027349]\n",
      "\taction [-0.36536303 -0.12778953 -0.38587824 -0.26073736]\n",
      "\taction [-0.29727748 -0.33106416 -0.31556875 -0.39244074]\n",
      "episode 108 at 1000 ts; done reached\n",
      "\taction [-0.98710549 -0.94829124 -0.91599321 -0.95106971]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [-0.74655682 -0.39385366 -0.48411226 -0.23456812]\n",
      "\taction [-0.32893836 -0.33496636 -0.50387549 -0.37616637]\n",
      "\taction [-0.37391964 -0.28608736 -0.23180754 -0.37950429]\n",
      "episode 109 at 1000 ts; done reached\n",
      "\taction [-0.83291423 -0.88371611 -0.85451829 -0.85916698]\n",
      "\taction [-0.23240128 -0.48752952 -0.36586294 -0.57568055]\n",
      "\taction [-0.35064593 -0.55078351 -0.41117626 -0.26069301]\n",
      "\taction [-0.35071594 -0.33593306 -0.41448948 -0.33322552]\n",
      "episode 110 at 1000 ts; done reached\n",
      "\taction [-0.85369086 -0.99126297 -0.81654257 -0.81811798]\n",
      "\taction [-0.42014971 -0.30237791 -0.29620025 -0.03604247]\n",
      "\taction [-0.12010501 -0.39198077 -0.40286636 -0.56751794]\n",
      "\taction [-0.28786609 -0.38339862 -0.61904341 -0.33542779]\n",
      "episode 111 at 1000 ts; done reached\n",
      "\taction [-0.85026258 -0.8531369  -0.93127728 -0.8820706 ]\n",
      "\taction [-0.46117464 -0.28070176 -0.48743877 -0.32807708]\n",
      "\taction [-0.38274732 -0.31704691 -0.51891112 -0.47346035]\n",
      "\taction [-0.21573465 -0.47840813 -0.22220631 -0.30093753]\n",
      "episode 112 at 1000 ts; done reached\n",
      "\taction [-0.96379292 -0.96818638 -0.91138101 -0.99339432]\n",
      "\taction [-0.27066252 -0.27267992 -0.52554435 -0.27169618]\n",
      "\taction [-0.38115498 -0.28011322 -0.52855521 -0.41055059]\n",
      "\taction [-0.17852466 -0.36140722 -0.27144772 -0.39423057]\n",
      "episode 113 at 1000 ts; done reached\n",
      "\taction [-0.98976052 -0.89060658 -0.96303755 -0.86927891]\n",
      "\taction [-0.25719866 -0.37205106 -0.30623388 -0.4788062 ]\n",
      "\taction [-0.62393612 -0.25571293 -0.2395996  -0.24101819]\n",
      "\taction [-0.41737074 -0.44198662 -0.41876084 -0.28827801]\n",
      "episode 114 at 1000 ts; done reached\n",
      "\taction [-0.89741004 -0.91580099 -0.89983815 -0.98162156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\taction [-0.54141301 -0.26384857 -0.17555097 -0.30925107]\n",
      "\taction [-0.3045629  -0.22380662 -0.41656765 -0.36298212]\n",
      "\taction [-0.15397863 -0.33709148 -0.41890991 -0.44767332]\n",
      "episode 115 at 1000 ts; done reached\n",
      "\taction [-0.82096726 -0.92247808 -0.86882651 -0.98816973]\n",
      "\taction [-0.32787284 -0.23912868 -0.18336394 -0.25290763]\n",
      "\taction [-0.30599728 -0.39990225 -0.20560145 -0.32833147]\n",
      "\taction [-0.28322732 -0.3171128  -0.36514169 -0.32649624]\n",
      "episode 116 at 1000 ts; done reached\n",
      "\taction [-0.81256849 -0.94997287 -0.84484953 -0.95994812]\n",
      "\taction [-0.23650952 -0.46399176 -0.39931443 -0.31381869]\n",
      "\taction [-0.2114532  -0.20563336 -0.53225309 -0.08998209]\n",
      "\taction [-0.44813585 -0.23297529 -0.26323813 -0.31593755]\n",
      "episode 117 at 1000 ts; done reached\n",
      "\taction [-0.81472528 -0.98313177 -0.92104107 -0.84263361]\n",
      "\taction [-0.26719892 -0.37189564 -0.27350122 -0.31921461]\n",
      "\taction [-0.38358063 -0.24413271 -0.34205681 -0.5123831 ]\n",
      "\taction [-0.3754071  -0.17195643 -0.06448094 -0.42353514]\n",
      "episode 118 at 1000 ts; done reached\n",
      "\taction [-0.99943209 -0.87779266 -0.90260136 -0.9976759 ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [-0.30590519 -0.48951724 -0.26090068 -0.16555198]\n",
      "\taction [-0.23507401 -0.4415563  -0.07991631 -0.39454105]\n",
      "\taction [-0.50565511 -0.39680383 -0.15411049 -0.45590344]\n",
      "episode 119 at 1000 ts; done reached\n",
      "\taction [-0.96363038 -0.99680763 -0.90661943 -0.81288701]\n",
      "\taction [-0.19167489 -0.35743043 -0.41102651 -0.43907273]\n",
      "\taction [-0.3254264  -0.28174981 -0.28147399 -0.38669744]\n",
      "\taction [-0.38805887 -0.45421353 -0.45255369 -0.4173224 ]\n",
      "episode 120 at 1000 ts; done reached\n",
      "\taction [-0.97263223 -0.84065425 -0.9859544  -0.82173717]\n",
      "\taction [-0.27373138 -0.24352972 -0.34607852 -0.22346939]\n",
      "\taction [-0.30799156 -0.42951021 -0.24046981 -0.35791609]\n",
      "\taction [-0.47543213 -0.48880276 -0.31888491 -0.37081343]\n",
      "episode 121 at 1000 ts; done reached\n",
      "\taction [-0.94316798 -0.9599824  -0.88142318 -0.95809454]\n",
      "\taction [-0.32012942 -0.19689162 -0.2486428  -0.20270935]\n",
      "\taction [-0.25838369 -0.35399944 -0.20903738 -0.42077848]\n",
      "\taction [-0.40594652 -0.43722999 -0.26083168 -0.22519995]\n",
      "episode 122 at 1000 ts; done reached\n",
      "\taction [-0.91775686 -0.95605671 -0.81102818 -0.8281765 ]\n",
      "\taction [-0.43696353 -0.50224894 -0.2367446  -0.12106692]\n",
      "\taction [-0.17034927 -0.3603718  -0.23784538 -0.18669185]\n",
      "\taction [-0.30727589 -0.53298646 -0.45979908 -0.38354012]\n",
      "episode 123 at 1000 ts; done reached\n",
      "\taction [-0.83680171 -0.93374747 -0.9936803  -0.89906323]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [-0.2952224  -0.27495125 -0.22157095 -0.31868768]\n",
      "\taction [-0.19291286 -0.41603824 -0.29016888 -0.42789856]\n",
      "\taction [-0.37388459 -0.53583258 -0.36450097 -0.48226288]\n",
      "episode 124 at 1000 ts; done reached\n",
      "\taction [-0.95878482 -0.9229427  -0.97635657 -0.81591088]\n",
      "\taction [-0.24503885 -0.26134253 -0.24767302 -0.30627525]\n",
      "\taction [-0.41075525 -0.3200359  -0.31339163 -0.48438773]\n",
      "\taction [-0.23408103 -0.18800284 -0.30878472 -0.09713732]\n",
      "episode 125 at 1000 ts; done reached\n",
      "\taction [-0.96186519 -0.99666423 -0.96241975 -0.99946237]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [-0.36813369 -0.13431469 -0.21804072 -0.37273985]\n",
      "\taction [-0.25838459 -0.31134814 -0.2253924  -0.34044328]\n",
      "\taction [-0.48945674 -0.32962227 -0.31186762 -0.24754649]\n",
      "episode 126 at 1000 ts; done reached\n",
      "\taction [-0.90426803 -0.80008835 -0.86461323 -0.89109665]\n",
      "\taction [-0.15736185 -0.29608947 -0.31215203 -0.23166016]\n",
      "\taction [-0.46928656 -0.46650204 -0.38056061 -0.28860083]\n",
      "\taction [-0.44826633 -0.16961958 -0.23190449 -0.46508247]\n",
      "episode 127 at 1000 ts; done reached\n",
      "\taction [-0.98857087 -0.85746109 -0.96784818 -0.99865025]\n",
      "\taction [-0.35038018 -0.48201424 -0.60551953 -0.57658672]\n",
      "\taction [-0.58972645 -0.25580698 -0.40226123 -0.29556477]\n",
      "\taction [-0.57366472 -0.43672287 -0.44256926 -0.34861517]\n",
      "episode 128 at 1000 ts; done reached\n",
      "\taction [-0.90159816 -0.95876122 -0.92739034 -0.8034144 ]\n",
      "\taction [-0.27295613 -0.27756789 -0.20924571 -0.39653847]\n",
      "\taction [-0.43028721 -0.45420244 -0.26593545 -0.27722469]\n",
      "\taction [-0.44141135 -0.35418382 -0.50035125 -0.26064202]\n",
      "episode 129 at 1000 ts; done reached\n",
      "\taction [-0.9378702  -0.85249954 -0.97326487 -0.90125227]\n",
      "\taction [-0.32933554 -0.34712219 -0.16924451 -0.35625881]\n",
      "\taction [-0.27085951 -0.38209766 -0.19644919 -0.29668728]\n",
      "\taction [-0.203629   -0.31797764 -0.4438535  -0.35339162]\n",
      "episode 130 at 1000 ts; done reached\n",
      "\taction [-0.97816551 -0.86575657 -0.89710736 -0.81226605]\n",
      "\taction [-0.42272016 -0.3972562  -0.38813928 -0.44131827]\n",
      "\taction [-0.18974224 -0.39018068 -0.3136726  -0.30587175]\n",
      "\taction [-0.3868618  -0.42487893 -0.20573145 -0.17171328]\n",
      "episode 131 at 1000 ts; done reached\n",
      "\taction [-0.8161009  -0.98272306 -0.97572082 -0.91149861]\n",
      "\taction [-0.26180315 -0.29245505 -0.31691352 -0.2363129 ]\n",
      "\taction [-0.23139757 -0.43403041 -0.12719989 -0.30025849]\n",
      "\taction [-0.27494732 -0.55863506 -0.39733902 -0.25099057]\n",
      "episode 132 at 1000 ts; done reached\n",
      "\taction [-0.80315661 -0.95282328 -0.97947162 -0.96530753]\n",
      "\taction [-0.39372343 -0.36647213 -0.29455218 -0.56479263]\n",
      "\taction [-0.22510506 -0.57507199 -0.48889136 -0.39007038]\n",
      "\taction [-0.46852115 -0.32005915 -0.37249118 -0.39475721]\n",
      "episode 133 at 1000 ts; done reached\n",
      "\taction [-0.99516046 -0.88820285 -0.97943771 -0.83199179]\n",
      "\taction [-0.52386737 -0.51017445 -0.13103822 -0.32713604]\n",
      "\taction [-0.50871199 -0.17923184 -0.26177835 -0.49942243]\n",
      "\taction [-0.20658346 -0.29050866 -0.49038503 -0.30254278]\n",
      "episode 134 at 1000 ts; done reached\n",
      "\taction [-0.99999869 -0.83610195 -0.90325314 -0.90265143]\n",
      "\taction [-0.30293214 -0.22518897 -0.22642666 -0.29643425]\n",
      "\taction [-0.3322936  -0.45217046 -0.4164269  -0.38474134]\n",
      "\taction [-0.53582424 -0.36513424 -0.25110349 -0.3020359 ]\n",
      "episode 135 at 1000 ts; done reached\n",
      "\taction [-0.96675992 -0.99802274 -0.86806077 -0.8915562 ]\n",
      "\taction [-0.13360161 -0.3414377  -0.14846551 -0.39114225]\n",
      "\taction [-0.38489413 -0.23373698 -0.02588285 -0.14139245]\n",
      "\taction [-0.34068346 -0.32621795 -0.36205614 -0.36370143]\n",
      "episode 136 at 1000 ts; done reached\n",
      "\taction [-0.98561132 -0.86805469 -0.93882477 -0.94597322]\n",
      "\taction [-0.40245792 -0.08637723 -0.46235347 -0.07749552]\n",
      "\taction [-0.49577686 -0.36237118 -0.48208308 -0.42849079]\n",
      "\taction [-0.36931768 -0.27912489 -0.07763324 -0.29621011]\n",
      "episode 137 at 1000 ts; done reached\n",
      "\taction [-0.91093886 -0.96414435 -0.98714435 -0.84517658]\n",
      "\taction [-0.42985839 -0.25533882 -0.44448152 -0.44388804]\n",
      "\taction [-0.33888415 -0.27900171 -0.37165952 -0.34120747]\n",
      "\taction [-0.20323204 -0.32865256 -0.21049392 -0.36258978]\n",
      "episode 138 at 1000 ts; done reached\n",
      "\taction [-0.95777196 -0.91408902 -0.89455664 -0.8979314 ]\n",
      "\taction [-0.34653506 -0.29999799 -0.21624748 -0.44995749]\n",
      "\taction [-0.39056128 -0.25578845 -0.34241998 -0.19478761]\n",
      "\taction [-0.34479249 -0.36537156 -0.50133163 -0.37989941]\n",
      "episode 139 at 1000 ts; done reached\n",
      "\taction [-0.96984869 -0.93543059 -0.92048115 -0.92442143]\n",
      "\taction [-0.37638098 -0.3433218  -0.23470247 -0.30904177]\n",
      "\taction [-0.4317413  -0.40661347 -0.25155121 -0.44406402]\n",
      "\taction [-0.31470269 -0.25031048 -0.26494333 -0.46486396]\n",
      "episode 140 at 1000 ts; done reached\n",
      "\taction [-0.994919   -0.8293106  -0.81529421 -0.85579377]\n",
      "\taction [-0.43321306 -0.37860385 -0.53810763 -0.3842333 ]\n",
      "\taction [-0.17845048 -0.24266425 -0.12837158 -0.32703811]\n",
      "\taction [-0.31671602 -0.36394352 -0.24163447 -0.32711384]\n",
      "episode 141 at 1000 ts; done reached\n",
      "\taction [-0.86705995 -0.88273335 -0.93154156 -0.97946054]\n",
      "\taction [-0.21866883 -0.45334291 -0.30742586 -0.33763707]\n",
      "\taction [-0.18724023 -0.52317983 -0.26061645 -0.33223727]\n",
      "\taction [-0.47354585 -0.19147316 -0.31704414 -0.43196198]\n",
      "episode 142 at 1000 ts; done reached\n",
      "\taction [-0.8554458  -0.82057881 -0.86279219 -0.95519167]\n",
      "\taction [-0.2131442  -0.42008775 -0.12480872 -0.31150472]\n",
      "\taction [-0.44354755 -0.38963601 -0.24580468 -0.38995087]\n",
      "\taction [-0.20807384 -0.24286364 -0.3202289  -0.17252025]\n",
      "episode 143 at 1000 ts; done reached\n",
      "\taction [-0.83386964 -0.97448909 -0.93569452 -0.96886098]\n",
      "\taction [-0.42336479 -0.38093764 -0.45081216 -0.28335166]\n",
      "\taction [-0.30291688 -0.41565993 -0.4901149  -0.44094077]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\taction [-0.28785467 -0.22255257 -0.24451616 -0.2778067 ]\n",
      "episode 144 at 1000 ts; done reached\n",
      "\taction [-0.80026054 -0.81984949 -0.99887848 -0.88179868]\n",
      "\taction [-0.39274684 -0.14599943 -0.23060042 -0.46482694]\n",
      "\taction [-0.50100642 -0.39436561 -0.27242535 -0.40962714]\n",
      "\taction [-0.10315451 -0.35258818 -0.41510502 -0.0685635 ]\n",
      "episode 145 at 1000 ts; done reached\n",
      "\taction [-0.87899143 -0.92161012 -0.84667414 -0.98616558]\n",
      "\taction [-0.45060372 -0.26362702 -0.33998355 -0.38168904]\n",
      "\taction [-0.413225   -0.28618738 -0.2744326  -0.10592639]\n",
      "\taction [-0.39181545 -0.27285412 -0.29978818 -0.3721039 ]\n",
      "episode 146 at 1000 ts; done reached\n",
      "\taction [-0.95637697 -0.97843021 -0.95598197 -0.83873528]\n",
      "\taction [-0.21777581 -0.19545765 -0.35966501 -0.36419615]\n",
      "\taction [-0.1906341  -0.62852931 -0.3257384  -0.44714105]\n",
      "\taction [-0.39494389 -0.47240651 -0.47371566 -0.51823181]\n",
      "episode 147 at 1000 ts; done reached\n",
      "\taction [-0.91153133 -0.95526826 -0.93247432 -0.90574437]\n",
      "\taction [-0.34640095 -0.30687782 -0.22757436 -0.39809996]\n",
      "\taction [-0.53313482 -0.28756037 -0.41674557 -0.34672213]\n",
      "\taction [-0.36016086 -0.41470107 -0.26243278 -0.34668699]\n",
      "episode 148 at 1000 ts; done reached\n",
      "\taction [-0.87549895 -0.90608746 -0.81254876 -0.85560441]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [-0.30704516 -0.45910573 -0.29498094 -0.27372521]\n",
      "\taction [-0.41852903 -0.15884145 -0.47080091 -0.31452161]\n",
      "\taction [-0.37865344 -0.14266071 -0.311937   -0.44280741]\n",
      "episode 149 at 1000 ts; done reached\n",
      "\taction [-0.82127726 -0.82105142 -0.93058491 -0.84901339]\n",
      "\taction [-0.29275286 -0.34700122 -0.26094422 -0.29211232]\n",
      "\taction [-0.19821937 -0.3029176  -0.43682364 -0.41397473]\n",
      "\taction [-0.28989941 -0.47265989 -0.36805156 -0.49124143]\n",
      "episode 150 at 1000 ts; done reached\n",
      "\taction [-0.89988029 -0.83595812 -0.90232199 -0.82925248]\n",
      "\taction [-0.20732324 -0.43820196 -0.37703452 -0.2844415 ]\n",
      "\taction [-0.30818275 -0.31811947 -0.28636274 -0.37182808]\n",
      "\taction [-0.47477204 -0.15719311 -0.3395662  -0.47547683]\n",
      "episode 151 at 1000 ts; done reached\n",
      "\taction [-0.86576122 -0.98085994 -0.95871168 -0.9119674 ]\n",
      "\taction [-0.21627747 -0.1454201  -0.24107566 -0.3926726 ]\n",
      "\taction [-0.56278878 -0.5496527  -0.13486169 -0.41789499]\n",
      "\taction [-0.30434889 -0.47225526 -0.5723123  -0.28398815]\n",
      "episode 152 at 1000 ts; done reached\n",
      "\taction [-0.86742568 -0.86483073 -0.81701779 -0.98947459]\n",
      "\taction [-0.50374937 -0.23417236 -0.46694988 -0.42610207]\n",
      "\taction [-0.50716895 -0.44498178 -0.37676743 -0.39357093]\n",
      "\taction [-0.46084338 -0.42866609 -0.473537   -0.54607165]\n",
      "episode 153 at 1000 ts; done reached\n",
      "\taction [-0.80263722 -0.99663544 -0.97346067 -0.833547  ]\n",
      "\taction [-0.15764755 -0.33523059 -0.25208837 -0.21362115]\n",
      "\taction [-0.28095454 -0.27777648 -0.33852234 -0.4652127 ]\n",
      "\taction [-0.45887911 -0.32955718 -0.26588821 -0.38661367]\n",
      "episode 154 at 1000 ts; done reached\n",
      "\taction [-0.92493677 -0.85774279 -0.83556527 -0.97628087]\n",
      "\taction [-0.29585126 -0.23020235 -0.46910501 -0.38680363]\n",
      "\taction [-0.31666461 -0.28859949 -0.33672339 -0.37310195]\n",
      "\taction [-0.34107992 -0.27210519 -0.4205952  -0.3512525 ]\n",
      "episode 155 at 1000 ts; done reached\n",
      "\taction [-0.8166883  -0.85387975 -0.95946449 -0.83659339]\n",
      "\taction [-0.28996342 -0.48282862 -0.30084825 -0.30386287]\n",
      "\taction [-0.25197852 -0.20025447 -0.28472579 -0.42441851]\n",
      "\taction [-0.32633507 -0.04911486 -0.27709499 -0.27304962]\n",
      "episode 156 at 1000 ts; done reached\n",
      "\taction [-0.95257205 -0.83066565 -0.8087905  -0.94506133]\n",
      "\taction [-0.42876017 -0.22019851 -0.42255768 -0.2959151 ]\n",
      "\taction [-0.18179701 -0.37486508 -0.24673513 -0.53950936]\n",
      "\taction [-0.41730404 -0.33394417 -0.18793079 -0.21464382]\n",
      "episode 157 at 1000 ts; done reached\n",
      "\taction [-0.83248514 -0.86157948 -0.93839997 -0.80895483]\n",
      "\taction [-0.43228894 -0.33603239 -0.31290844 -0.48259124]\n",
      "\taction [-0.48788801 -0.35893694 -0.32682228 -0.28745171]\n",
      "\taction [-0.42355099 -0.12650448 -0.34503913 -0.41006517]\n",
      "episode 158 at 1000 ts; done reached\n",
      "\taction [-0.80082428 -0.9842298  -0.91763121 -0.88787723]\n",
      "\taction [-0.35330725 -0.26893488 -0.40335193 -0.41050088]\n",
      "\taction [-0.37914231 -0.40302983 -0.44857037 -0.07809377]\n",
      "\taction [-0.53024232 -0.38037255 -0.47278121 -0.36419028]\n",
      "episode 159 at 1000 ts; done reached\n",
      "\taction [-0.86748415 -0.86224872 -0.80238301 -0.94274348]\n",
      "\taction [-0.50070125 -0.47364077 -0.42989498 -0.58553106]\n",
      "\taction [-0.60816085 -0.428473   -0.27947745 -0.44181675]\n",
      "\taction [-0.2331934  -0.31210604 -0.21546242 -0.34802869]\n",
      "episode 160 at 1000 ts; done reached\n",
      "\taction [-0.87034029 -0.93323851 -0.87347478 -0.88963723]\n",
      "\taction [-0.48220116 -0.17485984 -0.4021036  -0.31243035]\n",
      "\taction [-0.1509722  -0.50056797 -0.65212226 -0.05830435]\n",
      "\taction [-0.35975423 -0.2599116  -0.34347725 -0.20331912]\n",
      "episode 161 at 1000 ts; done reached\n",
      "\taction [-0.85459417 -0.87730235 -0.91937786 -0.90944427]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [-0.49240628 -0.38887048 -0.26971701 -0.45130727]\n",
      "\taction [-0.31002793 -0.43555924 -0.38027608 -0.35189694]\n",
      "\taction [-0.28972405 -0.45034793 -0.38262403 -0.42551818]\n",
      "episode 162 at 1000 ts; done reached\n",
      "\taction [-0.93562192 -0.90523565 -0.99479949 -0.86028558]\n",
      "\taction [-0.29314974 -0.36273676 -0.14975941 -0.46972761]\n",
      "\taction [-0.395206   -0.37733367 -0.30229649 -0.25559467]\n",
      "\taction [-0.15747453 -0.47203493 -0.34955433 -0.37329596]\n",
      "episode 163 at 1000 ts; done reached\n",
      "\taction [-0.81285131 -0.80085772 -0.99679619 -0.96228319]\n",
      "\taction [-0.39674318 -0.43805274 -0.39486238 -0.14710718]\n",
      "\taction [-0.25755173 -0.25559139 -0.2208156  -0.2868686 ]\n",
      "\taction [-0.11391278 -0.28202495 -0.26786569 -0.43208697]\n",
      "episode 164 at 1000 ts; done reached\n",
      "\taction [-0.85290003 -0.87924039 -0.87094498 -0.91011113]\n",
      "\taction [-0.39530981 -0.28945652 -0.37184349 -0.54666394]\n",
      "\taction [-0.2327071  -0.30956712 -0.45546451 -0.28334597]\n",
      "\taction [-0.28054267 -0.47500229 -0.27776229 -0.49591181]\n",
      "episode 165 at 1000 ts; done reached\n",
      "\taction [-0.80328476 -0.82404929 -0.93269539 -0.96620536]\n",
      "\taction [-0.17395994 -0.20211789 -0.3019748  -0.30093619]\n",
      "\taction [-0.33284265 -0.47107175 -0.17655332 -0.33525679]\n",
      "\taction [-0.41310278 -0.28965214 -0.47145823 -0.33117285]\n",
      "episode 166 at 1000 ts; done reached\n",
      "\taction [-0.97357911 -0.85221577 -0.86293685 -0.87729079]\n",
      "\taction [-0.40804064 -0.26338458 -0.37660104 -0.28622711]\n",
      "\taction [-0.3431628  -0.61717963 -0.24600054 -0.46189123]\n",
      "\taction [-0.35681832 -0.26784006 -0.4181551  -0.24055035]\n",
      "episode 167 at 1000 ts; done reached\n",
      "\taction [-0.95328236 -0.95328802 -0.98917502 -0.86453485]\n",
      "\taction [-0.34046599 -0.31478304 -0.18775591 -0.31816402]\n",
      "\taction [-0.49492612 -0.49029574 -0.30016664 -0.31675923]\n",
      "\taction [-0.31016424 -0.37242666 -0.28589237 -0.23173296]\n",
      "episode 168 at 1000 ts; done reached\n",
      "\taction [-0.85164922 -0.83992302 -0.80394715 -0.95203948]\n",
      "\taction [-0.50018919 -0.42006829 -0.34578255 -0.20267296]\n",
      "\taction [-0.11372142 -0.47401965 -0.12610497 -0.30416653]\n",
      "\taction [-0.48697853 -0.34210986 -0.26604706 -0.28617126]\n",
      "episode 169 at 1000 ts; done reached\n",
      "\taction [-0.9220202  -0.97057998 -0.97342038 -0.95487732]\n",
      "\taction [-0.38392457 -0.49452186 -0.250893   -0.32991216]\n",
      "\taction [-0.44153526 -0.26308349 -0.23778431 -0.13171627]\n",
      "\taction [-0.21607803 -0.4438858  -0.50154638 -0.3408311 ]\n",
      "episode 170 at 1000 ts; done reached\n",
      "\taction [-0.87173414 -0.95641297 -0.90230578 -0.83157438]\n",
      "\taction [-0.38293773 -0.36006758 -0.26461816 -0.53178924]\n",
      "\taction [-0.4130224  -0.49346438 -0.27587965 -0.5299353 ]\n",
      "\taction [-0.31473145 -0.29346973 -0.27899334 -0.21928264]\n",
      "episode 171 at 1000 ts; done reached\n",
      "\taction [-0.96342653 -0.97048897 -0.87555653 -0.90437073]\n",
      "\taction [-0.4583478  -0.35940665 -0.38643333 -0.44797274]\n",
      "\taction [-0.16413787 -0.27197984 -0.32953617 -0.18466577]\n",
      "\taction [-0.3169722  -0.46077397 -0.21230401 -0.36458343]\n",
      "episode 172 at 1000 ts; done reached\n",
      "\taction [-0.96457767 -0.81183934 -0.8301549  -0.91515815]\n",
      "\taction [-0.3317557  -0.37125677 -0.2644878  -0.11099891]\n",
      "\taction [-0.27363104 -0.28575745 -0.55978674 -0.58261096]\n",
      "\taction [-0.37682065 -0.36332622 -0.28339034 -0.47774523]\n",
      "episode 173 at 1000 ts; done reached\n",
      "\taction [-0.91672146 -0.9546935  -0.93637359 -0.9723618 ]\n",
      "\taction [-0.29657933 -0.41584191 -0.41047245 -0.41051394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\taction [-0.29014671 -0.388376   -0.40371829 -0.17814739]\n",
      "\taction [-0.39348355 -0.46813744 -0.43537626 -0.30600652]\n",
      "episode 174 at 1000 ts; done reached\n",
      "\taction [-0.89331144 -0.93464923 -0.90227258 -0.84209806]\n",
      "\taction [-0.10771627 -0.13763519 -0.35655141 -0.19522886]\n",
      "\taction [-0.42987451 -0.37651616 -0.30578238 -0.47641268]\n",
      "\taction [-0.22674404 -0.40559018 -0.2025363  -0.48168787]\n",
      "episode 175 at 1000 ts; done reached\n",
      "\taction [-0.97360677 -0.87851679 -0.97472632 -0.98776442]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [-0.18144803 -0.43732718 -0.37619728 -0.28212759]\n",
      "\taction [-0.41519085 -0.38230458 -0.36324611 -0.18152358]\n",
      "\taction [-0.41122368 -0.16681704 -0.28558719 -0.39233571]\n",
      "episode 176 at 1000 ts; done reached\n",
      "\taction [-0.98755121 -0.93614715 -0.8408103  -0.8730101 ]\n",
      "\taction [-0.44534013 -0.52438754 -0.42126766 -0.50902331]\n",
      "\taction [-0.24913712 -0.1993455  -0.27469414 -0.46385205]\n",
      "\taction [-0.26171535 -0.22086766 -0.50789601 -0.54282546]\n",
      "episode 177 at 1000 ts; done reached\n",
      "\taction [-0.87980735 -0.83557981 -0.86866468 -0.86793631]\n",
      "\taction [-0.22112475 -0.1951647  -0.3268947  -0.2951993 ]\n",
      "\taction [-0.26820475 -0.09537669 -0.50144207 -0.19068058]\n",
      "\taction [-0.21452287 -0.34823576 -0.20788865 -0.24055763]\n",
      "episode 178 at 1000 ts; done reached\n",
      "\taction [-0.89786035 -0.92936051 -0.84871602 -0.88592261]\n",
      "\taction [-0.4146497  -0.18430489 -0.22445726 -0.29717311]\n",
      "\taction [-0.03931532 -0.32163072 -0.31871256 -0.35900521]\n",
      "\taction [-0.43732411 -0.30860156 -0.32393894 -0.34657142]\n",
      "episode 179 at 1000 ts; done reached\n",
      "\taction [-0.85764885 -0.85466725 -0.80895561 -0.96909308]\n",
      "\taction [-0.20888239 -0.54591417 -0.30005053 -0.29756212]\n",
      "\taction [-0.22422101 -0.22096685 -0.32960349 -0.16767383]\n",
      "\taction [-0.28960374 -0.36593041 -0.35263821 -0.27250698]\n",
      "episode 180 at 1000 ts; done reached\n",
      "\taction [-0.98919588 -0.81502789 -0.90766692 -0.81575572]\n",
      "\taction [-0.16402529 -0.40566757 -0.17734171 -0.32661065]\n",
      "\taction [-0.29118383 -0.31618577 -0.05997901 -0.1889023 ]\n",
      "\taction [-0.21942201 -0.34592116 -0.08869933 -0.49362797]\n",
      "episode 181 at 1000 ts; done reached\n",
      "\taction [-0.98689103 -0.90113676 -0.9867717  -0.85049742]\n",
      "\taction [-0.35358411 -0.45750946 -0.34199953 -0.32378295]\n",
      "\taction [-0.43311262 -0.47246301 -0.29704306 -0.20123382]\n",
      "\taction [-0.52307284 -0.43441972 -0.43103388 -0.55810076]\n",
      "episode 182 at 1000 ts; done reached\n",
      "\taction [-0.87178361 -0.97360623 -0.97258329 -0.8465414 ]\n",
      "\taction [-0.26056516 -0.3797721  -0.16823322 -0.33178723]\n",
      "\taction [-0.64843112 -0.25748017 -0.35296333 -0.51019967]\n",
      "\taction [-0.40238187 -0.27318957 -0.32662654 -0.45618245]\n",
      "episode 183 at 1000 ts; done reached\n",
      "\taction [-0.94899982 -0.81377399 -0.95116174 -0.88952255]\n",
      "\taction [-0.27187508 -0.30727243 -0.39202875 -0.43028554]\n",
      "\taction [-0.39606038 -0.33265784 -0.3737545  -0.32062608]\n",
      "\taction [-0.27876177 -0.35955834 -0.23487496 -0.20520909]\n",
      "episode 184 at 1000 ts; done reached\n",
      "\taction [-0.98788154 -0.87670541 -0.97781909 -0.99444002]\n",
      "\taction [-0.5838455  -0.2713083  -0.27830124 -0.29254803]\n",
      "\taction [-0.34081179 -0.36955044 -0.31315023 -0.14910015]\n",
      "\taction [-0.37858737 -0.38127977 -0.22691052 -0.17712852]\n",
      "episode 185 at 1000 ts; done reached\n",
      "\taction [-0.85432816 -0.9523229  -0.92481428 -0.97422409]\n",
      "\taction [-0.2417676  -0.21991277 -0.39244121 -0.45502597]\n",
      "\taction [-0.27180281 -0.19390079 -0.29710928 -0.32235354]\n",
      "\taction [-0.2559393  -0.1795229  -0.2812528  -0.37183738]\n",
      "episode 186 at 1000 ts; done reached\n",
      "\taction [-0.9139452  -0.89892989 -0.98598015 -0.98758328]\n",
      "\taction [-0.46609715 -0.59211808 -0.39433673 -0.12984368]\n",
      "\taction [-0.50787067 -0.52070683 -0.36609206 -0.2302932 ]\n",
      "\taction [-0.3063595  -0.39252543 -0.3304148  -0.44320482]\n",
      "episode 187 at 1000 ts; done reached\n",
      "\taction [-0.92624468 -0.89008904 -0.85177088 -0.92522722]\n",
      "\taction [-0.24068744 -0.25284657 -0.51104116 -0.26774886]\n",
      "\taction [-0.45199677 -0.23892131 -0.07352717 -0.2412775 ]\n",
      "\taction [-0.17759125 -0.35504079 -0.42900169 -0.455661  ]\n",
      "episode 188 at 1000 ts; done reached\n",
      "\taction [-0.86926687 -0.8381992  -0.95137185 -0.88727969]\n",
      "\taction [-0.41690451 -0.22932726 -0.37361997 -0.25517738]\n",
      "\taction [-0.33324713 -0.50734591 -0.30368912 -0.589656  ]\n",
      "\taction [-0.31290758 -0.28282589 -0.32222289 -0.39037606]\n",
      "episode 189 at 1000 ts; done reached\n",
      "\taction [-0.95549673 -0.88296735 -0.93212783 -0.85614413]\n",
      "\taction [-0.03449065 -0.33211377 -0.20559685 -0.20218271]\n",
      "\taction [-0.37579349 -0.16720065 -0.32052094 -0.243055  ]\n",
      "\taction [-0.4491179  -0.30172354 -0.16673422 -0.29684129]\n",
      "episode 190 at 1000 ts; done reached\n",
      "\taction [-0.86375421 -0.97343904 -0.83655632 -0.80203599]\n",
      "\taction [-0.28242341 -0.29354674 -0.46239752 -0.40464655]\n",
      "\taction [-0.13274916 -0.30042541 -0.39245316 -0.46419418]\n",
      "\taction [-0.26826    -0.35756534 -0.31442729 -0.43257624]\n",
      "episode 191 at 1000 ts; done reached\n",
      "\taction [-0.96299559 -0.88334501 -0.98620331 -0.92631572]\n",
      "\taction [-0.35005009 -0.32070395 -0.20744677 -0.30159938]\n",
      "\taction [-0.3959161  -0.40063336 -0.51976216 -0.40097338]\n",
      "\taction [-0.33187503 -0.29410484 -0.28851399 -0.15948801]\n",
      "episode 192 at 1000 ts; done reached\n",
      "\taction [-0.8413136  -0.88654733 -0.87513316 -0.90622652]\n",
      "\taction [-0.24310245 -0.34663284 -0.26568723 -0.10242543]\n",
      "\taction [-0.29801741 -0.30054438 -0.30359507 -0.08874658]\n",
      "\taction [-0.17386779 -0.3280414  -0.10323698 -0.5378387 ]\n",
      "episode 193 at 1000 ts; done reached\n",
      "\taction [-0.98421812 -0.96479899 -0.88439816 -0.94339305]\n",
      "\taction [-0.45585632 -0.49836594 -0.34823582 -0.31030989]\n",
      "\taction [-0.36121237 -0.33461219 -0.26626799 -0.2377934 ]\n",
      "\taction [-0.30224702 -0.41138694 -0.4394924  -0.27099317]\n",
      "episode 194 at 1000 ts; done reached\n",
      "\taction [-0.89062649 -0.86966163 -0.89567006 -0.86972135]\n",
      "\taction [-0.50309265 -0.35036591 -0.33714288 -0.37532067]\n",
      "\taction [-0.226312   -0.2991609  -0.11503869 -0.41953331]\n",
      "\taction [-0.32177562 -0.56015033 -0.21401972 -0.33942851]\n",
      "episode 195 at 1000 ts; done reached\n",
      "\taction [-0.80734444 -0.83243436 -0.9230383  -0.99752986]\n",
      "\taction [-0.36910325 -0.16330972 -0.41575763 -0.19855838]\n",
      "\taction [-0.28887576 -0.32929531 -0.19882286 -0.37508169]\n",
      "\taction [-0.43320072 -0.31680036 -0.30934757 -0.45897818]\n",
      "episode 196 at 1000 ts; done reached\n",
      "\taction [-0.92722166 -0.97887003 -0.91523886 -0.84682691]\n",
      "\taction [-0.43966016 -0.34118408 -0.11581044 -0.13505304]\n",
      "\taction [-0.27213898 -0.4812184  -0.25442952 -0.65973568]\n",
      "\taction [-0.38505751 -0.10867213 -0.30370301 -0.11764205]\n",
      "episode 197 at 1000 ts; done reached\n",
      "\taction [-0.96913189 -0.84748262 -0.8837297  -0.87477732]\n",
      "\taction [-0.44306794 -0.31327721 -0.48405683 -0.48893008]\n",
      "\taction [-0.21066087 -0.56068587 -0.48523712 -0.28426141]\n",
      "\taction [-0.4363195  -0.48776254 -0.44855452 -0.23351905]\n",
      "episode 198 at 1000 ts; done reached\n",
      "\taction [-0.9686287  -0.89131099 -0.91471463 -0.93873954]\n",
      "\taction [-0.41038865 -0.61505622 -0.39591667 -0.36786503]\n",
      "\taction [-0.38607121 -0.40187466 -0.40747237 -0.22481926]\n",
      "\taction [-0.41694075 -0.39808986 -0.28927201 -0.37528133]\n",
      "episode 199 at 1000 ts; done reached\n",
      "\taction [-0.83919734 -0.82150549 -0.9313671  -0.84930366]\n",
      "\taction [-0.22120249 -0.3686707  -0.48565307 -0.31225356]\n",
      "\taction [-0.12541859 -0.57592744 -0.1957604  -0.25231382]\n",
      "\taction [-0.44887978 -0.22416523 -0.33578709 -0.2983458 ]\n",
      "episode 200 at 1000 ts; done reached\n",
      "\taction [-0.92254621 -0.82025653 -0.94313627 -0.93503243]\n",
      "\taction [-0.35465577 -0.58197606 -0.4005293  -0.19238001]\n",
      "\taction [-0.30507448 -0.34939161 -0.41085526 -0.25048625]\n",
      "\taction [-0.41153237 -0.26670763 -0.37449327 -0.1904216 ]\n",
      "episode 201 at 1000 ts; done reached\n",
      "\taction [-0.92616165 -0.99025422 -0.93840426 -0.85678053]\n",
      "\taction [-0.38411856 -0.45773336 -0.44046095 -0.30858812]\n",
      "\taction [-0.24585529 -0.36413735 -0.15421836 -0.39766794]\n",
      "\taction [-0.21517113 -0.19954179 -0.44585839 -0.30104783]\n",
      "episode 202 at 1000 ts; done reached\n",
      "\taction [-0.89314753 -0.8468436  -0.97606504 -0.91589141]\n",
      "\taction [-0.13946505 -0.10758685 -0.55328864 -0.45770648]\n",
      "\taction [-0.19043082 -0.28047779 -0.39231321 -0.3595477 ]\n",
      "\taction [-0.57861257 -0.41763198 -0.39853823 -0.46467701]\n",
      "episode 203 at 1000 ts; done reached\n",
      "\taction [-0.85469002 -0.95211118 -0.91334063 -0.98541135]\n",
      "\taction [-0.24654219 -0.5081923  -0.38380387 -0.42213413]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\taction [-0.08101852 -0.35774672 -0.45084208 -0.63182604]\n",
      "\taction [-0.49930763 -0.20253737 -0.2503674  -0.21149783]\n",
      "episode 204 at 1000 ts; done reached\n",
      "\taction [-0.89240056 -0.84825438 -0.84493452 -0.8623299 ]\n",
      "\taction [-0.17191084 -0.32020915 -0.26371092 -0.36100084]\n",
      "\taction [-0.19859743 -0.65501535 -0.32956651 -0.3488504 ]\n",
      "\taction [-0.34690735 -0.40380877 -0.08707716 -0.43564874]\n",
      "episode 205 at 1000 ts; done reached\n",
      "\taction [-0.94410276 -0.98681086 -0.82912892 -0.81638336]\n",
      "\taction [-0.23645662 -0.26321018 -0.17988768 -0.27544031]\n",
      "\taction [-0.48538703 -0.32028043 -0.35957971 -0.35851958]\n",
      "\taction [-0.38737762 -0.47733146 -0.1942585  -0.36459261]\n",
      "episode 206 at 1000 ts; done reached\n",
      "\taction [-0.95202434 -0.90023476 -0.95847046 -0.96217936]\n",
      "\taction [-0.32035854 -0.3666124  -0.25982159 -0.33308202]\n",
      "\taction [-0.37918773 -0.41701499 -0.26577362 -0.26324546]\n",
      "\taction [-0.23466025 -0.35351878 -0.40645167 -0.45928541]\n",
      "episode 207 at 1000 ts; done reached\n",
      "\taction [-0.84760946 -0.86742228 -0.8119989  -0.92446607]\n",
      "\taction [-0.5191499  -0.33741409 -0.37317112 -0.11295553]\n",
      "\taction [-0.29100204 -0.33691722 -0.44665352 -0.26356992]\n",
      "\taction [-0.12412786 -0.29376432 -0.30451107 -0.39773878]\n",
      "episode 208 at 1000 ts; done reached\n",
      "\taction [-0.80891061 -0.85508561 -0.88998806 -0.83219683]\n",
      "\taction [-0.41784078 -0.27472857 -0.32954633 -0.33490354]\n",
      "\taction [-0.37065575 -0.31359613 -0.49752957 -0.42253485]\n",
      "\taction [-0.3844865  -0.23780519 -0.60380965 -0.2897121 ]\n",
      "episode 209 at 1000 ts; done reached\n",
      "\taction [-0.96628273 -0.86298728 -0.84523773 -0.99059927]\n",
      "\taction [-0.20288005 -0.45002472 -0.32031178 -0.14208989]\n",
      "\taction [-0.50593263 -0.08574135 -0.37585327 -0.46281189]\n",
      "\taction [-0.18937962 -0.3046838  -0.48645368 -0.34455687]\n",
      "episode 210 at 1000 ts; done reached\n",
      "\taction [-0.83380765 -0.84264982 -0.89526677 -0.90347964]\n",
      "\taction [-0.35930362 -0.37605318 -0.19023345 -0.39609417]\n",
      "\taction [-0.22287339 -0.29167727 -0.27433154 -0.13642196]\n",
      "\taction [-0.34217271 -0.353681   -0.40570283 -0.29697862]\n",
      "episode 211 at 1000 ts; done reached\n",
      "\taction [-0.99205858 -0.88977724 -0.80517244 -0.94151556]\n",
      "\taction [-0.3097629  -0.40977126 -0.17350124 -0.24139392]\n",
      "\taction [-0.22945748 -0.43197551 -0.30068618 -0.48769554]\n",
      "\taction [-0.29633826 -0.22459291 -0.33756697 -0.29370648]\n",
      "episode 212 at 1000 ts; done reached\n",
      "\taction [-0.86925173 -0.93390769 -0.81784129 -0.91544682]\n",
      "\taction [-0.31090614 -0.38959414 -0.2837241  -0.33499628]\n",
      "\taction [-0.32678175 -0.47729826 -0.18230666 -0.20660733]\n",
      "\taction [-0.28759402 -0.36287171 -0.56030011 -0.34483531]\n",
      "episode 213 at 1000 ts; done reached\n",
      "\taction [-0.83338404 -0.96626276 -0.87286961 -0.85951108]\n",
      "\taction [-0.36151674 -0.25131339 -0.18355833 -0.40599811]\n",
      "\taction [-0.28606981 -0.41456702 -0.38718262 -0.30554184]\n",
      "\taction [-0.3965179  -0.36680892 -0.32080469 -0.16547439]\n",
      "episode 214 at 1000 ts; done reached\n",
      "\taction [-0.94800526 -0.88742572 -0.96816784 -0.96087623]\n",
      "\taction [-0.36277887 -0.50193399 -0.42153889 -0.46621954]\n",
      "\taction [-0.4813171  -0.33367524 -0.2980068  -0.24546956]\n",
      "\taction [-0.21840173 -0.3244071  -0.48918489 -0.36890885]\n",
      "episode 215 at 1000 ts; done reached\n",
      "\taction [-0.83082294 -0.92161548 -0.9689545  -0.94861412]\n",
      "\taction [-0.11842817 -0.56225753 -0.38355923 -0.54941279]\n",
      "\taction [-0.24870282 -0.47824466 -0.47957185 -0.29908949]\n",
      "\taction [-0.34362113 -0.19955958 -0.46947822 -0.40119657]\n",
      "episode 216 at 1000 ts; done reached\n",
      "\taction [-0.82018155 -0.84653676 -0.82451034 -0.85510397]\n",
      "\taction [-0.31622979 -0.07881699 -0.33292684 -0.35961682]\n",
      "\taction [-0.37744775 -0.19630705 -0.26376364 -0.49548316]\n",
      "\taction [-0.32595769 -0.34780771 -0.43226334 -0.51113546]\n",
      "episode 217 at 1000 ts; done reached\n",
      "\taction [-0.94210029 -0.89220208 -0.83608395 -0.93094766]\n",
      "\taction [-0.32726797 -0.33190015 -0.29927108 -0.39166066]\n",
      "\taction [-0.34377709 -0.34802365 -0.35979715 -0.33538347]\n",
      "\taction [-0.40131715 -0.29633915 -0.27113312 -0.2286652 ]\n",
      "episode 218 at 1000 ts; done reached\n",
      "\taction [-0.96291965 -0.82642275 -0.83652526 -0.91781342]\n",
      "\taction [-0.49229661 -0.26466388 -0.20127605 -0.24028651]\n",
      "\taction [-0.2678538  -0.40308088 -0.20474303 -0.09742859]\n",
      "\taction [-0.29594129 -0.35852647 -0.45830533 -0.21353978]\n",
      "episode 219 at 1000 ts; done reached\n",
      "\taction [-0.85508907 -0.84006476 -0.80170202 -0.96940821]\n",
      "\taction [-0.33219582 -0.18653296 -0.41220164 -0.46297371]\n",
      "\taction [-0.43874207 -0.25010473 -0.31441012 -0.33715472]\n",
      "\taction [-0.20709872 -0.51418221 -0.53899616 -0.3522177 ]\n",
      "episode 220 at 1000 ts; done reached\n",
      "\taction [-0.90235776 -0.90709966 -0.80719745 -0.83040619]\n",
      "\taction [-0.36795446 -0.230832   -0.22240412 -0.349318  ]\n",
      "\taction [-0.48178267 -0.0586038  -0.48770067 -0.38874212]\n",
      "\taction [-0.2286994  -0.29195124 -0.27360737 -0.4701623 ]\n",
      "episode 221 at 1000 ts; done reached\n",
      "\taction [-0.81494349 -0.97871238 -0.83094573 -0.80633193]\n",
      "\taction [-0.28058153 -0.49958876 -0.41038841 -0.32856899]\n",
      "\taction [-0.37001014 -0.22894482 -0.3427048  -0.4112767 ]\n",
      "\taction [-0.22417066 -0.29367462 -0.4498513  -0.32886457]\n",
      "episode 222 at 1000 ts; done reached\n",
      "\taction [-0.97927183 -0.81350112 -0.91317105 -0.85582495]\n",
      "\taction [-0.44611984 -0.2891432  -0.16158071 -0.32625347]\n",
      "\taction [-0.37238446 -0.28798988 -0.15139665 -0.36423954]\n",
      "\taction [-0.39712313 -0.32600451 -0.26890498 -0.32752249]\n",
      "episode 223 at 1000 ts; done reached\n",
      "\taction [-0.84999412 -0.82290149 -0.94323331 -0.94484514]\n",
      "\taction [-0.46741459 -0.37188843 -0.2981329  -0.37826005]\n",
      "\taction [-0.21126252 -0.30247709 -0.21998592 -0.10516979]\n",
      "\taction [-0.1720355  -0.44640425 -0.24133459 -0.03362983]\n",
      "episode 224 at 1000 ts; done reached\n",
      "\taction [-0.83544117 -0.85869724 -0.96510005 -0.87873119]\n",
      "\taction [-0.27899402 -0.33959454 -0.25584272 -0.29635081]\n",
      "\taction [-0.18616214 -0.27078736 -0.31342691 -0.19229101]\n",
      "\taction [-0.40018442 -0.1313294  -0.25926304 -0.25861773]\n",
      "episode 225 at 1000 ts; done reached\n",
      "\taction [-0.81571424 -0.88275504 -0.88205487 -0.84222001]\n",
      "\taction [-0.26107159 -0.28904977 -0.46189761 -0.37978432]\n",
      "\taction [-0.41877836 -0.14598222 -0.47607511 -0.44410098]\n",
      "\taction [-0.27930823 -0.12366226 -0.42217892 -0.35804212]\n",
      "episode 226 at 1000 ts; done reached\n",
      "\taction [-0.91667259 -0.91369379 -0.82189721 -0.80748779]\n",
      "\taction [-0.31566888 -0.38029462 -0.31031346 -0.31369713]\n",
      "\taction [-0.3043732  -0.32591614 -0.40992033 -0.45623484]\n",
      "\taction [-0.16911502 -0.17662494 -0.54799134 -0.34777376]\n",
      "episode 227 at 1000 ts; done reached\n",
      "\taction [-0.87464797 -0.80019528 -0.90697092 -0.90887308]\n",
      "\taction [-0.43163937 -0.42888427 -0.58987081 -0.07491204]\n",
      "\taction [-0.23096967 -0.31967887 -0.39973673 -0.34047049]\n",
      "\taction [-0.50850654 -0.34933308 -0.2540108  -0.34979203]\n",
      "episode 228 at 1000 ts; done reached\n",
      "\taction [-0.82727343 -0.83660436 -0.99349654 -0.91867906]\n",
      "\taction [-0.42464662 -0.29612073 -0.41153985 -0.48176464]\n",
      "\taction [-0.60674566 -0.3745493  -0.32777861 -0.20766436]\n",
      "\taction [-0.33500823 -0.47492716 -0.36643124 -0.35912502]\n",
      "episode 229 at 1000 ts; done reached\n",
      "\taction [-0.95943445 -0.98239714 -0.80124277 -0.86074579]\n",
      "\taction [-0.27363864 -0.1632442  -0.18397355 -0.28234658]\n",
      "\taction [-0.36774358 -0.39377305 -0.52917349 -0.38257477]\n",
      "\taction [-0.46179873 -0.35869688 -0.44849622 -0.15956913]\n",
      "episode 230 at 1000 ts; done reached\n",
      "\taction [-0.97190636 -0.92288584 -0.89539665 -0.88490647]\n",
      "\taction [-0.22067823 -0.26305833 -0.49379015 -0.30810457]\n",
      "\taction [-0.23204182 -0.25360417 -0.10219874 -0.45622352]\n",
      "\taction [-0.44971928 -0.36990929 -0.18488494 -0.49819139]\n",
      "episode 231 at 1000 ts; done reached\n",
      "\taction [-0.89053017 -0.94689983 -0.94678873 -0.84129518]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [-0.27996409 -0.40128997 -0.34271491 -0.14997482]\n",
      "\taction [-0.42043278 -0.32631186 -0.31476736 -0.37417841]\n",
      "\taction [-0.34773496 -0.55918145 -0.55617511 -0.16734332]\n",
      "episode 232 at 1000 ts; done reached\n",
      "\taction [-0.83757597 -0.80814618 -0.84778869 -0.99329573]\n",
      "\taction [-0.47312099 -0.24728629 -0.3872304  -0.34601226]\n",
      "\taction [-0.32435012 -0.48932898 -0.4500024  -0.27019614]\n",
      "\taction [-0.43830568 -0.32359156 -0.29544413 -0.23653273]\n",
      "episode 233 at 1000 ts; done reached\n",
      "\taction [-0.83638513 -0.83015668 -0.98196113 -0.94929874]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\taction [-0.53213501 -0.16977564 -0.23235995 -0.31025755]\n",
      "\taction [-0.39163679 -0.38100711 -0.38673437 -0.0546292 ]\n",
      "\taction [-0.17042863 -0.37467062 -0.23249479 -0.32143277]\n",
      "episode 234 at 1000 ts; done reached\n",
      "\taction [-0.95042777 -0.87136227 -0.91202188 -0.89844304]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [-0.3452124  -0.28203213 -0.0770759  -0.57089877]\n",
      "\taction [-0.29711768 -0.43903986 -0.42734456 -0.2397384 ]\n",
      "\taction [-0.3100819  -0.15574257 -0.29241732 -0.41743323]\n",
      "episode 235 at 1000 ts; done reached\n",
      "\taction [-0.94008815 -0.90282047 -0.80145025 -0.83849311]\n",
      "\taction [-0.3472288  -0.30886108 -0.31465182 -0.43369025]\n",
      "\taction [-0.38117531 -0.38742959 -0.19565701 -0.20623405]\n",
      "\taction [-0.45542899 -0.46929824 -0.25030321 -0.40147692]\n",
      "episode 236 at 1000 ts; done reached\n",
      "\taction [-0.87949824 -0.8495279  -0.97748858 -0.83461595]\n",
      "\taction [-0.49148959 -0.47280425 -0.36109531 -0.26167387]\n",
      "\taction [-0.24910675 -0.33027467 -0.23160553 -0.44236609]\n",
      "\taction [-0.32265359 -0.2758595  -0.33007109 -0.44747233]\n",
      "episode 237 at 1000 ts; done reached\n",
      "\taction [-0.86277914 -0.95896947 -0.93125594 -0.94020295]\n",
      "\taction [-0.27767158 -0.47808933 -0.35944751 -0.2097435 ]\n",
      "\taction [-0.35911012 -0.01745137 -0.39329785 -0.34181994]\n",
      "\taction [-0.36165482 -0.43529776 -0.31197    -0.33187291]\n",
      "episode 238 at 1000 ts; done reached\n",
      "\taction [-0.93202853 -0.80409962 -0.94413006 -0.91886735]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [-0.42108679 -0.29147077 -0.25245968 -0.42811304]\n",
      "\taction [-0.36071566 -0.3974427  -0.63899344 -0.45521188]\n",
      "\taction [-0.42695791 -0.32531846 -0.22937965 -0.32594746]\n",
      "episode 239 at 1000 ts; done reached\n",
      "\taction [-0.86481875 -0.86828727 -0.85649043 -0.85022467]\n",
      "\taction [-0.31549683 -0.36857665 -0.20918724 -0.30965275]\n",
      "\taction [-0.42954683 -0.28729323 -0.49367556 -0.28171757]\n",
      "\taction [-0.49823415 -0.46098679 -0.41596904 -0.23053545]\n",
      "episode 240 at 1000 ts; done reached\n",
      "\taction [-0.9465661  -0.98462659 -0.81115437 -0.82457751]\n",
      "\taction [-0.18508695 -0.43329605 -0.15009958 -0.22984073]\n",
      "\taction [-0.46316141 -0.26083881 -0.34455249 -0.39726382]\n",
      "\taction [-0.28674155 -0.33157599 -0.39821774 -0.22926769]\n",
      "episode 241 at 1000 ts; done reached\n",
      "\taction [-0.86050349 -0.99162525 -0.90856826 -0.90209585]\n",
      "\taction [-0.28554723 -0.4612053  -0.16194564 -0.26904744]\n",
      "\taction [-0.27790344 -0.25215706 -0.25605756 -0.36455378]\n",
      "\taction [-0.4128252  -0.61672199 -0.12202406 -0.30196896]\n",
      "episode 242 at 1000 ts; done reached\n",
      "\taction [-0.82138759 -0.99022174 -0.90917593 -0.84958863]\n",
      "\taction [-0.47120571 -0.20943005 -0.08740521 -0.4007718 ]\n",
      "\taction [-0.4095735  -0.49375531 -0.3765766  -0.60096306]\n",
      "\taction [-0.36112139 -0.5263707  -0.39841059 -0.30795068]\n",
      "episode 243 at 1000 ts; done reached\n",
      "\taction [-0.89002937 -0.89084733 -0.87229055 -0.95667553]\n",
      "\taction [-0.52957779 -0.35256469 -0.27935499 -0.35193735]\n",
      "\taction [-0.27766782 -0.33927074 -0.27570799 -0.58846229]\n",
      "\taction [-0.3914974  -0.31320229 -0.51263118 -0.34132698]\n",
      "episode 244 at 1000 ts; done reached\n",
      "\taction [-0.9262594  -0.81634396 -0.97861189 -0.85002685]\n",
      "\taction [-0.3271693  -0.26592761 -0.2799598  -0.3310672 ]\n",
      "\taction [-0.34877229 -0.10332934 -0.42571482 -0.36999112]\n",
      "\taction [-0.44324166 -0.3591978  -0.27304122 -0.48230386]\n",
      "episode 245 at 1000 ts; done reached\n",
      "\taction [-0.87198097 -0.83988082 -0.97656345 -0.92257994]\n",
      "\taction [-0.24342369 -0.24219738 -0.37617725 -0.46672216]\n",
      "\taction [-0.30302384 -0.18554984 -0.22857994 -0.40367132]\n",
      "\taction [-0.3729966  -0.30650944 -0.38263828 -0.42376798]\n",
      "episode 246 at 1000 ts; done reached\n",
      "\taction [-0.84050959 -0.92394197 -0.92413795 -0.92550617]\n",
      "\taction [-0.32801712 -0.45937201 -0.33599338 -0.21357684]\n",
      "\taction [-0.37359029 -0.26481444 -0.23253576 -0.44694191]\n",
      "\taction [-0.24429031 -0.60710633 -0.40608343 -0.37866014]\n",
      "episode 247 at 1000 ts; done reached\n",
      "\taction [-0.99397755 -0.93977141 -0.80715358 -0.95511138]\n",
      "\taction [-0.35237879 -0.2605232  -0.40766338 -0.3555052 ]\n",
      "\taction [-0.30102107 -0.28645888 -0.43598548 -0.48862022]\n",
      "\taction [-0.47275299 -0.37574452 -0.38936582 -0.37024319]\n",
      "episode 248 at 1000 ts; done reached\n",
      "\taction [-0.93066674 -0.84094745 -0.95890343 -0.90117419]\n",
      "\taction [-0.44756821 -0.34814799 -0.36591616 -0.26848871]\n",
      "\taction [-0.23198707 -0.44553798 -0.35312453 -0.43334609]\n",
      "\taction [-0.40639287 -0.39869547 -0.26006746 -0.43357852]\n",
      "episode 249 at 1000 ts; done reached\n",
      "\taction [-0.92710793 -0.88067466 -0.97649306 -0.9675808 ]\n",
      "\taction [-0.46875042 -0.46165588 -0.44074696 -0.35815701]\n",
      "\taction [-0.28603277 -0.29220816 -0.16913903 -0.32942322]\n",
      "\taction [-0.46835604 -0.43854553 -0.17464514 -0.41423577]\n",
      "episode 250 at 1000 ts; done reached\n",
      "\taction [-0.91322005 -0.83991331 -0.82121938 -0.90629917]\n",
      "\taction [-0.17663558 -0.29191038 -0.28379893 -0.42624098]\n",
      "\taction [-0.34670621 -0.31145883 -0.34554163 -0.24082655]\n",
      "\taction [-0.34814414 -0.45116252 -0.33523706 -0.3227998 ]\n",
      "episode 251 at 1000 ts; done reached\n",
      "\taction [-0.9468106  -0.82949078 -0.93964034 -0.97891802]\n",
      "\taction [-0.17503209 -0.19625862 -0.30765334 -0.38585299]\n",
      "\taction [-0.17398213 -0.22365867 -0.33609873 -0.39796859]\n",
      "\taction [-0.47757804 -0.50362146 -0.55989772 -0.22747935]\n",
      "episode 252 at 1000 ts; done reached\n",
      "\taction [-0.99998951 -0.81913298 -0.82885909 -0.89384222]\n",
      "\taction [-0.29619604 -0.32720166 -0.30229637 -0.37862614]\n",
      "\taction [-0.26497182 -0.28722772 -0.38529095 -0.48912352]\n",
      "\taction [-0.28682044 -0.3243649  -0.38120627 -0.36569786]\n",
      "episode 253 at 1000 ts; done reached\n",
      "\taction [-0.82139832 -0.92804295 -0.88396496 -0.8273226 ]\n",
      "\taction [-0.22545512 -0.44367746 -0.45855621 -0.34384766]\n",
      "\taction [-0.28986174 -0.31208658 -0.40508041 -0.20859216]\n",
      "\taction [-0.20610717 -0.20089711 -0.47409168 -0.30681071]\n",
      "episode 254 at 1000 ts; done reached\n",
      "\taction [-0.89859986 -0.81873977 -0.93308431 -0.91613907]\n",
      "\taction [-0.42854711 -0.11774635 -0.47317055 -0.37493184]\n",
      "\taction [-0.20918274 -0.24067076 -0.26921818 -0.2443544 ]\n",
      "\taction [-0.22217765 -0.2785317  -0.25533903 -0.34263933]\n",
      "episode 255 at 1000 ts; done reached\n",
      "\taction [-0.83442682 -0.99581319 -0.92002892 -0.98932409]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [-0.5425756  -0.22344212 -0.293686   -0.53105628]\n",
      "\taction [-0.39705783 -0.40193012 -0.34522256 -0.5841285 ]\n",
      "\taction [-0.27986524 -0.5102877  -0.30285341 -0.3720409 ]\n",
      "episode 256 at 1000 ts; done reached\n",
      "\taction [-0.85382527 -0.81162918 -0.90719187 -0.94428074]\n",
      "\taction [-0.3662889  -0.32554731 -0.36400291 -0.52908701]\n",
      "\taction [-0.39326164 -0.24964792 -0.57579911 -0.22237575]\n",
      "\taction [-0.36462045 -0.271579   -0.27466235 -0.39828464]\n",
      "episode 257 at 1000 ts; done reached\n",
      "\taction [-0.92930627 -0.9928112  -0.85339206 -0.90070128]\n",
      "\taction [-0.21355569 -0.28968835 -0.5110451  -0.34759775]\n",
      "\taction [-0.36244962 -0.3324627  -0.32600707 -0.34486365]\n",
      "\taction [-0.32149333 -0.268493   -0.41538039 -0.29886779]\n",
      "episode 258 at 1000 ts; done reached\n",
      "\taction [-0.86158621 -0.86362451 -0.84231132 -0.81943434]\n",
      "\taction [-0.35682908 -0.28712383 -0.30921727 -0.30670556]\n",
      "\taction [-0.31446919 -0.27064213 -0.27235726 -0.25854367]\n",
      "\taction [-0.28165638 -0.3710514  -0.38995376 -0.36649582]\n",
      "episode 259 at 1000 ts; done reached\n",
      "\taction [-0.82029569 -0.86505985 -0.89624554 -0.97447687]\n",
      "\taction [-0.41298285 -0.46601683 -0.54507649 -0.23224819]\n",
      "\taction [-0.15582769 -0.30286604 -0.3106252  -0.25220761]\n",
      "\taction [-0.34108344 -0.31358966 -0.40223747 -0.26617363]\n",
      "episode 260 at 1000 ts; done reached\n",
      "\taction [-0.8453306  -0.86109632 -0.98119909 -0.8209821 ]\n",
      "\taction [-0.23173596 -0.49688545 -0.3941558  -0.17154504]\n",
      "\taction [-0.25571978 -0.27199954 -0.15806732 -0.29499653]\n",
      "\taction [-0.39254397 -0.35160884 -0.25546247 -0.355712  ]\n",
      "episode 261 at 1000 ts; done reached\n",
      "\taction [-0.99209362 -0.86488932 -0.9382956  -0.86025089]\n",
      "\taction [-0.42676193 -0.25041819 -0.25317696 -0.30356544]\n",
      "\taction [-0.28853518 -0.34550399 -0.24838673 -0.36682129]\n",
      "\taction [-0.39278823 -0.21516687 -0.24027701 -0.4012309 ]\n",
      "episode 262 at 1000 ts; done reached\n",
      "\taction [-0.89226609 -0.89920086 -0.83485705 -0.82724029]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\taction [-0.17425227 -0.44836524 -0.32151097 -0.42799288]\n",
      "\taction [-0.43435299 -0.49305922 -0.24319468 -0.22326581]\n",
      "\taction [-0.28789678 -0.32242528 -0.3671729  -0.39174399]\n",
      "episode 263 at 1000 ts; done reached\n",
      "\taction [-0.88764048 -0.97469765 -0.98695111 -0.98966432]\n",
      "\taction [-0.39280233 -0.55895013 -0.30331269 -0.20339085]\n",
      "\taction [-0.17242473 -0.16182092 -0.41711262 -0.38601637]\n",
      "\taction [-0.29844281 -0.20360337 -0.49315172 -0.47178572]\n",
      "episode 264 at 1000 ts; done reached\n",
      "\taction [-0.93844104 -0.95129639 -0.85250902 -0.89830989]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [-0.47690642 -0.28940749 -0.35515276 -0.51997924]\n",
      "\taction [-0.24124944 -0.34102708 -0.27853566 -0.35238025]\n",
      "\taction [-0.4293313  -0.42354655 -0.34511721 -0.39141032]\n",
      "episode 265 at 1000 ts; done reached\n",
      "\taction [-0.98613346 -0.87885797 -0.93095684 -0.94928849]\n",
      "\taction [-0.34006307 -0.25833765 -0.33621481 -0.23966129]\n",
      "\taction [-0.45928583 -0.30747256 -0.36013484 -0.38202837]\n",
      "\taction [-0.49528381 -0.35289803 -0.14768581 -0.27933249]\n",
      "episode 266 at 1000 ts; done reached\n",
      "\taction [-0.99912053 -0.91532642 -0.81903172 -0.86656761]\n",
      "\taction [-0.32221532 -0.28444323 -0.3820594  -0.39809564]\n",
      "\taction [-0.33322364 -0.37424472 -0.07080077 -0.35822138]\n",
      "\taction [-0.25939444 -0.41457802 -0.2642805  -0.31913999]\n",
      "episode 267 at 1000 ts; done reached\n",
      "\taction [-0.9530471  -0.98910725 -0.9155758  -0.90151292]\n",
      "\taction [-0.28430539 -0.19005699 -0.26071328 -0.35763323]\n",
      "\taction [-0.420077   -0.24842657 -0.29096529 -0.31737852]\n",
      "\taction [-0.29987526 -0.26611096 -0.22111446 -0.20827611]\n",
      "episode 268 at 1000 ts; done reached\n",
      "\taction [-0.97881043 -0.89056778 -0.91459107 -0.99080461]\n",
      "\taction [-0.38165823 -0.40164256 -0.26123241 -0.34795329]\n",
      "\taction [-0.25086755 -0.4537251  -0.05621625 -0.2866824 ]\n",
      "\taction [-0.30766603 -0.32982716 -0.26759034 -0.33637094]\n",
      "episode 269 at 1000 ts; done reached\n",
      "\taction [-0.99046344 -0.8909393  -0.87524915 -0.89680606]\n",
      "\taction [-0.43538031 -0.14144419 -0.43686339 -0.25976777]\n",
      "\taction [-0.3664006  -0.30819732 -0.41495878 -0.38331002]\n",
      "\taction [-0.3312912  -0.39115936 -0.4990508  -0.28128207]\n",
      "episode 270 at 1000 ts; done reached\n",
      "\taction [-0.91144377 -0.95937932 -0.88842905 -0.92627227]\n",
      "\taction [-0.56089914 -0.34601864 -0.33733666 -0.24900563]\n",
      "\taction [-0.4627752  -0.36814862 -0.2969192  -0.32269245]\n",
      "\taction [-0.34964091 -0.32016894 -0.37661642 -0.48327774]\n",
      "episode 271 at 1000 ts; done reached\n",
      "\taction [-0.85315287 -0.92309254 -0.98171735 -0.91733003]\n",
      "\taction [-0.42893398 -0.48293588 -0.39290425 -0.42236805]\n",
      "\taction [-0.23085022 -0.07831247 -0.27499309 -0.15939203]\n",
      "\taction [-0.56702399 -0.36927485 -0.22417343 -0.22965796]\n",
      "episode 272 at 1000 ts; done reached\n",
      "\taction [-0.89577252 -0.81786644 -0.85219932 -0.83842695]\n",
      "\taction [-0.16245823 -0.18453614 -0.22450791 -0.37126127]\n",
      "\taction [-0.47418642 -0.22286889 -0.45070952 -0.51657635]\n",
      "\taction [-0.36372948 -0.27272004 -0.4814471  -0.29873696]\n",
      "episode 273 at 1000 ts; done reached\n",
      "\taction [-0.90910828 -0.89849561 -0.97005343 -0.90764612]\n",
      "\taction [-0.50458795 -0.33495036 -0.35364833 -0.34280661]\n",
      "\taction [-0.24091843 -0.22087303 -0.4458648  -0.13020457]\n",
      "\taction [-0.55362213 -0.48749688 -0.25909358 -0.48619276]\n",
      "episode 274 at 1000 ts; done reached\n",
      "\taction [-0.95773554 -0.80041659 -0.92238861 -0.87942392]\n",
      "\taction [-0.40100265 -0.40891793 -0.27866665 -0.43593782]\n",
      "\taction [-0.35621282 -0.12382804 -0.3847211  -0.18639365]\n",
      "\taction [-0.25572005 -0.32095367 -0.16860041 -0.39308637]\n",
      "episode 275 at 1000 ts; done reached\n",
      "\taction [-0.88609868 -0.91689414 -0.84854257 -0.92460775]\n",
      "\taction [-0.38755268 -0.41841307 -0.42492443 -0.31667969]\n",
      "\taction [-0.36488828 -0.18362369 -0.43572274 -0.38546279]\n",
      "\taction [-0.456489   -0.33669743 -0.17394976 -0.33885023]\n",
      "episode 276 at 1000 ts; done reached\n",
      "\taction [-0.97084624 -0.97483909 -0.97549754 -0.90813953]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "\taction [-0.34252596 -0.44804311 -0.39107829 -0.44464538]\n",
      "\taction [-0.33380729 -0.44773746 -0.30766279 -0.24277748]\n",
      "\taction [-0.34341431 -0.23858894 -0.48187175 -0.20865701]\n",
      "episode 277 at 1000 ts; done reached\n",
      "\taction [-0.88864613 -0.95051587 -0.84374577 -0.89901775]\n",
      "\taction [-0.37278408 -0.10749205 -0.35216027 -0.20722678]\n",
      "\taction [-0.24955732 -0.21849382 -0.45359203 -0.32460663]\n",
      "\taction [-0.38434365 -0.23900774 -0.34764841 -0.27447143]\n",
      "episode 278 at 1000 ts; done reached\n",
      "\taction [-0.80581009 -0.91965818 -0.98956883 -0.98256612]\n",
      "\taction [-0.29748487 -0.18189339 -0.37546441 -0.35466272]\n",
      "\taction [-0.32335973 -0.24979258 -0.13896267 -0.31976375]\n",
      "\taction [-0.25174078 -0.36088717 -0.22505975 -0.36156267]\n",
      "episode 279 at 1000 ts; done reached\n",
      "\taction [-0.91508323 -0.88483149 -0.84248126 -0.91568834]\n",
      "\taction [-0.47890538 -0.28695384 -0.3677018  -0.35544765]\n",
      "\taction [-0.37849036 -0.47697929 -0.13980074 -0.41973427]\n",
      "\taction [-0.35325339 -0.22936967 -0.30725634 -0.59703606]\n",
      "episode 280 at 1000 ts; done reached\n",
      "\taction [-0.85048908 -0.97776026 -0.98998863 -0.85838091]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [-0.14639488 -0.31416428 -0.18926322 -0.39997247]\n",
      "\taction [-0.3749508  -0.44849545 -0.17963457 -0.22363645]\n",
      "\taction [-0.46869159 -0.42069709 -0.21422574 -0.31337258]\n",
      "episode 281 at 1000 ts; done reached\n",
      "\taction [-0.88040376 -0.97820652 -0.97430432 -0.8471989 ]\n",
      "\taction [-0.34719729 -0.48972663 -0.49769524 -0.35610989]\n",
      "\taction [-0.18746558 -0.28847247 -0.42581487 -0.33791941]\n",
      "\taction [-0.43004972 -0.3027555  -0.54360098 -0.37273037]\n",
      "episode 282 at 1000 ts; done reached\n",
      "\taction [-0.8867439  -0.9141199  -0.91714466 -0.87177414]\n",
      "\taction [-0.28570181 -0.21261387 -0.13765591 -0.30464381]\n",
      "\taction [-0.26881498 -0.36859632 -0.19976079 -0.3189154 ]\n",
      "\taction [-0.36664987 -0.13349305 -0.41570824 -0.33208099]\n",
      "episode 283 at 1000 ts; done reached\n",
      "\taction [-0.997334   -0.94738072 -0.83380699 -0.83547133]\n",
      "\taction [-0.39066911 -0.41506198 -0.37767422 -0.05393593]\n",
      "\taction [-0.46848941 -0.19808757 -0.36274818 -0.51469588]\n",
      "\taction [-0.43451273 -0.33124018 -0.25467786 -0.23505296]\n",
      "episode 284 at 1000 ts; done reached\n",
      "\taction [-0.94295871 -0.90803337 -0.94021207 -0.8459785 ]\n",
      "\taction [-0.30399099 -0.39079627 -0.30202135 -0.27523559]\n",
      "\taction [-0.28030947 -0.24269594 -0.45715767 -0.24983101]\n",
      "\taction [-0.34300748 -0.31921428 -0.15598793 -0.29316539]\n",
      "episode 285 at 1000 ts; done reached\n",
      "\taction [-0.92770898 -0.89811838 -0.81547874 -0.90433264]\n",
      "\taction [-0.53867596 -0.50611907 -0.50245106 -0.32706249]\n",
      "\taction [-0.30141878 -0.26029733 -0.46372372 -0.51188993]\n",
      "\taction [-0.4070155  -0.24701186 -0.23199569 -0.26203978]\n",
      "episode 286 at 1000 ts; done reached\n",
      "\taction [-0.87541622 -0.85963821 -0.9094258  -0.95510733]\n",
      "\taction [-0.38699725 -0.4139716  -0.36676109 -0.24519536]\n",
      "\taction [-0.47460547 -0.249405   -0.4436048  -0.38177618]\n",
      "\taction [-0.41073772 -0.37428185 -0.27962098 -0.26120794]\n",
      "episode 287 at 1000 ts; done reached\n",
      "\taction [-0.9981724  -0.87664115 -0.94984704 -0.83822089]\n",
      "\taction [-0.28506187 -0.2105951  -0.23889741 -0.40943819]\n",
      "\taction [-0.33089235 -0.35301897 -0.29178497 -0.28958145]\n",
      "\taction [-0.37557361 -0.35547221 -0.16584276 -0.39788982]\n",
      "episode 288 at 1000 ts; done reached\n",
      "\taction [-0.98983693 -0.98985535 -0.8868314  -0.87823021]\n",
      "\taction [-0.25153422 -0.36426398 -0.19434683 -0.42898586]\n",
      "\taction [-0.32529956 -0.4670389  -0.15330994 -0.3148118 ]\n",
      "\taction [-0.27809116 -0.3391743  -0.33971363 -0.34959647]\n",
      "episode 289 at 1000 ts; done reached\n",
      "\taction [-0.81436741 -0.94082713 -0.88454133 -0.92317522]\n",
      "\taction [-0.43893832 -0.29288855 -0.50507712 -0.1716212 ]\n",
      "\taction [-0.2277818  -0.32123771 -0.41170755 -0.21269281]\n",
      "\taction [-0.30332017 -0.39661023 -0.35522267 -0.15821531]\n",
      "episode 290 at 1000 ts; done reached\n",
      "\taction [-0.80902797 -0.87763751 -0.92082554 -0.9913159 ]\n",
      "\taction [-0.35315958 -0.3635602  -0.42664811 -0.38280725]\n",
      "\taction [-0.36896309 -0.22450995 -0.40494126 -0.30576617]\n",
      "\taction [-0.22468373 -0.5383119  -0.34716877 -0.11887293]\n",
      "episode 291 at 1000 ts; done reached\n",
      "\taction [-0.82115233 -0.85649598 -0.90274674 -0.97035712]\n",
      "\taction [-0.21083269 -0.29291075 -0.29532206 -0.16920602]\n",
      "\taction [-0.35136324 -0.38210166 -0.29836282 -0.4763436 ]\n",
      "\taction [-0.44504124 -0.31629241 -0.24698818 -0.25823376]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 292 at 1000 ts; done reached\n",
      "\taction [-0.90889925 -0.88720447 -0.98412806 -0.96397102]\n",
      "\taction [-0.25354257 -0.52657789 -0.27865714 -0.3286742 ]\n",
      "\taction [-0.4279961  -0.35431963 -0.30405077 -0.32177702]\n",
      "\taction [-0.28627503 -0.34575856 -0.52416575 -0.1485644 ]\n",
      "episode 293 at 1000 ts; done reached\n",
      "\taction [-0.92090243 -0.88238847 -0.93451208 -0.8623032 ]\n",
      "\taction [-0.30747831 -0.37824196 -0.21691266 -0.5223642 ]\n",
      "\taction [-0.23635358 -0.28002921 -0.138402   -0.34273449]\n",
      "\taction [-0.31713608 -0.37109721 -0.40866742 -0.32332054]\n",
      "episode 294 at 1000 ts; done reached\n",
      "\taction [-0.8635422  -0.96792775 -0.88303834 -0.89142197]\n",
      "\taction [-0.38197792 -0.32021344 -0.11806531 -0.28021288]\n",
      "\taction [-0.34947819 -0.17964225 -0.15889385 -0.55072999]\n",
      "\taction [-0.37828094 -0.41565475 -0.30097234 -0.51353502]\n",
      "episode 295 at 1000 ts; done reached\n",
      "\taction [-0.9887619  -0.83429229 -0.94658762 -0.85702938]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [-0.29519638 -0.35738808 -0.42074513 -0.47990498]\n",
      "\taction [-0.3174457  -0.49942428 -0.42437738 -0.19964573]\n",
      "\taction [-0.31815964 -0.52342969 -0.31567603 -0.4942351 ]\n",
      "episode 296 at 1000 ts; done reached\n",
      "\taction [-0.84330732 -0.87833345 -0.966286   -0.93308878]\n",
      "\taction [-0.38165164 -0.19191065 -0.30265775 -0.3685931 ]\n",
      "\taction [-0.22592126 -0.38994744 -0.3642762  -0.36446881]\n",
      "\taction [-0.33224034 -0.36664993 -0.44959447 -0.45198777]\n",
      "episode 297 at 1000 ts; done reached\n",
      "\taction [-0.88570243 -0.84961772 -0.81614935 -0.89241666]\n",
      "\taction [-0.35606405 -0.19285813 -0.45293757 -0.59784466]\n",
      "\taction [-0.50893229 -0.46368697 -0.45744276 -0.39406428]\n",
      "\taction [-0.46198016 -0.44793391 -0.26144627 -0.25527012]\n",
      "episode 298 at 1000 ts; done reached\n",
      "\taction [-0.8211785  -0.8399325  -0.96158457 -0.99889916]\n",
      "\taction [-0.24976398 -0.10464671 -0.24098313 -0.41239375]\n",
      "\taction [-0.54735839 -0.13918149 -0.38083515 -0.22677417]\n",
      "\taction [-0.31582236 -0.37134147 -0.50097501 -0.61013901]\n",
      "episode 299 at 1000 ts; done reached\n",
      "\taction [-0.81776303 -0.80121708 -0.82315427 -0.87301749]\n",
      "\taction [-0.13189422 -0.34400475 -0.50590384 -0.46831787]\n",
      "\taction [-0.38417262 -0.47445434 -0.33925626 -0.26916194]\n",
      "\taction [-0.29326952 -0.38259378 -0.44390517 -0.28466207]\n",
      "episode 300 at 1000 ts; done reached\n",
      "episode 300; average score past 100 episodes: 0.011499999742954969\n",
      "\taction [-0.91694087 -0.87816191 -0.84761083 -0.92398202]\n",
      "\taction [-0.38501513 -0.07418401 -0.15064655 -0.41582537]\n",
      "\taction [-0.34873292 -0.42800596 -0.33246702 -0.29346555]\n",
      "\taction [-0.43034169 -0.43281972 -0.41306779 -0.38252255]\n",
      "episode 301 at 1000 ts; done reached\n",
      "\taction [-0.87439126 -0.86296189 -0.96525472 -0.95289075]\n",
      "\taction [-0.37060687 -0.36181846 -0.46940675 -0.29842281]\n",
      "\taction [-0.27810371 -0.39590889 -0.30053216 -0.27210835]\n",
      "\taction [-0.51215106 -0.35933593 -0.53797901 -0.38476503]\n",
      "episode 302 at 1000 ts; done reached\n",
      "\taction [-0.97687328 -0.91481775 -0.84760475 -0.86097574]\n",
      "\taction [-0.27782276 -0.30937722 -0.48322627 -0.4449726 ]\n",
      "\taction [-0.19947451 -0.39845225 -0.31984276 -0.2578913 ]\n",
      "\taction [-0.44656643 -0.27631676 -0.45500264 -0.3262417 ]\n",
      "episode 303 at 1000 ts; done reached\n",
      "\taction [-0.94546455 -0.83882225 -0.86267275 -0.85596251]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [-0.31258601 -0.30360055 -0.35373968 -0.30285394]\n",
      "\taction [-0.29884207 -0.37745798 -0.54428482 -0.23320556]\n",
      "\taction [-0.60859019 -0.48719394 -0.46335685 -0.40439048]\n",
      "episode 304 at 1000 ts; done reached\n",
      "\taction [-0.86140215 -0.98389661 -0.94387877 -0.84626454]\n",
      "\taction [-0.35748714 -0.47696695 -0.38845658 -0.37813565]\n",
      "\taction [-0.2579051  -0.44003457 -0.42840716 -0.46908337]\n",
      "\taction [-0.47786137 -0.28644952 -0.36466569 -0.3252334 ]\n",
      "episode 305 at 1000 ts; done reached\n",
      "\taction [-0.89490211 -0.95691305 -0.87027228 -0.84618533]\n",
      "\taction [-0.29231507 -0.22075421 -0.43065444 -0.49317086]\n",
      "\taction [-0.33593652 -0.28098154 -0.31058049 -0.16116998]\n",
      "\taction [-0.42051128 -0.37167436 -0.38706142 -0.27417088]\n",
      "episode 306 at 1000 ts; done reached\n",
      "\taction [-0.90250134 -0.92563635 -0.86323225 -0.86548609]\n",
      "\taction [-0.22223164 -0.4214845  -0.35320047 -0.25034279]\n",
      "\taction [-0.42029119 -0.43829784 -0.18125464 -0.41109899]\n",
      "\taction [-0.29625762 -0.25520602 -0.30275014 -0.39778516]\n",
      "episode 307 at 1000 ts; done reached\n",
      "\taction [-0.95671999 -0.83633024 -0.92677683 -0.88763165]\n",
      "\taction [-0.46165287 -0.30179816 -0.38258034 -0.23820771]\n",
      "\taction [-0.22100627 -0.11339354 -0.27829039 -0.40477541]\n",
      "\taction [-0.20128727 -0.1776747  -0.26615304 -0.2746031 ]\n",
      "episode 308 at 1000 ts; done reached\n",
      "\taction [-0.99314612 -0.8693068  -0.81132257 -0.98028082]\n",
      "\taction [-0.38399762 -0.27177501 -0.25801349 -0.33595976]\n",
      "\taction [-0.29807371 -0.34429005 -0.35320923 -0.18550526]\n",
      "\taction [-0.55986381 -0.23314798 -0.38292432 -0.46863157]\n",
      "episode 309 at 1000 ts; done reached\n",
      "\taction [-0.9306308  -0.83115435 -0.94966555 -0.97655225]\n",
      "\taction [-0.36193618 -0.17832553 -0.20861891 -0.47434181]\n",
      "\taction [-0.42646948 -0.26870453 -0.29558185 -0.34801233]\n",
      "\taction [-0.25277269 -0.57619524 -0.42251599 -0.22355901]\n",
      "episode 310 at 1000 ts; done reached\n",
      "\taction [-0.99771523 -0.89661402 -0.86022556 -0.91341442]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [-0.2244247  -0.38049108 -0.39110228 -0.35613793]\n",
      "\taction [-0.19956551 -0.11312244 -0.26632732 -0.22432336]\n",
      "\taction [-0.3392635  -0.34623215 -0.1465099  -0.4606213 ]\n",
      "episode 311 at 1000 ts; done reached\n",
      "\taction [-0.82956964 -0.8871218  -0.91446978 -0.85839719]\n",
      "\taction [-0.34409541 -0.39955601 -0.38705963 -0.36317289]\n",
      "\taction [-0.31541014 -0.38026193 -0.49297297 -0.57290518]\n",
      "\taction [-0.28931832 -0.10199756 -0.37859321 -0.18018165]\n",
      "episode 312 at 1000 ts; done reached\n",
      "\taction [-0.94351292 -0.88558769 -0.94921285 -0.91455323]\n",
      "\taction [-0.62842357 -0.35912991 -0.22656654 -0.24305139]\n",
      "\taction [-0.4031226  -0.2564683  -0.36165732 -0.47685915]\n",
      "\taction [-0.37046647 -0.26844001 -0.03416277 -0.39913121]\n",
      "episode 313 at 1000 ts; done reached\n",
      "\taction [-0.90469629 -0.98505008 -0.91330099 -0.96042824]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [-0.32683507 -0.38687    -0.53160512 -0.38940173]\n",
      "\taction [-0.44051245 -0.13261895 -0.27936229 -0.23979564]\n",
      "\taction [-0.40950578 -0.33656767 -0.25766116 -0.15836331]\n",
      "episode 314 at 1000 ts; done reached\n",
      "\taction [-0.82772428 -0.9758544  -0.98623306 -0.84051967]\n",
      "\taction [-0.26563567 -0.23406151 -0.39430317 -0.23879908]\n",
      "\taction [-0.28802466 -0.35700423 -0.27470183 -0.09846465]\n",
      "\taction [-0.22534309 -0.2752353  -0.21960859 -0.45001566]\n",
      "episode 315 at 1000 ts; done reached\n",
      "\taction [-0.90577418 -0.98164386 -0.97444814 -0.97121429]\n",
      "\taction [-0.38636339 -0.30987343 -0.31769413 -0.38540167]\n",
      "\taction [-0.3110489  -0.21371911 -0.16875361 -0.22070843]\n",
      "\taction [-0.30378249 -0.31870711 -0.23588432 -0.31518257]\n",
      "episode 316 at 1000 ts; done reached\n",
      "\taction [-0.97399765 -0.82487047 -0.96782374 -0.86076236]\n",
      "\taction [-0.22506292 -0.30357251 -0.38584083 -0.40977708]\n",
      "\taction [-0.33177921 -0.33478537 -0.30321571 -0.4475657 ]\n",
      "\taction [-0.325643   -0.47871417 -0.43704069 -0.32054883]\n",
      "episode 317 at 1000 ts; done reached\n",
      "\taction [-0.89658415 -0.83089131 -0.88947207 -0.8134467 ]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [-0.12063114 -0.39842635 -0.28237334 -0.23160824]\n",
      "\taction [-0.25012347 -0.14982171 -0.28552011 -0.25988001]\n",
      "\taction [-0.18404058 -0.31207713 -0.3170945  -0.1743442 ]\n",
      "episode 318 at 1000 ts; done reached\n",
      "\taction [-0.89091963 -0.95884573 -0.87311041 -0.89921767]\n",
      "\taction [-0.22897649 -0.07994496 -0.34436092 -0.43823299]\n",
      "\taction [-0.20374051 -0.31920451 -0.26963657 -0.24075134]\n",
      "\taction [-0.33704549 -0.2521469  -0.34241596 -0.12378671]\n",
      "episode 319 at 1000 ts; done reached\n",
      "\taction [-0.96606457 -0.99451053 -0.85982943 -0.90538657]\n",
      "\taction [-0.33308458 -0.40437028 -0.32615957 -0.24877603]\n",
      "\taction [-0.3746787  -0.33721495 -0.25548655 -0.29563698]\n",
      "\taction [-0.5222218  -0.29656264 -0.38146481 -0.19540764]\n",
      "episode 320 at 1000 ts; done reached\n",
      "\taction [-0.91949195 -0.83478296 -0.92749643 -0.94961983]\n",
      "\taction [-0.47487414 -0.24814844 -0.28801414 -0.37132141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\taction [-0.28193155 -0.35248747 -0.24598491 -0.23869728]\n",
      "\taction [-0.46308273 -0.36410782 -0.25705525 -0.27694035]\n",
      "episode 321 at 1000 ts; done reached\n",
      "\taction [-0.92611516 -0.96788484 -0.95308179 -0.94770241]\n",
      "\taction [-0.34721413 -0.45874074 -0.25266284 -0.38267469]\n",
      "\taction [-0.1775796  -0.33196184 -0.14955151 -0.20876047]\n",
      "\taction [-0.44223833 -0.44230464 -0.20947559 -0.13818033]\n",
      "episode 322 at 1000 ts; done reached\n",
      "\taction [-0.81014776 -0.90813375 -0.8188417  -0.91291338]\n",
      "\taction [-0.3827492  -0.38688701 -0.52411067 -0.39211929]\n",
      "\taction [-0.33972391 -0.18687271 -0.47034928 -0.51953596]\n",
      "\taction [-0.45509738 -0.4250049  -0.45799962 -0.24611396]\n",
      "episode 323 at 1000 ts; done reached\n",
      "\taction [-0.86831516 -0.82874227 -0.83233762 -0.92686284]\n",
      "\taction [-0.15189192 -0.42781857 -0.25774533 -0.39422876]\n",
      "\taction [-0.32274982 -0.11144125 -0.30709022 -0.31651893]\n",
      "\taction [-0.31544825 -0.33851731 -0.53144556 -0.38552985]\n",
      "episode 324 at 1000 ts; done reached\n",
      "\taction [-0.90154618 -0.86652011 -0.93165344 -0.91873497]\n",
      "\taction [-0.41110745 -0.26692462 -0.50549364 -0.23370948]\n",
      "\taction [-0.33145049 -0.21588783 -0.49747777 -0.36124212]\n",
      "\taction [-0.49499741 -0.25779808 -0.35331425 -0.34362745]\n",
      "episode 325 at 1000 ts; done reached\n",
      "\taction [-0.87861019 -0.8553369  -0.97058892 -0.98323989]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [-0.16849214 -0.30709642 -0.239877   -0.32644626]\n",
      "\taction [-0.24604687 -0.25579005 -0.50452924 -0.38216817]\n",
      "\taction [-0.33874509 -0.27974415 -0.23306827 -0.27291173]\n",
      "episode 326 at 1000 ts; done reached\n",
      "\taction [-0.81615645 -0.99574554 -0.91686279 -0.96480978]\n",
      "\taction [-0.10740295 -0.43803284 -0.25427678 -0.37781498]\n",
      "\taction [-0.39800087 -0.41563475 -0.23845367 -0.38344038]\n",
      "\taction [-0.29588243 -0.37908545 -0.26525724 -0.319572  ]\n",
      "episode 327 at 1000 ts; done reached\n",
      "\taction [-0.85067564 -0.92086339 -0.80053407 -0.96706414]\n",
      "\taction [-0.21975884 -0.21313784 -0.34146062 -0.37353766]\n",
      "\taction [-0.53942961 -0.52587783 -0.41929287 -0.42781022]\n",
      "\taction [-0.34612507 -0.56150538 -0.36237654 -0.25487465]\n",
      "episode 328 at 1000 ts; done reached\n",
      "\taction [-0.83199239 -0.86280334 -0.90729815 -0.81915271]\n",
      "\taction [-0.37359953 -0.27767676 -0.44087899 -0.45330036]\n",
      "\taction [-0.32039177 -0.50620675 -0.43809313 -0.35393414]\n",
      "\taction [-0.6237905  -0.33099669 -0.4336367  -0.30693224]\n",
      "episode 329 at 1000 ts; done reached\n",
      "\taction [-0.9620896  -0.88654768 -0.84843832 -0.92428291]\n",
      "\taction [-0.30746961 -0.42188492 -0.40191162 -0.46116692]\n",
      "\taction [-0.47018415 -0.41739297 -0.35674179 -0.21003652]\n",
      "\taction [-0.37931186 -0.14263102 -0.30284151 -0.50340688]\n",
      "episode 330 at 1000 ts; done reached\n",
      "\taction [-0.96591944 -0.83770645 -0.97655112 -0.85974944]\n",
      "\taction [-0.341824   -0.25393185 -0.26003361 -0.1792016 ]\n",
      "\taction [-0.25624979 -0.2520704  -0.06628603 -0.21510589]\n",
      "\taction [-0.42660201 -0.36217153 -0.36983752 -0.39160603]\n",
      "episode 331 at 1000 ts; done reached\n",
      "\taction [-0.90429193 -0.86311042 -0.92585653 -0.8118068 ]\n",
      "\taction [-0.46302885 -0.13023823 -0.24647038 -0.19440748]\n",
      "\taction [-0.29339316 -0.28353998 -0.32374954 -0.42061108]\n",
      "\taction [-0.30613512 -0.11935254 -0.15266457 -0.29592589]\n",
      "episode 332 at 1000 ts; done reached\n",
      "\taction [-0.83332479 -0.96245891 -0.87263566 -0.85352296]\n",
      "\taction [-0.23286995 -0.44066766 -0.517793   -0.2987406 ]\n",
      "\taction [-0.22576191 -0.34097433 -0.30559313 -0.28542528]\n",
      "\taction [-0.36953551 -0.19752692 -0.48951429 -0.23746304]\n",
      "episode 333 at 1000 ts; done reached\n",
      "\taction [-0.97390783 -0.8547315  -0.87913221 -0.90591997]\n",
      "\taction [-0.52128315 -0.25545785 -0.33303452 -0.30428922]\n",
      "\taction [-0.21524157 -0.30288339 -0.30541223 -0.19873753]\n",
      "\taction [-0.45547199 -0.33296677 -0.34097072 -0.35549921]\n",
      "episode 334 at 1000 ts; done reached\n",
      "\taction [-0.86315298 -0.80864155 -0.99413806 -0.93841803]\n",
      "\taction [-0.41664305 -0.27521601 -0.2202213  -0.37598422]\n",
      "\taction [-0.32289332 -0.35008007 -0.32068264 -0.36922044]\n",
      "\taction [-0.50201774 -0.37387082 -0.38780293 -0.2743471 ]\n",
      "episode 335 at 1000 ts; done reached\n",
      "\taction [-0.81000257 -0.82677704 -0.89624202 -0.92925102]\n",
      "\taction [-0.30760479 -0.1136814  -0.302847   -0.26778162]\n",
      "\taction [-0.45022047 -0.17969918 -0.34987348 -0.15020794]\n",
      "\taction [-0.43699628 -0.30605921 -0.28987774 -0.38348886]\n",
      "episode 336 at 1000 ts; done reached\n",
      "\taction [-0.90867192 -0.8586964  -0.83594447 -0.91897273]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [-0.43266255 -0.15434505 -0.17375401 -0.32796574]\n",
      "\taction [-0.38322347 -0.35882166 -0.27814654 -0.21782781]\n",
      "\taction [-0.44774905 -0.24778864 -0.25214547 -0.32649755]\n",
      "episode 337 at 1000 ts; done reached\n",
      "\taction [-0.902448   -0.91502202 -0.83259863 -0.85864222]\n",
      "\taction [-0.28977028 -0.50385284 -0.41735563 -0.46386111]\n",
      "\taction [-0.21737909 -0.25593951 -0.61593491 -0.20449318]\n",
      "\taction [-0.41870746 -0.51040101 -0.20350976 -0.42219773]\n",
      "episode 338 at 1000 ts; done reached\n",
      "\taction [-0.99917758 -0.85037196 -0.97616005 -0.89858484]\n",
      "\taction [-0.47993973 -0.4338291  -0.5138855  -0.28560773]\n",
      "\taction [-0.2541019  -0.32953188 -0.37332463 -0.14375672]\n",
      "\taction [-0.45296785 -0.30874997 -0.22895303 -0.39296207]\n",
      "episode 339 at 1000 ts; done reached\n",
      "\taction [-0.96692336 -0.95833737 -0.89452368 -0.88004684]\n",
      "\taction [-0.3626526  -0.3523837  -0.29312518 -0.30902314]\n",
      "\taction [-0.46115357 -0.38180467 -0.43876135 -0.4335722 ]\n",
      "\taction [-0.23726194 -0.34977147 -0.31896517 -0.31351638]\n",
      "episode 340 at 1000 ts; done reached\n",
      "\taction [-0.81332129 -0.92226446 -0.85761172 -0.91055048]\n",
      "\taction [-0.40073618 -0.26911235 -0.41387537 -0.32765475]\n",
      "\taction [-0.34098294 -0.04315548 -0.40539494 -0.21658736]\n",
      "\taction [-0.3486703  -0.29369599 -0.26325405 -0.22832981]\n",
      "episode 341 at 1000 ts; done reached\n",
      "\taction [-0.90354884 -0.95464766 -0.91556829 -0.84696668]\n",
      "\taction [-0.29506174 -0.32333919 -0.08886191 -0.3416962 ]\n",
      "\taction [-0.16828799 -0.17161696 -0.36625409 -0.35186353]\n",
      "\taction [-0.29534617 -0.36575121 -0.39339024 -0.43406346]\n",
      "episode 342 at 1000 ts; done reached\n",
      "\taction [-0.96293896 -0.96080947 -0.8195504  -0.93943012]\n",
      "\taction [-0.28122488 -0.29674679 -0.2035155  -0.33789459]\n",
      "\taction [-0.52211374 -0.21069483 -0.20782648 -0.24919057]\n",
      "\taction [-0.18590003 -0.29847723 -0.36687329 -0.13403097]\n",
      "episode 343 at 1000 ts; done reached\n",
      "\taction [-0.80814272 -0.95268434 -0.93356746 -0.98779237]\n",
      "\taction [-0.18523982 -0.34866598 -0.36596462 -0.27532282]\n",
      "\taction [-0.28482834 -0.37078047 -0.51295096 -0.38161558]\n",
      "\taction [-0.49628255 -0.50183874 -0.27045584 -0.39345038]\n",
      "episode 344 at 1000 ts; done reached\n",
      "\taction [-0.99753183 -0.88233715 -0.90798551 -0.83310562]\n",
      "\taction [-0.33716697 -0.33061507 -0.22985551 -0.30109939]\n",
      "\taction [-0.26667044 -0.38571835 -0.38212368 -0.22438309]\n",
      "\taction [-0.02088133 -0.3857739  -0.13421527 -0.24082978]\n",
      "episode 345 at 1000 ts; done reached\n",
      "\taction [-0.91960716 -0.87292248 -0.95993972 -0.86693126]\n",
      "\taction [-0.3806448  -0.25183186 -0.40109852 -0.25265667]\n",
      "\taction [-0.39190763 -0.47889042 -0.31685838 -0.35400698]\n",
      "\taction [-0.52467287 -0.42482048 -0.38519087 -0.55720866]\n",
      "episode 346 at 1000 ts; done reached\n",
      "\taction [-0.98246217 -0.87306422 -0.81830829 -0.99380648]\n",
      "\taction [-0.40410998 -0.32201549 -0.28715003 -0.44151813]\n",
      "\taction [-0.28347233 -0.29113215 -0.45672911 -0.49566707]\n",
      "\taction [-0.19128767 -0.48184925 -0.30076334 -0.35032371]\n",
      "episode 347 at 1000 ts; done reached\n",
      "\taction [-0.81113988 -0.88478523 -0.92818904 -0.99882072]\n",
      "\taction [-0.38503686 -0.42004463 -0.62651062 -0.23078766]\n",
      "\taction [-0.34488431 -0.14451784 -0.54788518 -0.18910888]\n",
      "\taction [-0.33660018 -0.33646956 -0.308391   -0.36442134]\n",
      "episode 348 at 1000 ts; done reached\n",
      "\taction [-0.83440393 -0.80380654 -0.92513555 -0.99036652]\n",
      "\taction [-0.39721248 -0.46264368 -0.14379501 -0.0996834 ]\n",
      "\taction [-0.40203714 -0.31439885 -0.32733992 -0.39561421]\n",
      "\taction [-0.30778402 -0.44138524 -0.36190787 -0.29295805]\n",
      "episode 349 at 1000 ts; done reached\n",
      "\taction [-0.92175931 -0.92947245 -0.85130131 -0.80713218]\n",
      "\taction [-0.43975413 -0.24962173 -0.46507025 -0.60878807]\n",
      "\taction [-0.39799011 -0.51054007 -0.29805109 -0.22762832]\n",
      "\taction [-0.34245804 -0.40998873 -0.33041468 -0.37344235]\n",
      "episode 350 at 1000 ts; done reached\n",
      "\taction [-0.83259422 -0.96820897 -0.90867889 -0.90702629]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\taction [-0.29871127 -0.44375804 -0.32682377 -0.21910378]\n",
      "\taction [-0.39896855 -0.26552624 -0.37422732 -0.18605413]\n",
      "\taction [-0.25881079 -0.3841801  -0.30586377 -0.31160977]\n",
      "episode 351 at 1000 ts; done reached\n",
      "\taction [-0.97652304 -0.91787088 -0.8078866  -0.92177308]\n",
      "\taction [-0.25327191 -0.12501234 -0.25638592 -0.29795504]\n",
      "\taction [-0.28250548 -0.14272679 -0.31149772 -0.12273859]\n",
      "\taction [-0.22508955 -0.38308141 -0.28051046 -0.3096616 ]\n",
      "episode 352 at 1000 ts; done reached\n",
      "\taction [-0.96434432 -0.89245921 -0.89170831 -0.84845787]\n",
      "\taction [-0.25153649 -0.31220996 -0.33238003 -0.26603651]\n",
      "\taction [-0.30568135 -0.32060939 -0.33336785 -0.37910041]\n",
      "\taction [-0.30997935 -0.13566871 -0.29438028 -0.30859223]\n",
      "episode 353 at 1000 ts; done reached\n",
      "\taction [-0.88906324 -0.80939621 -0.89933246 -0.96575236]\n",
      "\taction [-0.29918131 -0.34840873 -0.36009938 -0.28898531]\n",
      "\taction [-0.31536427 -0.16973791 -0.34460196 -0.34017769]\n",
      "\taction [-0.32405451 -0.55125475 -0.32089612 -0.47255212]\n",
      "episode 354 at 1000 ts; done reached\n",
      "\taction [-0.89119589 -0.81021637 -0.97130108 -0.80904847]\n",
      "\taction [-0.26163825 -0.08394763 -0.19188011 -0.49152169]\n",
      "\taction [-0.28215629 -0.2362182  -0.47573993 -0.34749436]\n",
      "\taction [-0.41862243 -0.31279492 -0.1126885  -0.1602049 ]\n",
      "episode 355 at 1000 ts; done reached\n",
      "\taction [-0.95344061 -0.88717705 -0.88850117 -0.84025753]\n",
      "\taction [-0.31503299 -0.3363685  -0.22953257 -0.31377545]\n",
      "\taction [-0.36892933 -0.12482602 -0.37648475 -0.33229303]\n",
      "\taction [-0.43612441 -0.25257725 -0.26779112 -0.37189141]\n",
      "episode 356 at 1000 ts; done reached\n",
      "\taction [-0.81962597 -0.92372668 -0.95149648 -0.85518926]\n",
      "\taction [-0.26168367 -0.3803314  -0.57532007 -0.22597563]\n",
      "\taction [-0.12974289 -0.48964262 -0.10664079 -0.40991417]\n",
      "\taction [-0.33939588 -0.37402079 -0.29140186 -0.10244714]\n",
      "episode 357 at 1000 ts; done reached\n",
      "\taction [-0.95804322 -0.8579815  -0.88108432 -0.82180262]\n",
      "\taction [-0.30403605 -0.2523258  -0.25910288 -0.47330552]\n",
      "\taction [-0.20674449 -0.26174974 -0.24082176 -0.43417066]\n",
      "\taction [-0.27409911 -0.54910713 -0.24189572 -0.54371804]\n",
      "episode 358 at 1000 ts; done reached\n",
      "\taction [-0.81690753 -0.92539489 -0.91536421 -0.81466234]\n",
      "\taction [-0.23813964 -0.24802172 -0.46573347 -0.28164208]\n",
      "\taction [-0.19581732 -0.27322432 -0.34463149 -0.47554585]\n",
      "\taction [-0.31791458 -0.3555474  -0.34627694 -0.21235768]\n",
      "episode 359 at 1000 ts; done reached\n",
      "\taction [-0.97021186 -0.82494688 -0.93047446 -0.987643  ]\n",
      "\taction [-0.32011279 -0.3215386  -0.54704589 -0.40747261]\n",
      "\taction [-0.40673235 -0.35652262 -0.37581384 -0.50246567]\n",
      "\taction [-0.30376387 -0.42396995 -0.47475195 -0.09809659]\n",
      "episode 360 at 1000 ts; done reached\n",
      "\taction [-0.81525207 -0.83059937 -0.99986053 -0.88884699]\n",
      "\taction [-0.42712784 -0.44937807 -0.29703638 -0.26560915]\n",
      "\taction [-0.34044829 -0.23265862 -0.39301011 -0.52447897]\n",
      "\taction [-0.46703729 -0.25302565 -0.27604946 -0.42852128]\n",
      "episode 361 at 1000 ts; done reached\n",
      "\taction [-0.85374105 -0.98010814 -0.94106048 -0.87751615]\n",
      "\taction [-0.3375605  -0.31063733 -0.44286054 -0.52583408]\n",
      "\taction [-0.35588118 -0.16235556 -0.43081543 -0.37116998]\n",
      "\taction [-0.2627317  -0.54358065 -0.36304432 -0.26972485]\n",
      "episode 362 at 1000 ts; done reached\n",
      "\taction [-0.86070925 -0.89835554 -0.87947434 -0.83539647]\n",
      "\taction [-0.48783398 -0.317074   -0.3674086  -0.44874907]\n",
      "\taction [-0.25388002 -0.43097141 -0.25652131 -0.50507998]\n",
      "\taction [-0.14933263 -0.31687185 -0.36218983 -0.41632071]\n",
      "episode 363 at 1000 ts; done reached\n",
      "\taction [-0.97082597 -0.82594872 -0.81601906 -0.83896875]\n",
      "\taction [-0.05989942 -0.36269221 -0.27841744 -0.47010648]\n",
      "\taction [-0.1592547  -0.23390439 -0.46445999 -0.34857821]\n",
      "\taction [-0.18398836 -0.27525529 -0.42477489 -0.34033784]\n",
      "episode 364 at 1000 ts; done reached\n",
      "\taction [-0.89567649 -0.90093946 -0.93188179 -0.98851526]\n",
      "\taction [-0.32722118 -0.35801685 -0.45010704 -0.29411173]\n",
      "\taction [-0.32532912 -0.55342263 -0.55993116 -0.46185452]\n",
      "\taction [-0.25047469 -0.29692262 -0.28031111 -0.4334617 ]\n",
      "episode 365 at 1000 ts; done reached\n",
      "\taction [-0.85218984 -0.86835963 -0.82088423 -0.96033746]\n",
      "\taction [-0.27845836 -0.39483359 -0.27402839 -0.33521968]\n",
      "\taction [-0.35482892 -0.29244146 -0.22893551 -0.22283252]\n",
      "\taction [-0.21842252 -0.30635646 -0.33213401 -0.27102232]\n",
      "episode 366 at 1000 ts; done reached\n",
      "\taction [-0.89213872 -0.84055346 -0.82998168 -0.80490392]\n",
      "\taction [-0.19788142 -0.35315457 -0.3323693  -0.38795173]\n",
      "\taction [-0.3281801  -0.43651903 -0.2789439  -0.21061888]\n",
      "\taction [-0.15009944 -0.2672213  -0.41570625 -0.16426529]\n",
      "episode 367 at 1000 ts; done reached\n",
      "\taction [-0.92231786 -0.89094496 -0.97588509 -0.92310482]\n",
      "\taction [-0.39968169 -0.3639901  -0.28408551 -0.43578774]\n",
      "\taction [-0.1850547  -0.42017522 -0.38031343 -0.46213996]\n",
      "\taction [-0.44692567 -0.30958033 -0.35419765 -0.19819589]\n",
      "episode 368 at 1000 ts; done reached\n",
      "\taction [-0.91166914 -0.84181958 -0.80702072 -0.9622646 ]\n",
      "\taction [-0.4406029  -0.3996582  -0.3277469  -0.37669089]\n",
      "\taction [-0.31412509 -0.2563917  -0.3456803  -0.05901348]\n",
      "\taction [-0.42254013 -0.44412196 -0.3307102  -0.46210942]\n",
      "episode 369 at 1000 ts; done reached\n",
      "\taction [-0.81082851 -0.95603102 -0.80064094 -0.86016876]\n",
      "\taction [-0.46808213 -0.3616848  -0.40681317 -0.4043124 ]\n",
      "\taction [-0.33907908 -0.363188   -0.34888089 -0.32349667]\n",
      "\taction [-0.23693493 -0.21907569 -0.47467762 -0.339858  ]\n",
      "episode 370 at 1000 ts; done reached\n",
      "\taction [-0.86364716 -0.91811693 -0.92536318 -0.87524354]\n",
      "\taction [-0.32392693 -0.17542545 -0.4559468  -0.30731985]\n",
      "\taction [-0.32724088 -0.38231903 -0.31021687 -0.40945768]\n",
      "\taction [-0.26282421 -0.33012807 -0.38667369 -0.30634609]\n",
      "episode 371 at 1000 ts; done reached\n",
      "\taction [-0.97660869 -0.93059582 -0.91572273 -0.92126781]\n",
      "\taction [-0.15830386 -0.26307634 -0.45024377 -0.46288842]\n",
      "\taction [-0.13259554 -0.41940439 -0.37265417 -0.46986079]\n",
      "\taction [-0.31122762 -0.30311596 -0.19668199 -0.40062386]\n",
      "episode 372 at 1000 ts; done reached\n",
      "\taction [-0.86309177 -0.89019829 -0.81085503 -0.88931465]\n",
      "\taction [-0.44622609 -0.38982186 -0.27130455 -0.25840265]\n",
      "\taction [-0.33874574 -0.45608929 -0.39415517 -0.34040129]\n",
      "\taction [-0.31540558 -0.23395622 -0.25851572 -0.22870067]\n",
      "episode 373 at 1000 ts; done reached\n",
      "\taction [-0.94511724 -0.99201715 -0.85129321 -0.81549215]\n",
      "\taction [-0.37402609 -0.54006451 -0.21500403 -0.44294456]\n",
      "\taction [-0.29333538 -0.41246894 -0.33934677 -0.0939815 ]\n",
      "\taction [-0.16114955 -0.22794847 -0.38676783 -0.1799359 ]\n",
      "episode 374 at 1000 ts; done reached\n",
      "\taction [-0.93078393 -0.90686291 -0.86834478 -0.87691891]\n",
      "\taction [-0.28615952 -0.40487242 -0.36309847 -0.39445838]\n",
      "\taction [-0.11227663 -0.19294162 -0.33524486 -0.50496221]\n",
      "\taction [-0.40899208 -0.29953331 -0.2797125  -0.20384714]\n",
      "episode 375 at 1000 ts; done reached\n",
      "\taction [-0.89243132 -0.89555585 -0.83378994 -0.85591942]\n",
      "\taction [-0.3730166  -0.44405964 -0.38526455 -0.28379944]\n",
      "\taction [-0.28118923 -0.19234045 -0.33873534 -0.43949857]\n",
      "\taction [-0.39966968 -0.46174186 -0.39053124 -0.31395701]\n",
      "episode 376 at 1000 ts; done reached\n",
      "\taction [-0.97069687 -0.80795234 -0.98058391 -0.98914778]\n",
      "\taction [-0.10075258 -0.31557485 -0.39006153 -0.26275635]\n",
      "\taction [-0.34101579 -0.51721448 -0.34479526 -0.17472593]\n",
      "\taction [-0.55851001 -0.47495103 -0.26290345 -0.34769744]\n",
      "episode 377 at 1000 ts; done reached\n",
      "\taction [-0.88117433 -0.82497144 -0.89079899 -0.82011026]\n",
      "\taction [-0.28780943 -0.51997721 -0.32010683 -0.32309309]\n",
      "\taction [-0.38952932 -0.27710649 -0.20523807 -0.37841251]\n",
      "\taction [-0.43575352 -0.46254638 -0.4016099  -0.33018115]\n",
      "episode 378 at 1000 ts; done reached\n",
      "\taction [-0.93015701 -0.97659731 -0.8433814  -0.94528753]\n",
      "\taction [-0.07827103 -0.32322845 -0.49836311 -0.23192428]\n",
      "\taction [-0.29707158 -0.5131976  -0.30596578 -0.35881525]\n",
      "\taction [-0.33688632 -0.39606544 -0.28826106 -0.29212472]\n",
      "episode 379 at 1000 ts; done reached\n",
      "\taction [-0.81915718 -0.88933128 -0.94566846 -0.89271271]\n",
      "\taction [-0.38184246 -0.29588664 -0.23222673 -0.32483763]\n",
      "\taction [-0.31204927 -0.39797646 -0.14887948 -0.3730509 ]\n",
      "\taction [-0.31504333 -0.42668706 -0.18850461 -0.18608306]\n",
      "episode 380 at 1000 ts; done reached\n",
      "\taction [-0.95632517 -0.8039571  -0.81488949 -0.80206996]\n",
      "\taction [-0.26407343 -0.29620531 -0.17837113 -0.4399797 ]\n",
      "\taction [-0.35708684 -0.39552546 -0.28746924 -0.29490846]\n",
      "\taction [-0.15019502 -0.22126    -0.18004668 -0.45882165]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 381 at 1000 ts; done reached\n",
      "\taction [-0.9687115  -0.99914467 -0.87557483 -0.82295716]\n",
      "\taction [-0.29979485 -0.51558912 -0.15206708 -0.34976923]\n",
      "\taction [-0.1432804  -0.24427888 -0.62224984 -0.20533514]\n",
      "\taction [-0.2286281  -0.33470732 -0.45035645 -0.11532483]\n",
      "episode 382 at 1000 ts; done reached\n",
      "\taction [-0.89781392 -0.90334398 -0.9800809  -0.89085108]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [-0.42867905 -0.38402086 -0.40701658 -0.24555105]\n",
      "\taction [-0.09565067 -0.38605031 -0.3661963  -0.29150304]\n",
      "\taction [-0.34364209 -0.37521085 -0.18810607 -0.18600559]\n",
      "episode 383 at 1000 ts; done reached\n",
      "\taction [-0.84328651 -0.86404073 -0.98512459 -0.96278358]\n",
      "\taction [-0.25741088 -0.3687222  -0.24065283 -0.3972581 ]\n",
      "\taction [-0.37318242 -0.41603553 -0.30360484 -0.38231131]\n",
      "\taction [-0.32915229 -0.36396563 -0.10443297 -0.30219996]\n",
      "episode 384 at 1000 ts; done reached\n",
      "\taction [-0.81485403 -0.8708446  -0.86117405 -0.95121646]\n",
      "\taction [-0.32958016 -0.35261503 -0.19328846 -0.36608586]\n",
      "\taction [-0.365495   -0.38186091 -0.22845073 -0.18990482]\n",
      "\taction [-0.46055833 -0.28704166 -0.57876217 -0.31782529]\n",
      "episode 385 at 1000 ts; done reached\n",
      "\taction [-0.9682923  -0.84319729 -0.95117241 -0.88038492]\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [-0.24911347 -0.35873488 -0.30198064 -0.21731938]\n",
      "\taction [-0.55998987 -0.33082932 -0.39244837 -0.39923137]\n",
      "\taction [-0.59844792 -0.40926197 -0.22193132 -0.40557399]\n",
      "episode 386 at 1000 ts; done reached\n",
      "\taction [-0.89654827 -0.81965685 -0.95014489 -0.82668614]\n",
      "\taction [-0.46584743 -0.22787817 -0.51743966 -0.34614113]\n",
      "\taction [-0.23366018 -0.27564973 -0.4149192  -0.40276593]\n",
      "\taction [-0.38863182 -0.53616923 -0.41221023 -0.50318193]\n",
      "episode 387 at 1000 ts; done reached\n",
      "\taction [-0.92728913 -0.88365275 -0.92275995 -0.85104913]\n",
      "\taction [-0.29876441 -0.51053828 -0.48995879 -0.29634309]\n",
      "\taction [-0.32827917 -0.23201102 -0.06106065 -0.26929581]\n",
      "\taction [-0.43948576 -0.47963589 -0.31668362 -0.34804735]\n",
      "episode 388 at 1000 ts; done reached\n",
      "\taction [-0.8710615  -0.89165032 -0.83472151 -0.90012425]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [-0.42743379 -0.41179925 -0.43507981 -0.26046634]\n",
      "\taction [-0.20912276 -0.22647886 -0.40959638 -0.39166489]\n",
      "\taction [-0.39923364 -0.3059777  -0.3903988  -0.31898078]\n",
      "episode 389 at 1000 ts; done reached\n",
      "\taction [-0.97630608 -0.81236237 -0.92123723 -0.80626875]\n",
      "\taction [-0.36742839 -0.24787775 -0.3063525  -0.19758329]\n",
      "\taction [-0.38990727 -0.33605802 -0.48389754 -0.33845431]\n",
      "\taction [-0.18997711 -0.27897593 -0.4029133  -0.41429102]\n",
      "episode 390 at 1000 ts; done reached\n",
      "\taction [-0.86759233 -0.86212862 -0.96367848 -0.91034704]\n",
      "\taction [-0.52976525 -0.28419256 -0.43798295 -0.43109095]\n",
      "\taction [-0.43467408 -0.27942568 -0.31214964 -0.28962663]\n",
      "\taction [-0.5568279  -0.32368544 -0.56515694 -0.25667363]\n",
      "episode 391 at 1000 ts; done reached\n",
      "\taction [-0.91524035 -0.86660433 -0.84270972 -0.80278343]\n",
      "\taction [-0.41397813 -0.30701077 -0.41790497 -0.48444995]\n",
      "\taction [-0.43605766 -0.26969707 -0.66348529 -0.52061361]\n",
      "\taction [-0.20386665 -0.33681902 -0.40521899 -0.40679663]\n",
      "episode 392 at 1000 ts; done reached\n",
      "\taction [-0.81070912 -0.96835995 -0.85041898 -0.95027357]\n",
      "\taction [-0.30967924 -0.23312251 -0.26597518 -0.18093598]\n",
      "\taction [-0.5878613  -0.34192112 -0.24279116 -0.29511097]\n",
      "\taction [-0.09888957 -0.26347226 -0.18265297 -0.32589811]\n",
      "episode 393 at 1000 ts; done reached\n",
      "\taction [-0.8738308  -0.85491186 -0.87831962 -0.83589852]\n",
      "\taction [-0.39794934 -0.30254143 -0.25653529 -0.20200044]\n",
      "\taction [-0.25642151 -0.46811977 -0.41686618 -0.1714572 ]\n",
      "\taction [-0.30805391 -0.31726262 -0.42982954 -0.40555716]\n",
      "episode 394 at 1000 ts; done reached\n",
      "\taction [-0.80801988 -0.95346487 -0.93591535 -0.8542366 ]\n",
      "\taction [-0.34184667 -0.38788584 -0.3023631  -0.29928246]\n",
      "\taction [-0.32740733 -0.43361259 -0.38214776 -0.44615674]\n",
      "\taction [-0.47156191 -0.13991888 -0.20400669 -0.20468876]\n",
      "episode 395 at 1000 ts; done reached\n",
      "\taction [-0.98084629 -0.99169666 -0.88297296 -0.97461993]\n",
      "\taction [-0.29232711 -0.54389071 -0.33443323 -0.37129173]\n",
      "\taction [-0.22261071 -0.4594686  -0.51017088 -0.34943485]\n",
      "\taction [-0.24428356 -0.45134202 -0.32946283 -0.30935526]\n",
      "episode 396 at 1000 ts; done reached\n",
      "\taction [-0.80136794 -0.95063299 -0.94170845 -0.88269973]\n",
      "\taction [-0.38915268 -0.38749906 -0.31643796 -0.41407314]\n",
      "\taction [-0.22681306 -0.25067058 -0.21504237 -0.30430827]\n",
      "\taction [-0.38596562 -0.31954151 -0.3245849  -0.41038293]\n",
      "episode 397 at 1000 ts; done reached\n",
      "\taction [-0.8020243  -0.94879872 -0.93390882 -0.82501286]\n",
      "\taction [-0.53343058 -0.22422832 -0.26508048 -0.21381694]\n",
      "\taction [-0.36256954 -0.39668787 -0.08539099 -0.4390724 ]\n",
      "\taction [-0.30045131 -0.42264429 -0.28924128 -0.00772396]\n",
      "episode 398 at 1000 ts; done reached\n",
      "\taction [-0.8758077  -0.95851696 -0.93245852 -0.86061126]\n",
      "\taction [-0.31464782 -0.36527407 -0.38205716 -0.27296254]\n",
      "\taction [-0.41704386 -0.19732502 -0.27492645 -0.49317127]\n",
      "\taction [-0.46812376 -0.30055648 -0.44254965 -0.21590818]\n",
      "episode 399 at 1000 ts; done reached\n",
      "\taction [-0.98701805 -0.95347309 -0.91196036 -0.83148938]\n",
      "\taction [-0.62349606 -0.27976549 -0.26946828 -0.3593246 ]\n",
      "\taction [-0.26243058 -0.26256895 -0.32891691 -0.18573058]\n",
      "\taction [-0.02903487 -0.46290874 -0.06266394 -0.33639759]\n",
      "episode 400 at 1000 ts; done reached\n",
      "\taction [-0.98714185 -0.96744913 -0.88562697 -0.81348526]\n",
      "\taction [-0.18149021 -0.2942147  -0.29705355 -0.27414915]\n",
      "\taction [-0.22620922 -0.34525865 -0.25430587 -0.34632868]\n",
      "\taction [-0.27016389 -0.41767642 -0.45559794 -0.3079685 ]\n",
      "episode 401 at 1000 ts; done reached\n",
      "\taction [-0.83580327 -0.88149607 -0.85308832 -0.84206539]\n",
      "\taction [-0.18070579 -0.22458188 -0.3997308  -0.15874913]\n",
      "\taction [-0.26887062 -0.38628474 -0.31131271 -0.29446697]\n",
      "\taction [-0.27488068 -0.4705005  -0.36954537 -0.46342239]\n",
      "episode 402 at 1000 ts; done reached\n",
      "\taction [-0.86877036 -0.93169987 -0.8681013  -0.96301842]\n",
      "\taction [-0.48591959 -0.19237116 -0.36053392 -0.37270361]\n",
      "\taction [-0.29965544 -0.32339483 -0.37608302 -0.38284311]\n",
      "\taction [ -4.82459158e-01  -3.87671709e-01  -3.12969774e-01  -1.38142248e-04]\n",
      "episode 403 at 1000 ts; done reached\n",
      "\taction [-0.96529138 -0.84153205 -0.87096852 -0.84989828]\n",
      "\taction [-0.55151302 -0.58206344 -0.33066347 -0.40758064]\n",
      "\taction [-0.27411178 -0.42854345 -0.18763021 -0.38011184]\n",
      "\taction [-0.23921582 -0.34641311 -0.3072674  -0.25248215]\n",
      "episode 404 at 1000 ts; done reached\n",
      "\taction [-0.95207381 -0.95732743 -0.9547292  -0.9766795 ]\n",
      "\taction [-0.31210211 -0.33005765 -0.38276511 -0.29841512]\n",
      "\taction [-0.22284552 -0.40750071 -0.31915611 -0.24252473]\n",
      "\taction [-0.44890672 -0.45102388 -0.31104591 -0.45650989]\n",
      "episode 405 at 1000 ts; done reached\n",
      "\taction [-0.80246651 -0.92378706 -0.90992194 -0.87282586]\n",
      "reward 0.029999999329447746\n",
      "reward 0.029999999329447746\n",
      "\taction [-0.46402961 -0.41176379 -0.35476848 -0.40578845]\n",
      "\taction [-0.17694731 -0.37077847 -0.35229889 -0.26491567]\n",
      "\taction [-0.32902467 -0.4756411  -0.43720523 -0.27436918]\n",
      "episode 406 at 1000 ts; done reached\n",
      "\taction [-0.83411384 -0.92045468 -0.8887707  -0.81626654]\n",
      "\taction [-0.2071043  -0.12974478 -0.33264825 -0.42811117]\n",
      "\taction [-0.27085647 -0.42819497 -0.62560326 -0.34802291]\n",
      "\taction [-0.24378601 -0.52667773 -0.46587679 -0.26294538]\n",
      "episode 407 at 1000 ts; done reached\n",
      "\taction [-0.80108589 -0.8320033  -0.80063027 -0.94081205]\n",
      "\taction [-0.36331367 -0.3633191  -0.22199123 -0.46705532]\n",
      "\taction [-0.20688818 -0.32251438 -0.19622262 -0.52979648]\n",
      "\taction [-0.27261314 -0.54557168 -0.35161015 -0.36061618]\n",
      "episode 408 at 1000 ts; done reached\n",
      "\taction [-0.96909595 -0.81468362 -0.81677377 -0.81413746]\n",
      "\taction [-0.17119899 -0.19852869 -0.21251851 -0.32017615]\n",
      "\taction [-0.21884091 -0.2144555  -0.24465016 -0.41762593]\n",
      "\taction [-0.40226501 -0.43688688 -0.48622006 -0.29370981]\n",
      "episode 409 at 1000 ts; done reached\n",
      "\taction [-0.80787528 -0.89570415 -0.83089912 -0.97677398]\n",
      "\taction [-0.29610419 -0.33327374 -0.29027703 -0.39016816]\n",
      "\taction [-0.34037313 -0.38641936 -0.32986251 -0.3472662 ]\n",
      "\taction [-0.39678815 -0.55527127 -0.20823418 -0.26508012]\n",
      "episode 410 at 1000 ts; done reached\n",
      "\taction [-0.83522832 -0.80697232 -0.88312328 -0.93094939]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\taction [-0.35123202 -0.31145409 -0.28016135 -0.25476778]\n",
      "\taction [-0.35174072 -0.21899419 -0.37015709 -0.44360751]\n",
      "\taction [-0.24615251 -0.44775888 -0.21269938 -0.4277932 ]\n",
      "episode 411 at 1000 ts; done reached\n",
      "\taction [-0.83692235 -0.93559462 -0.85710663 -0.99419141]\n",
      "\taction [-0.24425717 -0.46742439 -0.36292875 -0.31530395]\n",
      "\taction [-0.22869456 -0.47237703 -0.35118553 -0.55549848]\n",
      "\taction [-0.30749279 -0.40940553 -0.33311009 -0.29063159]\n",
      "episode 412 at 1000 ts; done reached\n",
      "\taction [-0.83270735 -0.92007732 -0.82532328 -0.8600812 ]\n",
      "\taction [-0.34464768 -0.38405904 -0.50456458 -0.19140269]\n",
      "\taction [-0.32369587 -0.1838838  -0.37566212 -0.1691525 ]\n",
      "\taction [-0.45453435 -0.27936289 -0.49325675 -0.43037292]\n",
      "episode 413 at 1000 ts; done reached\n",
      "\taction [-0.83453494 -0.95050514 -0.83569235 -0.82024544]\n",
      "\taction [-0.37249598 -0.31100231 -0.34630865 -0.48046511]\n",
      "\taction [-0.36249244 -0.33094171 -0.35412785 -0.4004561 ]\n",
      "\taction [-0.38764688 -0.44459724 -0.29172838 -0.46845689]\n",
      "episode 414 at 1000 ts; done reached\n",
      "\taction [-0.96753711 -0.98316729 -0.89460236 -0.9595871 ]\n",
      "\taction [-0.46593061 -0.5510534  -0.15632476 -0.35477975]\n",
      "\taction [-0.21502493 -0.09271589 -0.13665038 -0.47847518]\n",
      "\taction [-0.11967415 -0.42853197 -0.47853976 -0.3242467 ]\n",
      "episode 415 at 1000 ts; done reached\n",
      "\taction [-0.96136755 -0.80371469 -0.92846888 -0.89717472]\n",
      "\taction [-0.2940779  -0.20199227 -0.36946976 -0.14947478]\n",
      "\taction [-0.39051828 -0.33631274 -0.49895114 -0.24550484]\n",
      "\taction [-0.50384438 -0.39628202 -0.53467792 -0.27065873]\n",
      "episode 416 at 1000 ts; done reached\n",
      "\taction [-0.84632868 -0.92795807 -0.84987038 -0.92260468]\n",
      "\taction [-0.22867584 -0.40182161 -0.58501416 -0.30083761]\n",
      "\taction [-0.42734489 -0.35663277 -0.42571464 -0.23080796]\n",
      "\taction [-0.32050112 -0.1644654  -0.39406368 -0.46536374]\n",
      "episode 417 at 1000 ts; done reached\n",
      "\taction [-0.83703274 -0.82371682 -0.99060386 -0.95994163]\n",
      "\taction [-0.41418558 -0.42886794 -0.0146033  -0.48750871]\n",
      "\taction [-0.0549545  -0.32410428 -0.30988812 -0.26201469]\n",
      "\taction [-0.46766019 -0.16698207 -0.35030809 -0.18305075]\n",
      "episode 418 at 1000 ts; done reached\n",
      "\taction [-0.94837981 -0.83928651 -0.81586033 -0.99870414]\n",
      "\taction [-0.39422178 -0.31012657 -0.15686814 -0.45608309]\n",
      "\taction [-0.12550452 -0.17657031 -0.42781731 -0.45338985]\n",
      "\taction [-0.31591713 -0.11011414 -0.24100463 -0.43447068]\n",
      "episode 419 at 1000 ts; done reached\n",
      "\taction [-0.80730563 -0.93215334 -0.95252013 -0.90161228]\n",
      "\taction [-0.28214046 -0.38115776 -0.3512013  -0.31038657]\n",
      "\taction [-0.43736345 -0.36283356 -0.40188321 -0.29299021]\n",
      "\taction [-0.21188818 -0.3993777  -0.27456546 -0.42273346]\n",
      "episode 420 at 1000 ts; done reached\n",
      "\taction [-0.99064392 -0.9208051  -0.90154678 -0.9366461 ]\n",
      "\taction [-0.29007378 -0.45886129 -0.30554587 -0.30461475]\n",
      "\taction [-0.38426083 -0.35277551 -0.4240602  -0.28584337]\n",
      "\taction [-0.50015122 -0.3063038  -0.21771574 -0.43866819]\n",
      "episode 421 at 1000 ts; done reached\n",
      "\taction [-0.91586357 -0.93373007 -0.89562285 -0.89337575]\n",
      "\taction [-0.31292275 -0.36782235 -0.42039824 -0.194005  ]\n",
      "\taction [-0.24935846 -0.42403832 -0.52227765 -0.20325945]\n",
      "\taction [-0.27797106 -0.4751662  -0.62230158 -0.11265739]\n",
      "episode 422 at 1000 ts; done reached\n",
      "\taction [-0.80008554 -0.82671088 -0.96521121 -0.8827998 ]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.019999999552965164\n",
      "\taction [-0.37578979 -0.35878369 -0.38545787 -0.33773312]\n",
      "\taction [-0.20055249 -0.32540238 -0.33340082 -0.45441896]\n",
      "\taction [-0.54500419 -0.27674294 -0.30523264 -0.51972961]\n",
      "episode 423 at 1000 ts; done reached\n",
      "\taction [-0.92532164 -0.94470632 -0.95315254 -0.85486931]\n",
      "\taction [-0.50134337 -0.36891648 -0.20169739 -0.38869753]\n",
      "\taction [-0.53649163 -0.46823412 -0.43259969 -0.45025837]\n",
      "\taction [-0.34935439 -0.35069296 -0.3896167  -0.32326308]\n",
      "episode 424 at 1000 ts; done reached\n",
      "\taction [-0.80268472 -0.80810851 -0.95158565 -0.92890584]\n",
      "\taction [-0.48573804 -0.40067926 -0.16305055 -0.26890886]\n",
      "\taction [-0.32479963 -0.31963447 -0.34080917 -0.23021892]\n",
      "\taction [-0.17783143 -0.3639321  -0.33689424 -0.48716149]\n",
      "episode 425 at 1000 ts; done reached\n",
      "\taction [-0.8048858  -0.80663443 -0.90127933 -0.83765501]\n",
      "\taction [-0.45843947 -0.42090324 -0.46856761 -0.36611947]\n",
      "\taction [-0.43077922 -0.4004868  -0.3858467  -0.34633911]\n",
      "\taction [-0.32203525 -0.40663156 -0.17671296 -0.38872108]\n",
      "episode 426 at 1000 ts; done reached\n",
      "\taction [-0.94310403 -0.87824011 -0.81003004 -0.86867213]\n",
      "\taction [-0.37802985 -0.41552615 -0.33474219 -0.44876471]\n",
      "\taction [-0.44264913 -0.33720243 -0.24927005 -0.50704896]\n",
      "\taction [-0.37790421 -0.28831804 -0.47051039 -0.10672138]\n",
      "episode 427 at 1000 ts; done reached\n",
      "\taction [-0.93933016 -0.89299214 -0.90133673 -0.92770934]\n",
      "\taction [-0.3953495  -0.32957849 -0.38656032 -0.31986406]\n",
      "\taction [-0.47671604 -0.2598004  -0.24479339 -0.22499233]\n",
      "\taction [-0.29717344 -0.20881028 -0.3767024  -0.26623636]\n",
      "episode 428 at 1000 ts; done reached\n",
      "\taction [-0.81193781 -0.92906857 -0.93870425 -0.94559991]\n",
      "\taction [-0.32438666 -0.34610787 -0.23270477 -0.40606257]\n",
      "\taction [-0.22583245 -0.41463748 -0.1287718  -0.3029938 ]\n",
      "\taction [-0.33860582 -0.33347216 -0.31205761 -0.30509594]\n",
      "episode 429 at 1000 ts; done reached\n",
      "\taction [-0.83821535 -0.92286432 -0.86679846 -0.99225825]\n",
      "\taction [-0.43240526 -0.00327253 -0.17877871 -0.30478707]\n",
      "\taction [-0.38693655 -0.43935829 -0.39562219 -0.47486255]\n",
      "\taction [-0.24970701 -0.29728416 -0.23905002 -0.07694175]\n",
      "episode 430 at 1000 ts; done reached\n",
      "\taction [-0.8017689  -0.97583312 -0.92538011 -0.92415142]\n",
      "\taction [-0.39244634 -0.27918172 -0.2135891  -0.3681719 ]\n",
      "\taction [-0.33658984 -0.41473034 -0.54643583 -0.25663009]\n",
      "\taction [-0.33452621 -0.18970136 -0.35762918 -0.29598579]\n",
      "episode 431 at 1000 ts; done reached\n",
      "\taction [-0.89406288 -0.98197901 -0.86011022 -0.92536002]\n",
      "\taction [-0.32528469 -0.39932805 -0.46278116 -0.46153563]\n",
      "\taction [-0.57727003 -0.42241001 -0.35190198 -0.27071327]\n",
      "\taction [-0.4559688  -0.39646435 -0.43020928 -0.35313475]\n",
      "episode 432 at 1000 ts; done reached\n",
      "\taction [-0.95722896 -0.92120928 -0.93825227 -0.91959673]\n",
      "\taction [-0.30999547 -0.44812474 -0.54855955 -0.34243092]\n",
      "\taction [-0.28051287 -0.17424308 -0.29223821 -0.51612365]\n",
      "\taction [-0.13918255 -0.52683628 -0.16749251 -0.14977217]\n",
      "episode 433 at 1000 ts; done reached\n",
      "\taction [-0.83539951 -0.80820191 -0.94168925 -0.80310369]\n",
      "\taction [-0.41000271 -0.35630298 -0.40106905 -0.47950792]\n",
      "\taction [-0.23028083 -0.44011971 -0.31619257 -0.34939498]\n",
      "\taction [-0.27126619 -0.46539676 -0.08768172 -0.48478746]\n",
      "episode 434 at 1000 ts; done reached\n",
      "\taction [-0.87830096 -0.89955908 -0.89714408 -0.9743349 ]\n",
      "\taction [-0.56022191 -0.30558592 -0.48759201 -0.27534279]\n",
      "\taction [-0.19456562 -0.1186752  -0.21781057 -0.34574965]\n",
      "\taction [-0.24351919 -0.36292857 -0.17374501 -0.24845821]\n",
      "episode 435 at 1000 ts; done reached\n",
      "\taction [-0.99275041 -0.86265326 -0.89603519 -0.85573101]\n",
      "\taction [-0.21175735 -0.2257075  -0.17847598 -0.3666445 ]\n",
      "\taction [-0.21954115 -0.09909953 -0.15160187 -0.45493236]\n",
      "\taction [-0.44735876 -0.45081785 -0.23580419 -0.50538373]\n",
      "episode 436 at 1000 ts; done reached\n",
      "\taction [-0.83695453 -0.92018396 -0.96142906 -0.9891448 ]\n",
      "\taction [-0.47345501 -0.37756729 -0.58877981 -0.37759253]\n",
      "\taction [-0.39801568 -0.27351141 -0.51735914 -0.40477756]\n",
      "\taction [-0.53818572 -0.40272805 -0.3457554  -0.48589164]\n",
      "episode 437 at 1000 ts; done reached\n",
      "\taction [-0.81473565 -0.80318737 -0.9013831  -0.89259052]\n",
      "\taction [-0.28375039 -0.36260858 -0.42052439 -0.46301478]\n",
      "\taction [-0.31658441 -0.26435184 -0.37192148 -0.2381929 ]\n",
      "\taction [-0.23019631 -0.37459549 -0.25580737 -0.52641773]\n",
      "episode 438 at 1000 ts; done reached\n",
      "\taction [-0.90960085 -0.93252313 -0.99384683 -0.8692497 ]\n",
      "\taction [-0.16031078 -0.39300162 -0.55377245 -0.50516081]\n",
      "\taction [-0.51013464 -0.37378198 -0.39986205 -0.28369573]\n",
      "\taction [-0.30612224 -0.37591937 -0.31623116 -0.18665379]\n",
      "episode 439 at 1000 ts; done reached\n",
      "\taction [-0.94839281 -0.84137332 -0.97685957 -0.80364978]\n",
      "\taction [-0.50524247 -0.41940776 -0.33614388 -0.41212231]\n",
      "\taction [-0.39043909 -0.37086424 -0.38221943 -0.2236878 ]\n",
      "\taction [-0.26746917 -0.15530691 -0.4162401  -0.50923443]\n",
      "episode 440 at 1000 ts; done reached\n",
      "\taction [-0.97889829 -0.90679598 -0.9799965  -0.86864793]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\taction [-0.4743802  -0.40165809 -0.52820849 -0.21044634]\n",
      "\taction [-0.36917007 -0.48416725 -0.44456792 -0.41249949]\n",
      "\taction [-0.25341824 -0.40849131 -0.26754633 -0.26654729]\n",
      "episode 441 at 1000 ts; done reached\n",
      "\taction [-0.9182815  -0.92379731 -0.92133617 -0.97510415]\n",
      "\taction [-0.26246476 -0.34899554 -0.44643086 -0.21967854]\n",
      "\taction [-0.45993704 -0.42264155 -0.42356193 -0.27258691]\n",
      "\taction [-0.38035405 -0.5403868  -0.3457059  -0.11785747]\n",
      "episode 442 at 1000 ts; done reached\n",
      "\taction [-0.99286598 -0.80602694 -0.85650891 -0.80854017]\n",
      "\taction [-0.26521686 -0.46881774 -0.27135178 -0.256311  ]\n",
      "\taction [-0.32693112 -0.30079055 -0.50049067 -0.26127341]\n",
      "\taction [-0.12736255 -0.28243974 -0.23276262 -0.32228649]\n",
      "episode 443 at 1000 ts; done reached\n",
      "\taction [-0.97755837 -0.98341227 -0.90113711 -0.97171563]\n",
      "reward 0.019999999552965164\n",
      "\taction [-0.18843983 -0.19679862 -0.21873873 -0.65100956]\n",
      "\taction [-0.19927147 -0.35191786 -0.43705535 -0.40784648]\n",
      "\taction [-0.36888587 -0.34199384 -0.20831677 -0.3011466 ]\n",
      "episode 444 at 1000 ts; done reached\n",
      "\taction [-0.89274591 -0.84335202 -0.98447031 -0.96538216]\n",
      "\taction [-0.18431677 -0.21014512 -0.10824351 -0.3765012 ]\n",
      "\taction [-0.18618855 -0.23121125 -0.47325552 -0.20732787]\n",
      "\taction [-0.52485323 -0.38132402 -0.27118966 -0.39960206]\n",
      "episode 445 at 1000 ts; done reached\n",
      "\taction [-0.90421075 -0.93319118 -0.99946636 -0.92446339]\n",
      "\taction [-0.34988752 -0.18747574 -0.32609469 -0.34940061]\n",
      "\taction [-0.29873896 -0.35391033 -0.36189219 -0.28799224]\n",
      "\taction [-0.18696193 -0.34206203 -0.41545644 -0.35179064]\n",
      "episode 446 at 1000 ts; done reached\n",
      "\taction [-0.94336981 -0.86351848 -0.98404372 -0.99924099]\n",
      "reward 0.019999999552965164\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.029999999329447746\n",
      "\taction [-0.30704048 -0.30296591 -0.51881713 -0.14136714]\n",
      "\taction [-0.21164477 -0.11927643 -0.31611207 -0.32933849]\n",
      "\taction [-0.20331423 -0.4199912  -0.35508615 -0.39806604]\n",
      "episode 447 at 1000 ts; done reached\n",
      "\taction [-0.96848488 -0.9504016  -0.93920845 -0.88799733]\n",
      "\taction [-0.32214552 -0.46435058 -0.40857938 -0.2463989 ]\n",
      "\taction [-0.35118288 -0.3751415  -0.49226275 -0.0803317 ]\n",
      "\taction [-0.26565862 -0.37223169 -0.34129167 -0.13977422]\n",
      "episode 448 at 1000 ts; done reached\n",
      "\taction [-0.82738036 -0.93226266 -0.89504254 -0.9186371 ]\n",
      "\taction [-0.34652081 -0.27830783 -0.37895077 -0.2601026 ]\n",
      "\taction [-0.31386858 -0.26822931 -0.26232535 -0.39902154]\n",
      "\taction [-0.49635255 -0.20320411 -0.41970509 -0.37581202]\n",
      "episode 449 at 1000 ts; done reached\n",
      "\taction [-0.99559313 -0.83230889 -0.85183948 -0.865762  ]\n",
      "\taction [-0.24394688 -0.31762618 -0.37211451 -0.17626618]\n",
      "\taction [-0.39699998 -0.30046925 -0.52667898 -0.34933811]\n",
      "\taction [-0.2499637  -0.45468989 -0.27367732 -0.40211117]\n",
      "episode 450 at 1000 ts; done reached\n",
      "\taction [-0.86278158 -0.828816   -0.92449129 -0.9296931 ]\n",
      "\taction [-0.40413088 -0.42442042 -0.33878398 -0.39281464]\n",
      "\taction [-0.35861313 -0.3875885  -0.29140717 -0.31176275]\n",
      "\taction [-0.32752591 -0.25288776 -0.29147154 -0.31858569]\n",
      "episode 451 at 1000 ts; done reached\n",
      "\taction [-0.80088151 -0.99471933 -0.95551699 -0.93933749]\n",
      "\taction [-0.42530763 -0.41931349 -0.1734097  -0.27735215]\n",
      "\taction [-0.37287888 -0.30536819 -0.43551022 -0.49680501]\n",
      "\taction [-0.47464418 -0.25113991 -0.21995339 -0.17991784]\n",
      "episode 452 at 1000 ts; done reached\n",
      "\taction [-0.97382957 -0.92128587 -0.81359386 -0.88806611]\n",
      "\taction [-0.244315   -0.49926844 -0.47798911 -0.27919608]\n",
      "\taction [-0.36905026 -0.2122936  -0.14646859 -0.09607548]\n",
      "\taction [-0.5211342  -0.43312278 -0.53179502 -0.437197  ]\n",
      "episode 453 at 1000 ts; done reached\n",
      "\taction [-0.85470164 -0.80597007 -0.86751103 -0.92593437]\n",
      "\taction [-0.28781739 -0.29938084 -0.28250289 -0.51888394]\n",
      "\taction [-0.41600487 -0.39335793 -0.29326707 -0.26087147]\n",
      "\taction [-0.25952062 -0.40547791 -0.09002436 -0.36154833]\n",
      "episode 454 at 1000 ts; done reached\n",
      "\taction [-0.98298162 -0.82712013 -0.99541003 -0.9261719 ]\n",
      "\taction [-0.42937672 -0.48843381 -0.19243349 -0.42559019]\n",
      "\taction [-0.26042336 -0.32992455 -0.29508248 -0.39021814]\n",
      "\taction [-0.44409463 -0.60161537 -0.24027605 -0.32049704]\n",
      "episode 455 at 1000 ts; done reached\n",
      "\taction [-0.94832164 -0.99473691 -0.98933923 -0.89054394]\n",
      "\taction [-0.41712123 -0.17829332 -0.2930105  -0.56349474]\n",
      "\taction [-0.31440279 -0.28217411 -0.29599082 -0.39485824]\n",
      "\taction [-0.47733906 -0.38092998 -0.22543643 -0.31262231]\n",
      "episode 456 at 1000 ts; done reached\n",
      "\taction [-0.97003168 -0.93838334 -0.86134344 -0.99211562]\n",
      "\taction [-0.34131128 -0.38359049 -0.22973433 -0.32674095]\n",
      "\taction [-0.32199886 -0.47128525 -0.31480956 -0.5146873 ]\n",
      "\taction [-0.30267608 -0.47554931 -0.09616738 -0.212597  ]\n",
      "episode 457 at 1000 ts; done reached\n",
      "\taction [-0.99585181 -0.85977387 -0.93259758 -0.94923168]\n",
      "\taction [-0.17171505 -0.33612826 -0.39350015 -0.39077801]\n",
      "\taction [-0.32831293 -0.31991217 -0.35000223 -0.30556762]\n",
      "\taction [-0.57371932 -0.37268186 -0.31354445 -0.23697641]\n",
      "episode 458 at 1000 ts; done reached\n",
      "\taction [-0.95983422 -0.86112463 -0.84280288 -0.9677037 ]\n",
      "\taction [-0.37789035 -0.40506327 -0.14666751 -0.39047924]\n",
      "\taction [-0.43187627 -0.27273235 -0.25768125 -0.27541241]\n",
      "\taction [-0.39674556 -0.41553321 -0.46017891 -0.29639161]\n",
      "episode 459 at 1000 ts; done reached\n",
      "\taction [-0.888493   -0.89577103 -0.84974664 -0.80461317]\n",
      "\taction [-0.42221811 -0.299523   -0.50209367 -0.50769305]\n",
      "\taction [-0.35503566 -0.1380423  -0.16672288 -0.27370712]\n",
      "\taction [-0.42484328 -0.2421805  -0.35502401 -0.44290024]\n",
      "episode 460 at 1000 ts; done reached\n",
      "\taction [-0.83536106 -0.84058994 -0.97886729 -0.85341692]\n",
      "\taction [-0.46818051 -0.46643734 -0.18137449 -0.49891812]\n",
      "\taction [-0.53517902 -0.45545566 -0.47221816 -0.23444051]\n",
      "\taction [-0.20412806 -0.29238108 -0.29494888 -0.42035255]\n",
      "episode 461 at 1000 ts; done reached\n",
      "\taction [-0.99278235 -0.88455039 -0.88997078 -0.87419242]\n",
      "\taction [-0.41879851 -0.22330615 -0.22382087 -0.52533036]\n",
      "\taction [-0.36113939 -0.60851502 -0.31800598 -0.31859758]\n",
      "\taction [-0.38761601 -0.49106938 -0.29668918 -0.53604853]\n",
      "episode 462 at 1000 ts; done reached\n",
      "\taction [-0.83246469 -0.99711382 -0.96349412 -0.9952442 ]\n",
      "\taction [-0.17736444 -0.34379438 -0.46522832 -0.33581105]\n",
      "\taction [-0.32044864 -0.36985937 -0.20810463 -0.32236898]\n",
      "\taction [-0.43384805 -0.29781038 -0.38619304 -0.22798789]\n",
      "episode 463 at 1000 ts; done reached\n",
      "\taction [-0.88962454 -0.98200262 -0.82720768 -0.81711918]\n",
      "reward 0.009999999776482582\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "reward 0.03999999910593033\n",
      "\taction [-0.34211725 -0.37290797 -0.27426192 -0.21161912]\n",
      "\taction [-0.38599944 -0.32189852 -0.50933111 -0.21904591]\n",
      "\taction [-0.42757165 -0.29892817 -0.28802511 -0.27733257]\n",
      "episode 464 at 1000 ts; done reached\n",
      "\taction [-0.90221483 -0.94658351 -0.93925804 -0.94631696]\n",
      "\taction [-0.48832142 -0.40423301 -0.23084387 -0.41914368]\n",
      "\taction [-0.36845937 -0.20885286 -0.21967633 -0.27339333]\n",
      "\taction [-0.56825686 -0.2205832  -0.32117197 -0.26222768]\n",
      "episode 465 at 1000 ts; done reached\n",
      "\taction [-0.96469265 -0.87121207 -0.92996573 -0.85110581]\n",
      "\taction [-0.36774656 -0.39586532 -0.245654   -0.35733104]\n",
      "\taction [-0.13942662 -0.34990045 -0.38788503 -0.34967536]\n",
      "\taction [-0.26805732 -0.36273688 -0.33864963 -0.47636899]\n",
      "episode 466 at 1000 ts; done reached\n",
      "\taction [-0.99148834 -0.8314687  -0.95847279 -0.93863672]\n",
      "\taction [-0.43803471 -0.17466573 -0.29448128 -0.22376376]\n",
      "\taction [-0.28229165 -0.19802029 -0.31143236 -0.27452901]\n",
      "\taction [-0.20495482 -0.21431366 -0.24439944 -0.38371104]\n",
      "episode 467 at 1000 ts; done reached\n",
      "\taction [-0.89100266 -0.8183614  -0.96333688 -0.96578771]\n",
      "\taction [-0.43384409 -0.09973492 -0.53456074 -0.37944838]\n",
      "\taction [-0.41466299 -0.37731275 -0.24048544 -0.2241924 ]\n",
      "\taction [-0.35693574 -0.25285247 -0.3258546  -0.36287418]\n",
      "episode 468 at 1000 ts; done reached\n",
      "\taction [-0.88763481 -0.82258379 -0.96667594 -0.98283106]\n",
      "\taction [-0.38304001 -0.370949   -0.247732   -0.06385982]\n",
      "\taction [-0.37618962 -0.19965075 -0.22646375 -0.22857013]\n",
      "\taction [-0.30611587 -0.27648935 -0.40010035 -0.24701798]\n",
      "episode 469 at 1000 ts; done reached\n",
      "\taction [-0.87382025 -0.89113539 -0.97014803 -0.81993431]\n",
      "\taction [-0.29942521 -0.36029163 -0.32068217 -0.26499319]\n",
      "\taction [-0.37420186 -0.14311787 -0.32911575 -0.3009229 ]\n",
      "\taction [-0.22610879 -0.41966459 -0.50278765 -0.23156215]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 470 at 1000 ts; done reached\n",
      "\taction [-0.93488896 -0.86042517 -0.90674883 -0.97617292]\n",
      "\taction [-0.33835199 -0.44310123 -0.38206863 -0.33729687]\n",
      "\taction [-0.35185024 -0.17215779 -0.40963846 -0.22970106]\n",
      "\taction [-0.20026205 -0.40475065 -0.17661545 -0.46061411]\n",
      "episode 471 at 1000 ts; done reached\n",
      "\taction [-0.80252427 -0.91123235 -0.86001706 -0.81108516]\n",
      "\taction [-0.21338418 -0.11657191 -0.29331738 -0.27391687]\n",
      "\taction [-0.37267408 -0.31250224 -0.29211286 -0.25009814]\n",
      "\taction [-0.25192931 -0.29180673 -0.38946429 -0.41254568]\n",
      "episode 472 at 1000 ts; done reached\n",
      "\taction [-0.98389232 -0.90821314 -0.81761944 -0.88603455]\n",
      "\taction [-0.40291488 -0.26875791 -0.37522087 -0.33912852]\n",
      "\taction [-0.20235571 -0.25645214 -0.30313358 -0.43456131]\n",
      "\taction [-0.3781032  -0.07332039 -0.27465355 -0.2523801 ]\n",
      "episode 473 at 1000 ts; done reached\n",
      "\taction [-0.87133098 -0.83884507 -0.90728033 -0.92764664]\n",
      "\taction [-0.36172473 -0.18828732 -0.43835202 -0.34895298]\n",
      "\taction [-0.31305742 -0.36580241 -0.32315293 -0.32170868]\n",
      "\taction [-0.38202196 -0.3011736  -0.23476067 -0.4515585 ]\n",
      "episode 474 at 1000 ts; done reached\n",
      "\taction [-0.96392924 -0.81874961 -0.85665739 -0.82282251]\n",
      "\taction [-0.22478303 -0.40435687 -0.13175566 -0.20423795]\n",
      "\taction [-0.31362212 -0.49582645 -0.1825698  -0.53688002]\n",
      "\taction [-0.30632073 -0.35548073 -0.39222291 -0.20526306]\n",
      "episode 475 at 1000 ts; done reached\n",
      "\taction [-0.8681345  -0.80735242 -0.97492445 -0.99289125]\n",
      "\taction [-0.397517   -0.33178195 -0.60477835 -0.2634494 ]\n",
      "\taction [-0.35079879 -0.30712444 -0.29576081 -0.37626061]\n",
      "\taction [-0.33672452 -0.34569874 -0.38808683 -0.17238785]\n",
      "episode 476 at 1000 ts; done reached\n",
      "\taction [-0.9144904  -0.87977368 -0.99177963 -0.92304444]\n",
      "\taction [-0.44779748 -0.51091874 -0.31128368 -0.2639176 ]\n",
      "\taction [-0.45748466 -0.39870057 -0.31282294 -0.2425077 ]\n",
      "\taction [-0.25383255 -0.39736938 -0.42579383 -0.48749614]\n",
      "episode 477 at 1000 ts; done reached\n",
      "\taction [-0.83440977 -0.91021901 -0.98580205 -0.94441074]\n",
      "\taction [-0.19847041 -0.26477617 -0.2472696  -0.31962267]\n",
      "\taction [-0.37100273 -0.40471521 -0.22654246 -0.46758595]\n",
      "\taction [-0.15357147 -0.35602474 -0.27502462 -0.32340094]\n",
      "episode 478 at 1000 ts; done reached\n",
      "\taction [-0.80567896 -0.90216273 -0.98544192 -0.85232186]\n",
      "\taction [-0.13599589 -0.33811888 -0.24021474 -0.44010133]\n",
      "\taction [-0.49715543 -0.56955528 -0.38914767 -0.35980612]\n",
      "\taction [-0.15514629 -0.44835445 -0.15332136 -0.45888248]\n",
      "episode 479 at 1000 ts; done reached\n",
      "\taction [-0.99637789 -0.87464386 -0.93096751 -0.88471103]\n",
      "\taction [-0.35155547 -0.2741487  -0.2253987  -0.37585792]\n",
      "\taction [-0.39744037 -0.33073032 -0.12095849 -0.38402152]\n",
      "\taction [-0.28834161 -0.46371958 -0.4405998  -0.59881079]\n",
      "episode 480 at 1000 ts; done reached\n",
      "\taction [-0.94576114 -0.89490068 -0.84047753 -0.8797586 ]\n",
      "\taction [-0.34996688 -0.36792779 -0.30030486 -0.39775103]\n",
      "\taction [-0.2062819  -0.44772866 -0.32618591 -0.30261591]\n",
      "\taction [-0.3593322  -0.40995112 -0.27237868 -0.39979276]\n",
      "episode 481 at 1000 ts; done reached\n",
      "\taction [-0.98438591 -0.93991464 -0.89190733 -0.90790689]\n",
      "\taction [-0.37851328 -0.3887504  -0.32239902 -0.27350208]\n",
      "\taction [-0.2116551  -0.52028131 -0.43423158 -0.20818262]\n",
      "\taction [-0.47395036 -0.34332976 -0.31109032 -0.3357369 ]\n",
      "episode 482 at 1000 ts; done reached\n",
      "\taction [-0.93452805 -0.99794859 -0.99685019 -0.87557125]\n",
      "\taction [-0.26024833 -0.27647156 -0.28222585 -0.3716951 ]\n",
      "\taction [-0.31744492 -0.32491297 -0.36068514 -0.32938167]\n",
      "\taction [-0.46391225 -0.34221873 -0.34096697 -0.4915309 ]\n",
      "episode 483 at 1000 ts; done reached\n",
      "\taction [-0.95154124 -0.84989601 -0.94680774 -0.92056781]\n",
      "\taction [-0.29112053 -0.27993962 -0.26661035 -0.17569424]\n",
      "\taction [-0.23106062 -0.39304009 -0.49276552 -0.2302282 ]\n",
      "\taction [-0.29070702 -0.30362889 -0.39279461 -0.3312847 ]\n",
      "episode 484 at 1000 ts; done reached\n",
      "\taction [-0.89685243 -0.89802504 -0.80902719 -0.94966209]\n",
      "reward 0.029999999329447746\n",
      "reward 0.03999999910593033\n",
      "reward 0.009999999776482582\n",
      "\taction [-0.25179175 -0.36514732 -0.24364239 -0.45571533]\n",
      "\taction [-0.23812357 -0.31559721 -0.44448778 -0.28156203]\n",
      "\taction [-0.36487293 -0.49931693 -0.48833773 -0.31522763]\n",
      "episode 485 at 1000 ts; done reached\n",
      "\taction [-0.81387538 -0.92957377 -0.91176122 -0.92827177]\n",
      "\taction [-0.45169109 -0.50012505 -0.49702623 -0.31269288]\n",
      "\taction [-0.34319583 -0.34266722 -0.44558057 -0.19369173]\n",
      "\taction [-0.43313608 -0.31472233 -0.50966549 -0.38385782]\n",
      "episode 486 at 1000 ts; done reached\n",
      "\taction [-0.91748434 -0.93770111 -0.88085914 -0.94090849]\n",
      "\taction [-0.34470317 -0.43081912 -0.43479449 -0.32595545]\n",
      "\taction [-0.27645317 -0.39387348 -0.32651019 -0.33095133]\n",
      "\taction [-0.20811701 -0.56891704 -0.32230416 -0.44197592]\n",
      "episode 487 at 1000 ts; done reached\n",
      "\taction [-0.81078303 -0.85857511 -0.8009311  -0.80409652]\n",
      "\taction [-0.41877636 -0.06408013 -0.3343977  -0.30952451]\n",
      "\taction [-0.61609858 -0.26788396 -0.31729662 -0.50113291]\n",
      "\taction [-0.20246324 -0.3160201  -0.32315174 -0.38702786]\n",
      "episode 488 at 1000 ts; done reached\n",
      "\taction [-0.9722268  -0.88955951 -0.8272391  -0.93318057]\n",
      "\taction [-0.32501444 -0.44927487 -0.27186003 -0.2076235 ]\n",
      "\taction [-0.26409224 -0.30874434 -0.44868144 -0.32523578]\n",
      "\taction [-0.24347173 -0.28002369 -0.34545192 -0.19589727]\n",
      "episode 489 at 1000 ts; done reached\n",
      "\taction [-0.96200591 -0.93335837 -0.99870682 -0.80463785]\n",
      "\taction [-0.28262559 -0.16130991 -0.20776553 -0.11861336]\n",
      "\taction [-0.43559328 -0.54123414 -0.2566157  -0.32972488]\n",
      "\taction [-0.23076025 -0.29520944 -0.18876006 -0.4228248 ]\n",
      "episode 490 at 1000 ts; done reached\n",
      "\taction [-0.81626338 -0.94982785 -0.94203097 -0.83156049]\n",
      "\taction [-0.30899939 -0.49860686 -0.5264734  -0.32692492]\n",
      "\taction [-0.41123912 -0.28716096 -0.25507483 -0.38454196]\n",
      "\taction [-0.38533428 -0.21981604 -0.28466168 -0.49418885]\n",
      "episode 491 at 1000 ts; done reached\n",
      "\taction [-0.96146315 -0.97489345 -0.88014936 -0.94960433]\n",
      "\taction [-0.41180098 -0.41056523 -0.20585927 -0.26080129]\n",
      "\taction [-0.45181841 -0.42434666 -0.16618018 -0.38331586]\n",
      "\taction [-0.39393798 -0.28437772 -0.34775752 -0.38133654]\n",
      "episode 492 at 1000 ts; done reached\n",
      "\taction [-0.92994022 -0.87080383 -0.95278907 -0.92124349]\n",
      "\taction [-0.33731291 -0.28903997 -0.26143166 -0.40407139]\n",
      "\taction [-0.53524703 -0.42538467 -0.53653967 -0.19229206]\n",
      "\taction [-0.26977178 -0.3058621  -0.30890739 -0.371465  ]\n",
      "episode 493 at 1000 ts; done reached\n",
      "\taction [-0.98253572 -0.95918387 -0.80268443 -0.83800727]\n",
      "\taction [-0.44336566 -0.41344604 -0.24364617 -0.19089693]\n",
      "\taction [-0.37715685 -0.42747459 -0.2962364  -0.27662894]\n",
      "\taction [-0.40512434 -0.17816341 -0.37024507 -0.32364458]\n",
      "episode 494 at 1000 ts; done reached\n",
      "\taction [-0.97085273 -0.9816094  -0.80780488 -0.99826568]\n",
      "\taction [-0.39031121 -0.35763994 -0.27644056 -0.2346794 ]\n",
      "\taction [-0.25829345 -0.24272738 -0.20010148 -0.36857441]\n",
      "\taction [-0.37924448 -0.40511027 -0.28064793 -0.29895407]\n",
      "episode 495 at 1000 ts; done reached\n",
      "\taction [-0.86354363 -0.83757955 -0.96313727 -0.97454685]\n",
      "\taction [-0.50264174 -0.02151799 -0.24660987 -0.38301951]\n",
      "\taction [-0.22378318 -0.16365887 -0.39448467 -0.54855305]\n",
      "\taction [-0.23611224 -0.42414889 -0.28122297 -0.32940596]\n",
      "episode 496 at 1000 ts; done reached\n",
      "\taction [-0.88882428 -0.91393113 -0.9917239  -0.84447455]\n",
      "reward 0.019999999552965164\n",
      "reward 0.019999999552965164\n",
      "\taction [-0.39540821 -0.21510899 -0.3193908  -0.325317  ]\n",
      "\taction [-0.43181479 -0.22231643 -0.35907403 -0.29805273]\n",
      "\taction [-0.33919159 -0.3918618  -0.46300754 -0.37040797]\n",
      "episode 497 at 1000 ts; done reached\n",
      "\taction [-0.94793493 -0.99439496 -0.83906108 -0.80203962]\n",
      "\taction [-0.2073084  -0.37091053 -0.36439455 -0.30381131]\n",
      "\taction [-0.32182008 -0.337239   -0.32993099 -0.35869268]\n",
      "\taction [-0.43123657 -0.35159954 -0.36706886 -0.3417556 ]\n",
      "episode 498 at 1000 ts; done reached\n",
      "\taction [-0.8629083  -0.83666641 -0.85009658 -0.83559489]\n",
      "\taction [-0.37527815 -0.17598687 -0.24394502 -0.37877128]\n",
      "\taction [-0.30232739 -0.07437921 -0.28321579 -0.36312509]\n",
      "\taction [-0.28502554 -0.1038687  -0.42198989 -0.13171934]\n",
      "episode 499 at 1000 ts; done reached\n",
      "[0.19999999552965164, 1.2999999709427357, 0.7399999834597111, 1.0599999763071537, 0.8399999812245369, 0.8999999798834324, 0.5899999868124723, 0.9499999787658453, 0.1099999975413084, 0.1099999975413084, 0.2799999937415123, 0.5099999886006117, 0.0, 0.0, 0.0, 0.1699999962002039, 0.0, 0.2899999935179949, 1.9499999564141035, 0.14999999664723873, 0.6799999848008156, 0.35999999195337296, 0.6799999848008156, 0.7099999841302633, 0.5299999881535769, 0.7699999827891588, 0.5999999865889549, 0.47999998927116394, 0.29999999329447746, 0.8999999798834324, 0.789999982342124, 0.5399999879300594, 0.40999999083578587, 1.649999963119626, 0.5799999870359898, 0.909999979659915, 0.25999999418854713, 0.4399999901652336, 0.35999999195337296, 0.5899999868124723, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11999999731779099, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05999999865889549, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13999999687075615, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12999999709427357, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12999999709427357, 0.0, 0.0, 0.0, 0.0, 0.1699999962002039, 0.0, 0.09999999776482582, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09999999776482582, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11999999731779099, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13999999687075615, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11999999731779099, 0.0, 0.13999999687075615, 0.11999999731779099, 0.0, 0.0, 0.0, 0.13999999687075615, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09999999776482582, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1599999964237213, 0.0, 0.14999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04999999888241291, 0.0, 0.0, 0.0, 0.08999999798834324, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07999999821186066, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17999999597668648, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12999999709427357, 0.0, 0.0, 0.08999999798834324, 0.0, 0.0, 0.0, 0.08999999798834324, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09999999776482582, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12999999709427357, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09999999776482582, 0.0, 0.0, 0.14999999664723873, 0.0, 0.0, 0.11999999731779099, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05999999865889549, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1599999964237213, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.019999999552965164, 0.0, 0.0, 0.1699999962002039, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12999999709427357, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07999999821186066, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03999999910593033, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "import queue\n",
    "from collections import deque\n",
    "\n",
    "print_every = 300\n",
    "# seems to be 1000 for the env anyway\n",
    "max_ts = 2000\n",
    "max_episodes = 500\n",
    "curr_agent = agent.Agent(state_size, action_size)\n",
    "\n",
    "\n",
    "# can't use a queue.Queue because \"Insertion will block once this size has been reached, until queue items are consumed\"\n",
    "scores = deque(maxlen=100)                          # initialize the score (for each agent)\n",
    "scores_history = []\n",
    "\n",
    "\n",
    "# env expecting the list?\n",
    "# action not in the form env was expecting?\n",
    "\n",
    "# dropout too high?\n",
    "\n",
    "\n",
    "episode_won_i = 0\n",
    "\n",
    "with active_session():\n",
    "    for i in range(max_episodes):\n",
    "        # initialize for the start of the episode\n",
    "        env_info = env.reset(train_mode=True)[brain_name]      # reset the environment    \n",
    "        state = env_info.vector_observations[0]                  # get the current state (for each agent)\n",
    "        # resets the noise class variable\n",
    "        curr_agent.reset()\n",
    "        score = 0\n",
    "        \n",
    "        for t in range(max_ts):\n",
    "            action = curr_agent.act(state.astype('float32', copy=False))\n",
    "            \n",
    "            if t % print_every == 0:\n",
    "                print('\\taction', action)\n",
    "                \n",
    "            env_info = env.step(action)[brain_name]\n",
    "            reward = env_info.rewards[0]\n",
    "            if reward != 0:\n",
    "                print(\"reward\", reward)\n",
    "            next_state = env_info.vector_observations[0]\n",
    "            done = env_info.local_done[0]\n",
    "            \n",
    "            #score = score * curr_agent.Q_DISCOUNT + reward[0]\n",
    "            #score = score * curr_agent.Q_DISCOUNT + reward\n",
    "            score = score + reward\n",
    "\n",
    "            curr_agent.step(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "\n",
    "            # done is a vector\n",
    "            if done: \n",
    "            #if done[0]: \n",
    "                print(\"episode {} at {} ts; done reached\".format(i, t))\n",
    "                break\n",
    "        scores_history.append(score)\n",
    "        scores.append(score)\n",
    "        if i % print_every == 0:\n",
    "            print(\"episode {}; average score past 100 episodes: {}\".format(i, np.mean(scores)))\n",
    "        if np.mean(scores) >= 30:\n",
    "            episode_won_i = i\n",
    "            print(\"Solved in {} episodes\".format(episode_won_i))\n",
    "            curr_agent.save()\n",
    "            break\n",
    "            \n",
    "    print(scores_history)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_history = [0.19999999552965164, 1.2999999709427357, 0.7399999834597111, 1.0599999763071537, 0.8399999812245369, 0.8999999798834324, 0.5899999868124723, 0.9499999787658453, 0.1099999975413084, 0.1099999975413084, 0.2799999937415123, 0.5099999886006117, 0.0, 0.0, 0.0, 0.1699999962002039, 0.0, 0.2899999935179949, 1.9499999564141035, 0.14999999664723873, 0.6799999848008156, 0.35999999195337296, 0.6799999848008156, 0.7099999841302633, 0.5299999881535769, 0.7699999827891588, 0.5999999865889549, 0.47999998927116394, 0.29999999329447746, 0.8999999798834324, 0.789999982342124, 0.5399999879300594, 0.40999999083578587, 1.649999963119626, 0.5799999870359898, 0.909999979659915, 0.25999999418854713, 0.4399999901652336, 0.35999999195337296, 0.5899999868124723, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11999999731779099, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05999999865889549, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13999999687075615, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12999999709427357, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12999999709427357, 0.0, 0.0, 0.0, 0.0, 0.1699999962002039, 0.0, 0.09999999776482582, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09999999776482582, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11999999731779099, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13999999687075615, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11999999731779099, 0.0, 0.13999999687075615, 0.11999999731779099, 0.0, 0.0, 0.0, 0.13999999687075615, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09999999776482582, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1599999964237213, 0.0, 0.14999999664723873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04999999888241291, 0.0, 0.0, 0.0, 0.08999999798834324, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07999999821186066, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17999999597668648, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12999999709427357, 0.0, 0.0, 0.08999999798834324, 0.0, 0.0, 0.0, 0.08999999798834324, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09999999776482582, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12999999709427357, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09999999776482582, 0.0, 0.0, 0.14999999664723873, 0.0, 0.0, 0.11999999731779099, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05999999865889549, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1599999964237213, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.019999999552965164, 0.0, 0.0, 0.1699999962002039, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12999999709427357, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07999999821186066, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03999999910593033, 0.0, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f98023205c0>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9802380eb8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot of rewards\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(1,len(scores_history) +1 ), scores_history)\n",
    "\n",
    "#plt.plot(range(1,len(scores) +1 ), scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'agent' from '/home/workspace/agent.py'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  A few **important notes**:\n",
    "- When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```\n",
    "- To structure your work, you're welcome to work directly in this Jupyter notebook, or you might like to start over with a new file!  You can see the list of files in the workspace by clicking on **_Jupyter_** in the top left corner of the notebook.\n",
    "- In this coding environment, you will not be able to watch the agents while they are training.  However, **_after training the agents_**, you can download the saved model weights to watch the agents on your own machine! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
